
# Acceptance_test-driven_development.md




(Top)





1
Overview




Toggle Overview subsection





1.1
Creation








1.2
Testing strategy










2
Acceptance criteria and tests




Toggle Acceptance criteria and tests subsection





2.1
Test format








2.2
Complete test








2.3
Test examination








2.4
Another test example








2.5
Project acceptance tests










3
See also








4
References








5
External links










1.1
Creation








1.2
Testing strategy














2.1
Test format








2.2
Complete test








2.3
Test examination








2.4
Another test example








2.5
Project acceptance tests






















Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Acceptance test–driven development (ATDD) is a development methodology based on communication between the business customers, the developers, and the testers.[1] ATDD encompasses many of the same practices as specification by example (SBE),[2][3] behavior-driven development (BDD),[4] example-driven development (EDD),[5] and support-driven development also called story test–driven development (SDD).[6] All these processes aid developers and testers in understanding the customer's needs prior to implementation and allow customers to be able to converse in their own domain language.

ATDD is closely related to test-driven development (TDD).[7] It differs by the emphasis on developer-tester-business customer collaboration. ATDD encompasses acceptance testing, but highlights writing acceptance tests before developers begin coding.

Acceptance tests are from the user's point of view – the external view of the system.[1] They examine externally visible effects, such as specifying the correct output of a system given a particular input. Acceptance tests can verify how the state of something changes, such as an order that goes from "paid" to "shipped". They also can check the interactions with interfaces of other systems, such as shared databases or web services. In general, they are implementation independent, although automation of them may not be.[8][9]

Acceptance tests are created when the requirements are analyzed and prior to coding.[1] They can be developed collaboratively by requirement requester (product owner, business analyst, customer representative, etc.), developer, and tester. Developers implement the system using the acceptance tests. Failing tests provide quick feedback that the requirements are not being met. The tests are specified in business domain terms. The terms then form a ubiquitous language that is shared between the customers, developers, and testers.[10] Tests and requirements are interrelated.[11] A requirement that lacks a test may not be implemented properly. A test that does not refer to a requirement is an unneeded test. An acceptance test that is developed after implementation begins represents a new requirement.[12]

Acceptance tests are a part of an overall testing strategy. They are the customer tests that demonstrate the business intent of a system. Component tests are technical acceptance tests developed by an architect that specify the behavior of large modules. Unit tests are created by the developer to drive easy-to-maintain code.[13] They are often derived from acceptance tests and unit tests. Cross-functional testing includes usability testing,[14] exploratory testing,[15] and property testing (scaling and security).[16]

Acceptance criteria are a description of what would be checked by a test. Given a requirement such as "As a user, I want to check out a book from the library", an acceptance criterion might be, "verify the book is marked as checked out". An acceptance test for this requirement gives the details so that the test can be run with the same effect each time.

Acceptance tests usually follow this form:[1]

Given (setup)

When (trigger)

Then (verification)

Also, it is possible to add Statements that start with AND in any of the sections below (Given, When, Then).


For the example requirement, the steps could be listed as:
The previous steps do not include any specific example data, so that is added to complete the test:

Given:


Books




Title
Checked out


Great book
No


Users


Name
Sam

When:


Checkout action


User
Sam
Checks out
Great book

Then:


Books


Title
Checked out
User


Great book
Yes
Sam

Examination of the test with specific data usually leads to many questions. For the sample, these might be:

What if the book is already checked out?
What if the book does not exist?
What if the user is not registered on the system?
Is there a date that the book is due to be checked-in?
How many books can a user check out?
These questions help illuminate missing or ambiguous requirements. Additional details such as a due-date can be added to the expected result. Other acceptance tests can check that conditions such as attempting to check out a book that is already checked out produces the expected error.

Suppose the business customer wanted a business rule that a user could only check out one book at a time. The following test would demonstrate that:

Scenario:
Check that checkout business rule is enforced

Given:


Books


Title
Checked out
User


Great book
Yes
Sam


Another great book
No


Users


Name


Sam

When:


Checkout action


User
Sam
Checks out
Another great book

Then:


Error occurred


Description


Violation of checkout business rule

In addition to acceptance tests for requirements, acceptance tests can be used on a project as a whole.[1] For example, if this requirement was part of a library book checkout project, there could be acceptance tests for the whole project. These are often termed SMART objectives. An example test is "When the new library system is in production, the users will be able to check books in and out three times as fast as they do today".

Concordion
FitNesse
Robot Framework
Gauge (software)
Cucumber (software)
Software development philosophiesSoftware testingBusiness analysis






# Agile_modeling.md




(Top)





1
Core practices




Toggle Core practices subsection





1.1
Documentation








1.2
Modeling










2
Limitations








3
See also








4
References








5
External links










1.1
Documentation








1.2
Modeling


















This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these template messages)

The topic of this article may not meet Wikipedia's general notability guideline. Please help to demonstrate the notability of the topic by citing reliable secondary sources that are independent of the topic and provide significant coverage of it beyond a mere trivial mention. If notability cannot be shown, the article is likely to be merged, redirected, or deleted.Find sources: "Agile modeling" – news · newspapers · books · scholar · JSTOR (November 2019) (Learn how and when to remove this message)
 A major contributor to this article appears to have a close connection with its subject. It may require cleanup to comply with Wikipedia's content policies, particularly neutral point of view. Please discuss further on the talk page. (November 2019) (Learn how and when to remove this message)
This article may rely excessively on sources too closely associated with the subject, potentially preventing the article from being verifiable and neutral. Please help improve it by replacing them with more appropriate citations to reliable, independent, third-party sources. (November 2019) (Learn how and when to remove this message)

 (Learn how and when to remove this message)
The topic of this article may not meet Wikipedia's general notability guideline. Please help to demonstrate the notability of the topic by citing reliable secondary sources that are independent of the topic and provide significant coverage of it beyond a mere trivial mention. If notability cannot be shown, the article is likely to be merged, redirected, or deleted.Find sources: "Agile modeling" – news · newspapers · books · scholar · JSTOR (November 2019) (Learn how and when to remove this message)
 A major contributor to this article appears to have a close connection with its subject. It may require cleanup to comply with Wikipedia's content policies, particularly neutral point of view. Please discuss further on the talk page. (November 2019) (Learn how and when to remove this message)
This article may rely excessively on sources too closely associated with the subject, potentially preventing the article from being verifiable and neutral. Please help improve it by replacing them with more appropriate citations to reliable, independent, third-party sources. (November 2019) (Learn how and when to remove this message)
Agile modeling (AM) is a methodology for modeling and documenting software systems based on best practices. It is a collection of values and principles that can be applied on an (agile) software development project. This methodology is more flexible than traditional modeling methods, making it a better fit in a fast-changing environment.[1] It is part of the agile software development tool kit. 

Agile modeling is a supplement to other agile development methodologies such as Scrum, extreme programming (XP), and Rational Unified Process (RUP). It is explicitly included as part of the disciplined agile delivery (DAD) framework. As per 2011 stats, agile modeling accounted for 1% of all agile software development.[2]

Agile modeling is one form of Agile model-driven engineering (Agile MDE), which has been adopted in several application areas such as web application development, finance, and automotive systems [3]

There are several core practices:

Document continuously. Documentation is made throughout the life-cycle, in parallel to the creation of the rest of the solution.
Document late. Documentation is made as late as possible, avoiding speculative ideas that are likely to change in favor of stable information.
Executable specifications. Requirements are specified in the form of executable "customer tests", instead of non-executable "static" documentation.
Single-source information. Information (models, documentation, software), is stored in one place and one place only, to prevent questions about what the "correct" version / information is.
Active stakeholder participation. Stakeholders of the solution/software being modeled should be actively involved with doing so. This is an extension of the on-site customer practice from Extreme Programming.
Architecture envisioning. The team performs light-weight, high-level modeling that is just barely good enough (JBGE) at the beginning of a software project so as to explore the architecture strategy that the team believes will work.
Inclusive tools. Prefer modelling tools, such as whiteboards and paper, that are easy to work with (they're inclusive).
Iteration modeling. When a requirement/work item has not been sufficiently explored in detail via look-ahead modeling the team may choose to do that exploration during their iteration/sprint planning session. The need to do this is generally seen as a symptom that the team is not doing sufficient look-ahead modeling.
Just barely good enough (JBGE). All artifacts, including models and documents, should be just sufficient for the task at hand. JBGE is contextual in nature, in the case of the model it is determined by a combination of the complexity of whatever the model describes and the skills of the audience for that model.
Look-ahead modeling. An agile team will look down their backlog one or more iterations/sprints ahead to ensure that a requirement/work item is ready to be worked on. Also called "backlog grooming" or "backlog refinement" in Scrum.
Model storming. A short, often impromptu, agile modeling session. Model storming sessions are held to explore the details of a requirement or aspect of your design.
Multiple models. Agile modelers should know how to create a range of model types (such as user stories, story maps, data models, Unified Modeling Language (UML) diagrams, and more) so as to apply the best model for the situation at hand.
Prioritized requirements. Requirements should be worked on in priority order.
Requirements envisioning. The team performs light-weight, high-level modeling that is JBGE at the beginning of a software project to explore the stakeholder requirements.
There is significant dependence on personal communication and customer collaboration. Agile modeling disciplines can be difficult to apply [citation needed]:

On large teams (say 30 or more) without adequate tooling support
Where team members are unable to share and collaborate on models (which would make agile software development in general difficult)
When modeling skills are weak or lacking.
Story-driven modelling
Agile software development
Robustness diagram
Agile software development
Articles with topics of unclear notability from November 2019All articles with topics of unclear notabilityWikipedia articles with possible conflicts of interest from November 2019Articles lacking reliable references from November 2019All articles lacking reliable referencesArticles with multiple maintenance issuesAll articles with unsourced statementsArticles with unsourced statements from October 2016






# Agile_software_development.md




(Top)





1
History








2
Values and Principles




Toggle Values and Principles subsection





2.1
Values








2.2
Principles










3
Overview




Toggle Overview subsection





3.1
Iterative, incremental, and evolutionary








3.2
Efficient and face-to-face communication






3.2.1
Information radiator










3.3
Very short feedback loop and adaptation cycle








3.4
Quality focus










4
Philosophy




Toggle Philosophy subsection





4.1
Adaptive vs. predictive








4.2
Agile vs. waterfall








4.3
Code vs. documentation










5
Methods




Toggle Methods subsection





5.1
Agile software development practices






5.1.1
Acceptance test-driven development








5.1.2
Agile modeling








5.1.3
Agile testing








5.1.4
Backlogs








5.1.5
Behavior-driven development








5.1.6
Continuous integration








5.1.7
Cross-functional team








5.1.8
Daily stand-up










5.2
Method tailoring








5.3
Large-scale, offshore and distributed








5.4
Regulated domains










6
Experience and adoption




Toggle Experience and adoption subsection





6.1
Measuring agility






6.1.1
Internal assessments








6.1.2
Public surveys










6.2
Common agile software development pitfalls






6.2.1
Lack of overall product design








6.2.2
Adding stories to an iteration in progress








6.2.3
Lack of sponsor support








6.2.4
Insufficient training








6.2.5
Product owner role is not properly filled








6.2.6
Teams are not focused








6.2.7
Excessive preparation/planning








6.2.8
Problem-solving in the daily standup








6.2.9
Assigning tasks








6.2.10
Scrum master as a contributor








6.2.11
Lack of test automation








6.2.12
Allowing technical debt to build up








6.2.13
Attempting to take on too much in an iteration








6.2.14
Fixed time, resources, scope, and quality








6.2.15
Developer burnout












7
Agile management




Toggle Agile management subsection





7.1
Applications outside software development










8
Criticism








9
See also








10
References








11
Further reading








12
External links












2.1
Values








2.2
Principles














3.1
Iterative, incremental, and evolutionary








3.2
Efficient and face-to-face communication






3.2.1
Information radiator










3.3
Very short feedback loop and adaptation cycle








3.4
Quality focus












3.2.1
Information radiator
















4.1
Adaptive vs. predictive








4.2
Agile vs. waterfall








4.3
Code vs. documentation
















5.1
Agile software development practices






5.1.1
Acceptance test-driven development








5.1.2
Agile modeling








5.1.3
Agile testing








5.1.4
Backlogs








5.1.5
Behavior-driven development








5.1.6
Continuous integration








5.1.7
Cross-functional team








5.1.8
Daily stand-up










5.2
Method tailoring








5.3
Large-scale, offshore and distributed








5.4
Regulated domains










5.1.1
Acceptance test-driven development








5.1.2
Agile modeling








5.1.3
Agile testing








5.1.4
Backlogs








5.1.5
Behavior-driven development








5.1.6
Continuous integration








5.1.7
Cross-functional team








5.1.8
Daily stand-up
































6.1
Measuring agility






6.1.1
Internal assessments








6.1.2
Public surveys










6.2
Common agile software development pitfalls






6.2.1
Lack of overall product design








6.2.2
Adding stories to an iteration in progress








6.2.3
Lack of sponsor support








6.2.4
Insufficient training








6.2.5
Product owner role is not properly filled








6.2.6
Teams are not focused








6.2.7
Excessive preparation/planning








6.2.8
Problem-solving in the daily standup








6.2.9
Assigning tasks








6.2.10
Scrum master as a contributor








6.2.11
Lack of test automation








6.2.12
Allowing technical debt to build up








6.2.13
Attempting to take on too much in an iteration








6.2.14
Fixed time, resources, scope, and quality








6.2.15
Developer burnout












6.1.1
Internal assessments








6.1.2
Public surveys














6.2.1
Lack of overall product design








6.2.2
Adding stories to an iteration in progress








6.2.3
Lack of sponsor support








6.2.4
Insufficient training








6.2.5
Product owner role is not properly filled








6.2.6
Teams are not focused








6.2.7
Excessive preparation/planning








6.2.8
Problem-solving in the daily standup








6.2.9
Assigning tasks








6.2.10
Scrum master as a contributor








6.2.11
Lack of test automation








6.2.12
Allowing technical debt to build up








6.2.13
Attempting to take on too much in an iteration








6.2.14
Fixed time, resources, scope, and quality








6.2.15
Developer burnout








































7.1
Applications outside software development




















Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Agile software development is an umbrella term for approaches to developing software that reflect the values and principles agreed upon by The Agile Alliance, a group of 17 software practitioners in 2001[1]. As documented in their Manifesto for Agile Software Development the practitioners value:[2]

Individuals and interactions over processes and tools
Working software over comprehensive documentation
Customer collaboration over contract negotiation
Responding to change over following a plan
The practitioners cite inspiration from new practices at the time including extreme programming, scrum, dynamic systems development method, adaptive software development and being sympathetic to the need for an alternative to documentation driven, heavyweight software development processes. [3]

Many software development practices emerged from the agile mindset. These agile-based practices, sometimes called Agile (with a capital A)[4] include requirements, discovery and solutions improvement through the collaborative effort of self-organizing and cross-functional teams with their customer(s)/end user(s).[5][6]

While there is much anecdotal evidence that the agile mindset and agile-based practices improve the software development process, the empirical evidence is limited and less than conclusive.[7][8][9]

Iterative and incremental software development methods can be traced back as early as 1957,[10] with evolutionary project management[11][12] and adaptive software development[13] emerging in the early 1970s.[14]

During the 1990s, a number of lightweight software development methods evolved in reaction to the prevailing heavyweight methods (often referred to collectively as waterfall) that critics described as overly regulated, planned, and micromanaged.[15] These lightweight methods included: rapid application development (RAD), from 1991;[16][17] the unified process (UP) and dynamic systems development method (DSDM), both from 1994; Scrum, from 1995; Crystal Clear and extreme programming (XP), both from 1996; and feature-driven development (FDD), from 1997. Although these all originated before the publication of the Agile Manifesto, they are now collectively referred to as agile software development methods.[3]

Already since 1991 similar changes had been underway in manufacturing[18][19] and management thinking[20] derived from Lean management.

In 2001, seventeen software developers met at a resort in Snowbird, Utah to discuss lightweight development methods. They were: Kent Beck (Extreme Programming), Ward Cunningham (Extreme Programming), Dave Thomas (PragProg, Ruby), Jeff Sutherland (Scrum), Ken Schwaber (Scrum), Jim Highsmith (Adaptive Software Development), Alistair Cockburn (Crystal), Robert C. Martin (SOLID), Mike Beedle (Scrum), Arie van Bennekum, Martin Fowler (OOAD and UML), James Grenning, Andrew Hunt (PragProg, Ruby), Ron Jeffries (Extreme Programming), Jon Kern, Brian Marick (Ruby, TDD), and Steve Mellor (OOA). The group, The Agile Alliance, published the Manifesto for Agile Software Development.[2]

In 2005, a group headed by Cockburn and Highsmith wrote an addendum of project management principles, the PM Declaration of Interdependence,[21] to guide software project management according to agile software development methods.

In 2009, a group working with Martin wrote an extension of software development principles, the Software Craftsmanship Manifesto, to guide agile software development according to professional conduct and mastery.

In 2011, the Agile Alliance created the Guide to Agile Practices (renamed the Agile Glossary in 2016),[22] an evolving open-source compendium of the working definitions of agile practices, terms, and elements, along with interpretations and experience guidelines from the worldwide community of agile practitioners.

The agile manifesto reads:[2]

We are uncovering better ways of developing software by doing it and helping others do it. Through this work we have come to value:

 Individuals and interactions over processes and tools 
 Working software over comprehensive documentation 
 Customer collaboration over contract negotiation 
 Responding to change over following a plan 
That is, while there is value in the items on the right, we value the items on the left more.

Scott Ambler explained:[23]

Tools and processes are important, but it is more important to have competent people working together effectively.
Good documentation is useful in helping people to understand how the software is built and how to use it, but the main point of development is to create software, not documentation.
A contract is important but is no substitute for working closely with customers to discover what they need.
A project plan is important, but it must not be too rigid to accommodate changes in technology or the environment, stakeholders' priorities, and people's understanding of the problem and its solution.
Introducing the manifesto on behalf of the Agile Alliance, Jim Highsmith said,

The Agile movement is not anti-methodology, in fact many of us want to restore credibility to the word methodology. We want to restore a balance. We embrace modeling, but not in order to file some diagram in a dusty corporate repository. We embrace documentation, but not hundreds of pages of never-maintained and rarely-used tomes. We plan, but recognize the limits of planning in a turbulent environment. Those who would brand proponents of XP or SCRUM or any of the other Agile Methodologies as "hackers" are ignorant of both the methodologies and the original definition of the term hacker.
The values are based on these principles:[25]

Customer satisfaction by early and continuous delivery of valuable software.
Welcome changing requirements, even in late development.
Deliver working software frequently (weeks rather than months).
Close, daily cooperation between business people and developers.
Projects are built around motivated individuals, who should be trusted.
Face-to-face conversation is the best form of communication (co-location).
Working software is the primary measure of progress.
Sustainable development, able to maintain a constant pace.
Continuous attention to technical excellence and good design.
Simplicity—the art of maximizing the amount of work not done—is essential.
Best architectures, requirements, and designs emerge from self-organizing teams.
Regularly, the team reflects on how to become more effective, and adjusts accordingly.
Most agile development methods break product development work into small increments that minimize the amount of up-front planning and design. Iterations, or sprints, are short time frames (timeboxes)[26] that typically last from one to four weeks.[27]: 20  Each iteration involves a cross-functional team working in all functions: planning, analysis, design, coding, unit testing, and acceptance testing. At the end of the iteration a working product is demonstrated to stakeholders. This minimizes overall risk and allows the product to adapt to changes quickly.[28][29] An iteration might not add enough functionality to warrant a market release, but the goal is to have an available release (with minimal bugs) at the end of each iteration.[30] Through incremental development, products have room to "fail often and early" throughout each iterative phase instead of drastically on a final release date.[31] Multiple iterations might be required to release a product or new features. Working software is the primary measure of progress.[25]

A key advantage of agile approaches is speed to market and risk mitigation. Smaller increments are typically released to market, reducing the time and cost risks of engineering a product that doesn't meet user requirements.

The 6th principle of the agile manifesto for software development states "The most efficient and effective method of conveying information to and within a development team is face-to-face conversation". The manifesto, written in 2001 when video conferencing was not widely used, states this in relation to the communication of information, not necessarily that a team should be co-located.

The principle of co-location is that co-workers on the same team should be situated together to better establish the identity as a team and to improve communication.[32] This enables face-to-face interaction, ideally in front of a whiteboard, that reduces the cycle time typically taken when questions and answers are mediated through phone, persistent chat, wiki, or email.[33] With the widespread adoption of remote working during the COVID-19 pandemic and changes to tooling, more studies have been conducted[34] around co-location and distributed working which show that co-location is increasingly less relevant.

No matter which development method is followed, every team should include a customer representative (known as product owner in Scrum). This representative is agreed by stakeholders to act on their behalf and makes a personal commitment to being available for developers to answer questions throughout the iteration. At the end of each iteration, the project stakeholders together with the customer representative review progress and re-evaluate priorities with a view to optimizing the return on investment (ROI) and ensuring alignment with customer needs and company goals. The importance of stakeholder satisfaction, detailed by frequent interaction and review at the end of each phase, is why the approach is often denoted as a customer-centered methodology.[35]

In agile software development, an information radiator is a (normally large) physical display, board with sticky notes or similar, located prominently near the development team, where passers-by can see it.[36] It presents an up-to-date summary of the product development status.[37][38] A build light indicator may also be used to inform a team about the current status of their product development.

A common characteristic in agile software development is the daily stand-up (known as daily scrum in the Scrum framework). In a brief session (e.g., 15 minutes), team members review collectively how they are progressing toward their goal and agree whether they need to adapt their approach. To keep to the agreed time limit, teams often use simple coded questions (such as what they completed the previous day, what they aim to complete that day, and whether there are any impediments or risks to progress), and delay detailed discussions and problem resolution until after the stand-up.[39]

Specific tools and techniques, such as continuous integration, automated unit testing, pair programming, test-driven development, design patterns, behavior-driven development, domain-driven design, code refactoring and other techniques are often used to improve quality and enhance product development agility.[40] This is predicated on designing and building quality in from the beginning and being able to demonstrate software for customers at any point, or at least at the end of every iteration.[41]

Compared to traditional software engineering, agile software development mainly targets complex systems and product development with dynamic, indeterministic and non-linear properties. Accurate estimates, stable plans, and predictions are often hard to get in early stages, and confidence in them is likely to be low. Agile practitioners use their free will to reduce the "leap of faith" that is needed before any evidence of value can be obtained.[42] Requirements and design are held to be emergent. Big up-front specifications would probably cause a lot of waste in such cases, i.e., are not economically sound. These basic arguments and previous industry experiences, learned from years of successes and failures, have helped shape agile development's favor of adaptive, iterative and evolutionary development.[43]

Development methods exist on a continuum from adaptive to predictive.[44] Agile software development methods lie on the adaptive side of this continuum. One key of adaptive development methods is a rolling wave approach to schedule planning, which identifies milestones but leaves flexibility in the path to reach them, and also allows for the milestones themselves to change.[45]

Adaptive methods focus on adapting quickly to changing realities. When the needs of a project change, an adaptive team changes as well. An adaptive team has difficulty describing exactly what will happen in the future. The further away a date is, the more vague an adaptive method is about what will happen on that date. An adaptive team cannot report exactly what tasks they will do next week, but only which features they plan for next month. When asked about a release six months from now, an adaptive team might be able to report only the mission statement for the release, or a statement of expected value vs. cost.

Predictive methods, in contrast, focus on analysing and planning the future in detail and cater for known risks. In the extremes, a predictive team can report exactly what features and tasks are planned for the entire length of the development process. Predictive methods rely on effective early phase analysis and if this goes very wrong, the project may have difficulty changing direction. Predictive teams often institute a change control board to ensure they consider only the most valuable changes.

Risk analysis can be used to choose between adaptive (agile or value-driven) and predictive (plan-driven) methods.[46] Barry Boehm and Richard Turner suggest that each side of the continuum has its own home ground, as follows:[47]


Value-driven methods (agile)

Plan-driven methods (waterfall)

Formal methods


Low criticality

High criticality

Extreme criticality


Senior developers

Junior developers(?)

Senior developers


Requirements change often

Requirements do not change often

Limited requirements, limited features, see Wirth's law[clarification needed]


Small number of developers

Large number of developers

Requirements that can be modeled


Culture that responds to change

Culture that demands order

Extreme quality

One of the differences between agile software development methods and waterfall is the approach to quality and testing. In the waterfall model, work moves through software development life cycle (SDLC) phases—with one phase being completed before another can start—hence the testing phase is separate and follows a build phase. In agile software development, however, testing is completed in the same iteration as programming.

Because testing is done in every iteration—which develops a small piece of the software—users can frequently use those new pieces of software and validate the value. After the users know the real value of the updated piece of software, they can make better decisions about the software's future. Having a value retrospective and software re-planning session in each iteration—Scrum typically has iterations of just two weeks—helps the team continuously adapt its plans so as to maximize the value it delivers. This follows a pattern similar to the plan-do-check-act (PDCA) cycle, as the work is planned, done, checked (in the review and retrospective), and any changes agreed are acted upon.

This iterative approach supports a product rather than a project mindset. This provides greater flexibility throughout the development process; whereas on projects the requirements are defined and locked down from the very beginning, making it difficult to change them later. Iterative product development allows the software to evolve in response to changes in business environment or market requirements.

In a letter to IEEE Computer, Steven Rakitin expressed cynicism about agile software development, calling it "yet another attempt to undermine the discipline of software engineering" and translating "working software over comprehensive documentation" as "we want to spend all our time coding. Remember, real programmers don't write documentation."[48]

This is disputed by proponents of agile software development, who state that developers should write documentation if that is the best way to achieve the relevant goals, but that there are often better ways to achieve those goals than writing static documentation.[49]
Scott Ambler states that documentation should be "just barely good enough" (JBGE),[50] that too much or comprehensive documentation would usually cause waste, and developers rarely trust detailed documentation because it's usually out of sync with code,[49] while too little documentation may also cause problems for maintenance, communication, learning and knowledge sharing. Alistair Cockburn wrote of the Crystal Clear method: 

Crystal considers development a series of co-operative games, and intends that the documentation is enough to help the next win at the next game. The work products for Crystal include use cases, risk list, iteration plan, core domain models, and design notes to inform on choices...however there are no templates for these documents and descriptions are necessarily vague, but the objective is clear, just enough documentation for the next game. I always tend to characterize this to my team as: what would you want to know if you joined the team tomorrow.
Agile software development methods support a broad range of the software development life cycle.[52] Some methods focus on the practices (e.g., XP, pragmatic programming, agile modeling), while some focus on managing the flow of work (e.g., Scrum, Kanban). Some support activities for requirements specification and development (e.g., FDD), while some seek to cover the full development life cycle (e.g., DSDM, RUP).

Notable agile software development frameworks include:


Framework

Main contributor(s)


Adaptive software development (ASD)
Jim Highsmith, Sam Bayer


Agile modeling
Scott Ambler, Robert Cecil Martin


Agile unified process (AUP)
Scott Ambler


Disciplined agile delivery
Scott Ambler


Dynamic systems development method (DSDM)
Jennifer Stapleton


Extreme programming (XP)
Kent Beck, Robert Cecil Martin


Feature-driven development (FDD)
Jeff De Luca


Lean software development
Mary Poppendieck, Tom Poppendieck


Lean startup
Eric Ries


Kanban
Taiichi Ohno


Rapid application development (RAD)
James Martin


Scrum
Ken Schwaber, Jeff Sutherland


Scrumban


Agile software development is supported by a number of concrete practices, covering areas like requirements, design, modeling, coding, testing, planning, risk management, process, quality, etc. Some notable agile software development practices include:[53]


Practice

Main contributor(s)


Acceptance test-driven development (ATDD)



Agile modeling



Agile testing



Backlogs (Product and Sprint)
Ken Schwaber


Behavior-driven development (BDD)
Dan North, Liz Keogh


Continuous integration (CI)
Grady Booch


Cross-functional team



Daily stand-up / Daily Scrum

James O Coplien


Domain-driven design (DDD)
Eric Evans


Iterative and incremental development (IID)



Pair programming
Kent Beck


Planning poker
James Grenning, Mike Cohn


Refactoring
Martin Fowler


Retrospective



Scrum events (sprint planning, sprint review and retrospective)



Specification by example



Story-driven modeling
Albert Zündorf


Test-driven development (TDD)
Kent Beck


Timeboxing



User story
Alistair Cockburn


Velocity tracking


In the literature, different terms refer to the notion of method adaptation, including 'method tailoring', 'method fragment adaptation' and 'situational method engineering'. Method tailoring is defined as:

A process or capability in which human agents determine a system development approach for a specific project situation through responsive changes in, and dynamic interplays between contexts, intentions, and method fragments.
Situation-appropriateness should be considered as a distinguishing characteristic between agile methods and more plan-driven software development methods, with agile methods allowing product development teams to adapt working practices according to the needs of individual products.[71][70] Potentially, most agile methods could be suitable for method tailoring,[52] such as DSDM tailored in a CMM context.[72] and XP tailored with the Rule Description Practices (RDP) technique.[73] Not all agile proponents agree, however, with Schwaber noting "that is how we got into trouble in the first place, thinking that the problem was not having a perfect methodology. Efforts [should] center on the changes [needed] in the enterprise".[74] Bas Vodde reinforced this viewpoint, suggesting that unlike traditional, large methodologies that require you to pick and choose elements, Scrum provides the basics on top of which you add additional elements to localize and contextualize its use.[75] Practitioners seldom use system development methods, or agile methods specifically, by the book, often choosing to omit or tailor some of the practices of a method in order to create an in-house method.[76]

In practice, methods can be tailored using various tools. Generic process modeling languages such as Unified Modeling Language can be used to tailor software development methods. However, dedicated tools for method engineering such as the Essence Theory of Software Engineering of SEMAT also exist.[77]

Agile software development has been widely seen as highly suited to certain types of environments, including small teams of experts working on greenfield projects,[47][78] and the challenges and limitations encountered in the adoption of agile software development methods in a large organization with legacy infrastructure are well-documented and understood.[79]

In response, a range of strategies and patterns has evolved for overcoming challenges with large-scale development efforts (>20 developers)[80][81] or distributed (non-colocated) development teams,[82][83] amongst other challenges; and there are now several recognized frameworks that seek to mitigate or avoid these challenges.

There are many conflicting viewpoints on whether all of these are effective or indeed fit the definition of agile development, and this remains an active and ongoing area of research.[80][84]

When agile software development is applied in a distributed setting (with teams dispersed across multiple business locations), it is commonly referred to as distributed agile software development. The goal is to leverage the unique benefits offered by each approach. Distributed development allows organizations to build software by strategically setting up teams in different parts of the globe, virtually building software round-the-clock (more commonly referred to as follow-the-sun model). On the other hand, agile development provides increased transparency, continuous feedback, and more flexibility when responding to changes.

Agile software development methods were initially seen as best suitable for non-critical product developments, thereby excluded from use in regulated domains such as medical devices, pharmaceutical, financial, nuclear systems, automotive, and avionics sectors, etc. However, in the last several years, there have been several initiatives for the adaptation of agile methods for these domains.[85][86][87][88][89]

There are numerous standards that may apply in regulated domains, including ISO 26262, ISO 9000, ISO 9001, and ISO/IEC 15504.
A number of key concerns are of particular importance in regulated domains:[90]

Quality assurance (QA): Systematic and inherent quality management underpinning a controlled professional process and reliability and correctness of product.
Safety and security: Formal planning and risk management to mitigate safety risks for users and securely protecting users from unintentional and malicious misuse.
Traceability: Documentation providing auditable evidence of regulatory compliance and facilitating traceability and investigation of problems.
Verification and validation (V&V): Embedded throughout the software development process (e.g. user requirements specification, functional specification, design specification, code review, unit tests, integration tests, system tests).
Although agile software development methods can be used with any programming paradigm or language in practice, they were originally closely associated with object-oriented environments such as Smalltalk, Lisp and later Java, C#. The initial adopters of agile methods were usually small to medium-sized teams working on unprecedented systems with requirements that were difficult to finalize and likely to change as the system was being developed. This section describes common problems that organizations encounter when they try to adopt agile software development methods as well as various techniques to measure the quality and performance of agile teams.[91]

The Agility measurement index, amongst others, rates developments against five dimensions of product development (duration, risk, novelty, effort, and interaction).[92] Other techniques are based on measurable goals[93] and one study suggests that velocity can be used as a metric of agility. There are also agile self-assessments to determine whether a team is using agile software development practices (Nokia test,[94] Karlskrona test,[95] 42 points test).[96]

One of the early studies reporting gains in quality, productivity, and business satisfaction by using agile software developments methods was a survey conducted by Shine Technologies from November 2002 to January 2003.[97]

A similar survey, the State of Agile, is conducted every year starting in 2006 with thousands of participants from around the software development community. This tracks trends on the perceived benefits of agility, lessons learned, and good practices. Each survey has reported increasing numbers saying that agile software development helps them deliver software faster; improves their ability to manage changing customer priorities; and increases their productivity.[98] Surveys have also consistently shown better results with agile product development methods compared to classical project management.[99][100] In balance, there are reports that some feel that agile development methods are still too young to enable extensive academic research of their success.[101]

Organizations and teams implementing agile software development often face difficulties transitioning from more traditional methods such as waterfall development, such as teams having an agile process forced on them.[102] These are often termed agile anti-patterns or more commonly agile smells. Below are some common examples:

A goal of agile software development is to focus more on producing working software and less on documentation. This is in contrast to waterfall models where the process is often highly controlled and minor changes to the system require significant revision of supporting documentation. However, this does not justify completely doing without any analysis or design at all. Failure to pay attention to design can cause a team to proceed rapidly at first, but then to require significant rework as they attempt to scale up the system. One of the key features of agile software development is that it is iterative. When done correctly, agile software development allows the design to emerge as the system is developed and helps the team discover commonalities and opportunities for re-use.[103]

In agile software development, stories (similar to use case descriptions) are typically used to define requirements and an iteration is a short period of time during which the team commits to specific goals.[104] Adding stories to an iteration in progress is detrimental to a good flow of work. These should be added to the product backlog and prioritized for a subsequent iteration or in rare cases the iteration could be cancelled.[105]

This does not mean that a story cannot expand. Teams must deal with new information, which may produce additional tasks for a story. If the new information prevents the story from being completed during the iteration, then it should be carried over to a subsequent iteration. However, it should be prioritized against all remaining stories, as the new information may have changed the story's original priority.

Agile software development is often implemented as a grassroots effort in organizations by software development teams trying to optimize their development processes and ensure consistency in the software development life cycle. By not having sponsor support, teams may face difficulties and resistance from business partners, other development teams and management. Additionally, they may suffer without appropriate funding and resources.[106] This increases the likelihood of failure.[107]

A survey performed by VersionOne found respondents cited insufficient training as the most significant cause for failed agile implementations[108] Teams have fallen into the trap of assuming the reduced processes of agile software development compared to other approaches such as waterfall means that there are no actual rules for agile software development. [citation needed]

The product owner is responsible for representing the business in the development activity and is often the most demanding role.[109]

A common mistake is to fill the product owner role with someone from the development team. This requires the team to make its own decisions on prioritization without real feedback from the business. They try to solve business issues internally or delay work as they reach outside the team for direction. This often leads to distraction and a breakdown in collaboration.[110]

Agile software development requires teams to meet product commitments, which means they should focus on work for only that product. However, team members who appear to have spare capacity are often expected to take on other work, which makes it difficult for them to help complete the work to which their team had committed.[111]

Teams may fall into the trap of spending too much time preparing or planning. This is a common trap for teams less familiar with agile software development where the teams feel obliged to have a complete understanding and specification of all stories. Teams should be prepared to move forward with only those stories in which they have confidence, then during the iteration continue to discover and prepare work for subsequent iterations (often referred to as backlog refinement or grooming).

A daily standup should be a focused, timely meeting where all team members disseminate information. If problem-solving occurs, it often can involve only certain team members and potentially is not the best use of the entire team's time. If during the daily standup the team starts diving into problem-solving, it should be set aside until a sub-team can discuss, usually immediately after the standup completes.[112]

One of the intended benefits of agile software development is to empower the team to make choices, as they are closest to the problem. Additionally, they should make choices as close to implementation as possible, to use more timely information in the decision. If team members are assigned tasks by others or too early in the process, the benefits of localized and timely decision making can be lost.[113]

Being assigned work also constrains team members into certain roles (for example, team member A must always do the database work), which limits opportunities for cross-training.[113] Team members themselves can choose to take on tasks that stretch their abilities and provide cross-training opportunities.

In the Scrum framework, which claims to be consistent with agile values and principles, the scrum master role is accountable for ensuring the scrum process is followed and for coaching the scrum team through that process. A common pitfall is for a scrum master to act as a contributor. While not prohibited by the Scrum framework, the scrum master needs to ensure they have the capacity to act in the role of scrum master first and not work on development tasks. A scrum master's role is to facilitate the process rather than create the product.[114]

Having the scrum master also multitasking may result in too many context switches to be productive. Additionally, as a scrum master is responsible for ensuring roadblocks are removed so that the team can make forward progress, the benefit gained by individual tasks moving forward may not outweigh roadblocks that are deferred due to lack of capacity.[115]

Due to the iterative nature of agile development, multiple rounds of testing are often needed. Automated testing helps reduce the impact of repeated unit, integration, and regression tests and frees developers and testers to focus on higher value work.[116]

Test automation also supports continued refactoring required by iterative software development. Allowing a developer to quickly run tests to confirm refactoring has not modified the functionality of the application may reduce the workload and increase confidence that cleanup efforts have not introduced new defects.

Focusing on delivering new functionality may result in increased technical debt. The team must allow themselves time for defect remediation and refactoring. Technical debt hinders planning abilities by increasing the amount of unscheduled work as production defects distract the team from further progress.[117]

As the system evolves it is important to refactor.[118] Over time the lack of constant maintenance causes increasing defects and development costs.[117]

A common misconception is that agile software development allows continuous change, however an iteration backlog is an agreement of what work can be completed during an iteration.[119] Having too much work-in-progress (WIP) results in inefficiencies such as context-switching and queueing.[120] The team must avoid feeling pressured into taking on additional work.[121]

Agile software development fixes time (iteration duration), quality, and ideally resources in advance (though maintaining fixed resources may be difficult if developers are often pulled away from tasks to handle production incidents), while the scope remains variable. The customer or product owner often pushes for a fixed scope for an iteration. However, teams should be reluctant to commit to the locked time, resources and scope (commonly known as the project management triangle). Efforts to add scope to the fixed time and resources of agile software development may result in decreased quality.[122]

Due to the focused pace and continuous nature of agile practices, there is a heightened risk of burnout among members of the delivery team.[123]

Agile project management is an iterative development process, where feedback is continuously gathered from users and stakeholders to create the right user experience. Different methods can be used to perform an agile process, these include scrum, extreme programming, lean and kanban.[124]
The term agile management is applied to an iterative, incremental method of managing the design and build activities of engineering, information technology and other business areas that aim to provide new product or service development in a highly flexible and interactive manner, based on the principles expressed in the Manifesto for Agile Software Development.[125]
Agile project management metrics help reduce confusion, identify weak points, and measure team's performance throughout the development cycle. Supply chain agility is the ability of a supply chain to cope with uncertainty and variability on offer and demand. An agile supply chain can increase and reduce its capacity rapidly, so it can adapt to a fast-changing customer demand. Finally, strategic agility is the ability of an organisation to change its course of action as its environment is evolving. The key for strategic agility is to recognize external changes early enough and to allocate resources to adapt to these changing environments.[124]

Agile X techniques may also be called extreme project management. It is a variant of iterative life cycle[126] where deliverables are submitted in stages. The main difference between agile and iterative development is that agile methods complete small portions of the deliverables in each delivery cycle (iteration),[127] while iterative methods evolve the entire set of deliverables over time, completing them near the end of the project. Both iterative and agile methods were developed as a reaction to various obstacles that developed in more sequential forms of project organization. For example, as technology projects grow in complexity, end users tend to have difficulty defining the long-term requirements without being able to view progressive prototypes. Projects that develop in iterations can constantly gather feedback to help refine those requirements.

Agile management also offers a simple framework promoting communication and reflection on past work amongst team members.[128] Teams who were using traditional waterfall planning and adopted the agile way of development typically go through a transformation phase and often take help from agile coaches who help guide the teams through a smoother transformation. There are typically two styles of agile coaching: push-based and pull-based agile coaching. Here a "push-system" can refer to an upfront estimation of what tasks can be fitted into a sprint (pushing work) e.g. typical with scrum; whereas a "pull system" can refer to an environment where tasks are only performed when capacity is available.[129] Agile management approaches have also been employed and adapted to the business and government sectors. For example, within the federal government of the United States, the United States Agency for International Development (USAID) is employing a collaborative project management approach that focuses on incorporating collaborating, learning and adapting (CLA) strategies to iterate and adapt programming.[130]

Agile methods are mentioned in the Guide to the Project Management Body of Knowledge (PMBOK Guide 6th Edition) under the Product Development Lifecycle definition:

Within a project life cycle, there are generally one or more phases
that are associated with the development of the product, service, or result. These are called a development life cycle (...) Adaptive life cycles are agile, iterative, or incremental. The detailed scope is defined and approved before the start of an iteration. Adaptive life cycles are also referred to as agile or change-driven life cycles.[131]
According to Jean-Loup Richet (research fellow at ESSEC Institute for Strategic Innovation & Services) "this approach can be leveraged effectively for non-software products and for project management in general, especially in areas of innovation and uncertainty." The result is a product or project that best meets current customer needs and is delivered with minimal costs, waste, and time, enabling companies to achieve bottom line gains earlier than via traditional approaches.[132]

Agile software development methods have been extensively used for development of software products and some of them use certain characteristics of software, such as object technologies.[133] However, these techniques can be applied to the development of non-software products, such as computers, medical devices, food, clothing, and music.[134] Agile software development methods have been used in non-development IT infrastructure deployments and migrations. Some of the wider principles of agile software development have also found application in general management[135] (e.g., strategy, governance, risk, finance) under the terms business agility or agile business management. Agile software methodologies have also been adopted for use with the learning engineering process, an iterative data-informed process that applies the learning sciences, human-centered design, and data informed decision-making to support learners and their development.[136]

Agile software development paradigms can be used in other areas of life such as raising children. Its success in child development might be founded on some basic management principles; communication, adaptation, and awareness. In a TED Talk, Bruce Feiler shared how he applied basic agile paradigms to household management and raising children.[137]

Agile practices have been cited as potentially inefficient in large organizations and certain types of development.[138] Many organizations believe that agile software development methodologies are too extreme and adopt a hybrid approach[139] that mixes elements of agile software development and plan-driven approaches.[140] Some methods, such as dynamic systems development method (DSDM) attempt this in a disciplined way, without sacrificing fundamental principles.

The increasing adoption of agile practices has also been criticized as being a management fad that simply describes existing good practices under new jargon, promotes a one size fits all mindset towards development strategies, and wrongly emphasizes method over results.[141]

Alistair Cockburn organized a celebration of the 10th anniversary of the Manifesto for Agile Software Development in Snowbird, Utah on 12 February 2011, gathering some 30+ people who had been involved at the original meeting and since. A list of about 20 elephants in the room ('undiscussable' agile topics/issues) were collected, including aspects: the alliances, failures and limitations of agile software development practices and context (possible causes: commercial interests, decontextualization, no obvious way to make progress based on failure, limited objective evidence, cognitive biases and reasoning fallacies), politics and culture.[142] As Philippe Kruchten wrote:

The agile movement is in some ways a bit like a teenager: very self-conscious, checking constantly its appearance in a mirror, accepting few criticisms, only interested in being with its peers, rejecting en bloc all wisdom from the past, just because it is from the past, adopting fads and new jargon, at times cocky and arrogant. But I have no doubts that it will mature further, become more open to the outside world, more reflective, and therefore, more effective.
The "Manifesto" may have had a negative impact on higher education management and leadership, where it suggested to administrators that slower traditional and deliberative processes should be replaced with more "nimble" ones. The concept rarely found acceptance among university faculty.[143]

Another criticism is that in many ways, agile management and traditional management practices end up being in opposition to one another. A common criticism of this practice is that the time spent attempting to learn and implement the practice is too costly, despite potential benefits. A transition from traditional management to agile management requires total submission to agile and a firm commitment from all members of the organization to seeing the process through. Issues like unequal results across the organization, too much change for employees' ability to handle, or a lack of guarantees at the end of the transformation are just a few examples.[144]

Agile Automation
Cross-functional team
Scrum (software development)
Fail fast (business), a related subject in business management
Kanban
Agile leadership
Agile contracts
Agile software developmentSoftware project managementSoftware developmentSoftware engineeringSoftware development philosophies
CS1 maint: unfit URLWebarchive template wayback linksArticles with short descriptionShort description is different from WikidataUse dmy dates from August 2020Wikipedia articles needing clarification from December 2015Articles with excerptsAll articles with unsourced statementsArticles with unsourced statements from May 2018CS1 maint: location missing publisherArticles with BNE identifiersArticles with BNF identifiersArticles with BNFdata identifiersArticles with GND identifiersArticles with J9U identifiersArticles with LCCN identifiersArticles with NDL identifiersArticles with SUDOC identifiers






# Agile_testing.md




(Top)





1
Overview








2
Tools








3
Further reading








4
References














Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Agile testing is a software testing practice that follows the principles of agile software development. Agile testing involves all members of a cross-functional agile team, with special expertise contributed by testers, to ensure delivering the business value desired by the customer at frequent intervals, working at a sustainable pace. Specification by example is used to capture examples of desired and undesired behavior and guide coding.

Agile development recognizes that testing is not a separate phase, but an integral part of software development, along with coding. Agile teams use a "whole-team" approach to "baking quality in" to the software product. Testers on agile teams lend their expertise in eliciting examples of desired behavior from customers, collaborating with the development team to turn those into executable specifications that guide coding. Testing and coding are done incrementally and interactively, building up each feature until it provides enough value to release to production. Agile testing covers all types of testing. The Agile Testing Quadrants provide a helpful taxonomy to help teams identify and plan the testing needed.
The model of the Agile Testing Quadrants was originally described by Brian Marick,[1] and was popularized by Lisa Crispin and Janet Gregory in their book Agile Testing: A Practical Guide for Testers and Agile Teams.[2][3] It places different test types on two axis: Technology Facing vs Business Facing, and Support Programming vs Critique Product.[1]

Traditional testing methodologies (often employed in the Waterfall model of software development) usually involve a two-team, two-phase process in which the development team builds the product to as near perfection as possible. The software product is delivered late in the software development life cycle at which point the test team strives to find as many bugs/errors as possible. In contrast with these traditional methodologies, Agile testing focuses on repairing faults immediately, rather than waiting for the end of the project. When testing occurs at the tail end of a project, it can sometimes be sacrificed in terms of duration and quality to meet critical schedules and budget restrictions.[4] Costs are expected to go down as the time between development and testing feedback decreases.[4][5] With shorter feedback loops, bugs fixes and reworks require less time as developers spend much less time reengaging the code's context as they move on to new problems and projects.[4]

In the "Worldwide Software Testing Practices Report 2015 - 2016",[6] ISTQB found that the popularity of Agile methodologies are significantly increasing, which shows the need for Agile testing processes and techniques. They are providing an Agile Tester extension to their certification.[7]

As companies grow, agile testing teams often rely on software testing tools to solve challenges that can ultimately speed-up the release of feedback making sure.[8] Most teams look for collaboration features, automated or customized reporting and finding ways to avoid repeated efforts. Choosing the right tool will depend on the requirements of each team. Pairing up with other Agile Lifecycle Development Tools, Agile testing tools can deliver effective results by coexisting in integrated environments. Such is the case for Atlassian Marketplace and Microsoft Visual Studio.[9]

Some test management tools support Agile testing by getting teams involved earlier in the SDLC to continuously build test scenarios as stories evolve.[10] Teams often look for a solution that can deliver a combination of automated and manual testing.[11]

Janet Gregory; Lisa Crispin (2009). Agile Testing: A Practical Guide for Testers and Agile Teams. Addison-Wesley. ISBN 978-0-321-53446-0.
Gojko Adzic (2011). Specification by Example: How Successful Teams Deliver the Right Software. Manning. ISBN 978-1-61729-008-4.
Kev Martin (2016). The Agile Tester 2: Software testing in the agile world. CreateSpace. ISBN 978-1539646228.
Scott Ambler (2010). "Agile Testing and Quality Strategies: Discipline over Rhetoric". Retrieved 2010-07-15.
Alexander Tarlinder (2017). Developer Testing: Building Quality into Software. Addison-Wesley. ISBN 9780134291086.
Software testingAgile software development






# Agile_unified_process.md




(Top)





1
Discipline








2
Philosophies








3
Releases








4
See also








5
References








6
External links


















This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Agile unified process" – news · newspapers · books · scholar · JSTOR (August 2009) (Learn how and when to remove this message)
Agile unified process (AUP) is a simplified version of the rational unified process (RUP) developed by Scott Ambler.[1] It describes a simple, easy to understand approach to developing business application software using agile techniques and concepts yet still remaining true to the RUP. The AUP applies agile techniques including test-driven development (TDD), agile modeling (AM), agile change management, and database refactoring to improve productivity.

In 2011 the AUP accounted for one percent of all the agile methodologies used.[2] In 2012 the AUP was superseded by disciplined agile delivery (DAD). Since then work has ceased on evolving AUP.

Unlike the RUP, the AUP has only seven disciplines [citation needed]:

Model. Understand the business of the organization, the problem domain being addressed by the project, and identify a viable solution to address the problem domain.
Implementation. Transform model(s) into executable code and perform a basic level of testing, in particular unit testing.
Test. Perform an objective evaluation to ensure quality. This includes finding defects, verifying that the system works as designed, and validating that the requirements are met.
Deployment. Plan for the delivery of the system and to execute the plan to make the system available to end users.
Configuration management. Manage access to project artifacts. This includes not only tracking artifact versions over time but also controlling and managing changes to them.
Project management. Direct the activities that take place within the project. This includes managing risks, directing people (assigning tasks, tracking progress, etc.), and coordinating with people and systems outside the scope of the project to be sure that it is delivered on time and within budget.
Environment. Support the rest of the effort by ensuring that the proper process, guidance (standards and guidelines), and tools (hardware, software, etc.) are available for the team as needed.
The Agile UP is based on the following philosophies:[3]

Your staff know what they're doing. People are not going to read detailed process documentation, but they will want some high-level guidance and/or training from time to time. The AUP product provides links to many of the details, if you are interested, but doesn't force them upon you.
Simplicity. Everything is described concisely using a handful of pages, not thousands of them.
Agility. The Agile UP conforms to the values and principles of the agile software development and the Agile Alliance.
Focus on high-value activities. The focus is on the activities which actually count, not every possible thing that could happen to you on a project.
Tool independence. You can use any toolset that you want with the Agile UP. The recommendation is that you use the tools which are best suited for the job, which are often simple tools.
You'll want to tailor the AUP to meet your own needs.
The agile unified process distinguishes between two types of iterations. A development release iteration results in a deployment to the quality-assurance and/or demo area. A production release iteration results in a deployment to the production area. This is a significant refinement to the rational unified process.



Enterprise unified process
Unified process
Agile software development
Articles with short descriptionShort description is different from WikidataArticles needing additional references from August 2009All articles needing additional referencesAll articles with unsourced statementsArticles with unsourced statements from April 2012Webarchive template wayback links






# Alistair_Cockburn.md




(Top)





1
Life and career








2
Selected publications








3
References








4
External links














This biography of a living person needs additional citations for verification. Please help by adding reliable sources. Contentious material about living persons that is unsourced or poorly sourced must be removed immediately from the article and its talk page, especially if potentially libelous.Find sources: "Alistair Cockburn" – news · newspapers · books · scholar · JSTOR (August 2015) (Learn how and when to remove this message)
Alistair CockburnAlistair Cockburn in 2007NationalityAmericanOccupationComputer programmer
Alistair Cockburn (/ˈælɪstər ˈkoʊbərn/ AL-ist-ər KOH-bərn) is an American computer scientist, known as one of the initiators of the agile movement in software development. He cosigned (with 16 others)[1] the Manifesto for Agile Software Development.[2]

Cockburn started studying the methods of object oriented (OO) software development for IBM. From 1994, he formed "Humans and Technology" in Salt Lake City. He obtained his degree in computer science at the Case Western Reserve University. In 2003, he received his PhD degree from the University of Oslo.

Cockburn helped write the Manifesto for Agile Software Development in 2001, the agile PM Declaration of Interdependence in 2005, and co-founded the International Consortium for Agile in 2009 (with Ahmed Sidky and Ash Rofail). He is a principal expositor of the use case for documenting business processes and behavioral requirements for software, and inventor of the Cockburn Scale for categorizing software projects.

The methodologies in the Crystal family (e.g., Crystal Clear), described by Alistair Cockburn, are considered examples of lightweight methodology. The Crystal family is colour-coded to signify the "weight" of methodology needed. Thus, a large project which has consequences that involve risk to human life would use the Crystal Sapphire or Crystal Diamond methods. A small project might use Crystal Clear, Crystal Yellow or Crystal Orange.

Cockburn presented his Hexagonal Architecture (2005) as a solution to problems with traditional layering, coupling and entanglement.

In 2015, Alistair launched the Heart of Agile movement which is presented as a response to the overly complex state of the Agile industry.

Surviving Object-Oriented Projects, Alistair Cockburn, 1st edition, December, 1997, Addison-Wesley Professional, ISBN 0-201-49834-0.
Writing Effective Use Cases, Alistair Cockburn, 1st edition, January, 2000, Addison-Wesley Professional, ISBN 0-201-70225-8.
Agile Software Development, Alistair Cockburn, 1st edition, December 2001, Addison-Wesley Professional, ISBN 0-201-69969-9.
Patterns for Effective Use Cases, Steve Adolph, Paul Bramble, with Alistair Cockburn, Andy Pols contributors, August 2002, Addison-Wesley Professional, ISBN 0-201-72184-8.
People and Methodologies in Software Development, Alistair Cockburn, February 2003, D.Ph. dissertation, University of Oslo Press[3]
Crystal Clear : A Human-Powered Methodology for Small Teams, Alistair Cockburn, October 2004, Addison-Wesley Professional, ISBN 0-201-69947-8.
Agile Software Development: The Cooperative Game, Alistair Cockburn, 2nd edition, October 2006, Addison-Wesley Professional, ISBN 0-321-48275-1, ISBN 978-0-321-48275-4 .
Living peopleAmerican computer programmersAmerican technology writersCockburn family1953 birthsCase Western Reserve University alumniUniversity of Oslo alumniPeople from Salt Lake CityAgile software development
Articles with short descriptionShort description matches WikidataBLP articles lacking sources from August 2015All BLP articles lacking sourcesArticles with hCardsCommons category link is on WikidataArticles with ISNI identifiersArticles with VIAF identifiersArticles with WorldCat Entities identifiersArticles with GND identifiersArticles with J9U identifiersArticles with LCCN identifiersArticles with Libris identifiersArticles with NKC identifiersArticles with NLK identifiersArticles with NTA identifiersArticles with PLWABN identifiersArticles with DBLP identifiersArticles with SUDOC identifiers






# Behavior-driven_development.md




(Top)





1
Overview








2
History








3
Principles




Toggle Principles subsection





3.1
Behavioral specifications








3.2
Specification as a ubiquitous language










4
Specialized tooling




Toggle Specialized tooling subsection





4.1
Tooling principles








4.2
Tooling examples










5
Story versus specification








6
The three amigos








7
See also








8
References














3.1
Behavioral specifications








3.2
Specification as a ubiquitous language














4.1
Tooling principles








4.2
Tooling examples


















Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Behavior-driven development (BDD) involves naming software tests using domain language to describe the behavior of the code.

BDD involves use of a domain-specific language (DSL) using natural-language constructs (e.g., English-like sentences) that can express the behavior and the expected outcomes.

Proponents claim it encourages collaboration among developers, quality assurance experts, and customer representatives in a software project.[1][2][3] It encourages teams to use conversation and concrete examples to formalize a shared understanding of how the application should behave.[4] BDD is considered an effective practice especially when the problem space is complex.[5]

BDD is considered a refinement of test-driven development (TDD).[1][2][6][7][vague][8] [9] BDD combines the techniques of TDD with ideas from domain-driven design and object-oriented analysis and design to provide software development and management teams with shared tools and a shared process to collaborate on software development.[2][8]

At a high level, BDD is an idea about how software development should be managed by both business interests and technical insight. Its practice involves use of specialized tools.[6] Some tools specifically for BDD can be used for TDD. The tools automate the ubiquitous language.

BDD is a process by which DSL structured natural language statements are converted to executable tests. The result are tests that read like acceptance criteria for a given function. 

As such BDD is an extension of TDD.

BDD focuses on:

Where to start in the process
What to test and what not to test
How much to test in one go
What to call the tests
How to understand why a test fails
At its heart, BDD is about rethinking the approach to automated testing (including unit testing and acceptance testing) in order to avoid issues that naturally arise. For example, BDD suggests that unit test names be whole sentences starting with a conditional verb ("should" in English for example) and should be written in order of business value. Acceptance tests should be written using the standard agile framework of a user story: "Being a [role/actor/stakeholder] I want a [feature/capability] yielding a [benefit]". Acceptance criteria should be written in terms of scenarios and implemented in classes: Given [initial context], when [event occurs], then [ensure some outcomes] .

Starting from this point, many people developed BDD frameworks over a period of years, finally framing it in terms of a communication and collaboration framework for developers, QA and non-technical or business participants in a software project.[10] During the "Agile specifications, BDD and Testing eXchange" in November 2009 in London, Dan North[11] gave the following description of BDD:


BDD is a second-generation, outside-in, pull-based, multiple-stakeholder, multiple-scale, high-automation, agile methodology. It describes a cycle of interactions with well-defined outputs, resulting in the delivery of working, tested software that matters.
During an interview with Dan North at GOTO Conference in 2013, Liz Keogh[12] defined BDD as:

It's using examples to talk through how an application behaves... And having conversations about those examples.
[13]
Dan North created a BDD framework, JBehave, followed by a story-level BDD framework for Ruby called RBehave[14] which was later integrated into the RSpec project.[15] He also worked with David Chelimsky, Aslak Hellesøy and others to develop RSpec and also to write "The RSpec Book: Behaviour Driven Development with RSpec, Cucumber, and Friends". The first story-based framework in RSpec was later replaced by Cucumber mainly developed by Aslak Hellesøy. Capybara, which is a part of the Cucumber testing framework is one such web-based test automation software.

BDD suggests that software tests should be named in terms of desired behavior.[6][8][1] Borrowing from agile software development the "desired behavior" in this case consists of the requirements set by the business — that is, the desired behavior that has business value for whatever entity commissioned the software unit under construction.[6][1] Within BDD practice, this is referred to as BDD being an "outside-in" activity.[16]

TDD does not differentiate tests in terms of high-level software requirements, low-level technical details or anything in between. One way of looking at BDD therefore, is that it is an evolution of TDD which makes more specific choices.

Another BDD suggestion relates to how the desired behavior should be specified. BDD suggests using a semi-formal format for behavioral specification which is borrowed from user story specifications from the field of object-oriented analysis and design. The scenario aspect of this format may be regarded as an application of Hoare logic to behavioral specification of software using the domain-specific language.

BDD suggests that business analysts and software developers should collaborate in this area and should specify behavior in terms of user stories, which are each explicitly documented.[1][16] Each user story should, to some extent, follow the structure:[6][16]

As a: the person or role who will benefit from the feature;
I want: the feature;
so that: the benefit or value of the feature.
Given: the initial context at the beginning of the scenario, in one or more clauses;
When: the event that triggers the scenario;
Then: the expected outcome, in one or more clauses.
BDD does not require how this information is formatted, but it does suggest that a team should decide on a relatively simple, standardized format with the above elements.[6][16] In 2007, Dan North suggested a template for a textual format which is used in multiple BDD tools.[16] For example:


BDD suggested that the scenarios should be phrased declaratively rather than imperatively — in the business language, with no reference to elements of the UI through which the interactions take place.[17]

This format is referred to as the Gherkin language. The term Gherkin, however, is specific to the Cucumber, JBehave, Lettuce,[18] behave and Behat software tools.[19][20][21][22]

BDD borrows the concept of the ubiquitous language from domain driven design.[6][8] A ubiquitous language is a (semi-)formal language that is shared by all members of a software development team — both software developers and non-technical personnel.[23] The language in question is both used and developed by all team members as a common means of discussing the domain of the software in question.[23] In this way BDD becomes a vehicle for communication between all the different roles in a software project.[6][24]

A common risk with software development includes communication breakdowns between Developers and Business Stakeholders.[25] BDD uses the specification of desired behavior as a ubiquitous language for the project Team members. This is the reason that BDD insists on a semi-formal language for behavioral specification: some formality is a requirement for being a ubiquitous language.[6] In addition, having such a ubiquitous language creates a domain model of specifications, so that specifications may be reasoned about formally.[26] This model is also the basis for the different BDD-supporting software tools that are available.

The example given above establishes a user story for a software system under development. This user story identifies a stakeholder, a business effect and a business value. It also describes several scenarios, each with a precondition, trigger and expected outcome. Each of these parts is exactly identified by the more formal part of the language (the term Given might be considered a keyword, for example) and may therefore be processed in some way by a tool that understands the formal parts of the ubiquitous language.

Most BDD applications use text-based DSLs and specification approaches. However, graphical modeling of integration scenarios has also been applied successfully in practice, e.g., for testing purposes. [27]

Much like TDD, BDD may involve using specialized tooling. 

BDD requires not only test code as does TDD, but also a document that describes behavior in a more human-readable language. This requires a two-step process for executing the tests, reading and parsing the descriptions, and reading the test code and finding the corresponding test implementation to execute. This process makes BDD more laborious for developers. Proponents suggest that due to its human-readable nature the value of those documents extends to a relatively non-technical audience, and can hence serve as a communication means for describing requirements ("features").

In principle, a BDD support tool is a testing framework for software, much like the tools that support TDD. However, where TDD tools tend to be quite free-format in what is allowed for specifying tests, BDD tools are linked to the definition of the ubiquitous language.

The ubiquitous language allows business analysts to document behavioral requirements in a way that will also be understood by developers. The principle of BDD support tooling is to make these same requirements documents directly executable as a collection of tests. If this cannot be achieved because of reasons related to the technical tool that enables the execution of the specifications, then either the style of writing the behavioral requirements must be altered or the tool must be changed.[28] The exact implementation of behavioral requirements varies per tool, but agile practice has come up with the following general process:

The tooling reads a specification document.
The tooling directly understands completely formal parts of the ubiquitous language (such as the Given keyword in the example above). Based on this, the tool breaks each scenario up into meaningful clauses.
Each individual clause in a scenario is transformed into some sort of parameter for a test for the user story. This part requires project-specific work by the software developers.
The framework then executes the test for each scenario, with the parameters from that scenario.
Dan North has developed a number of frameworks that support BDD (including JBehave and RBehave), whose operation is based on the template that he suggested for recording user stories.[6] These tools use a textual description for use cases and several other tools (such as CBehave) have followed suit. However, this format is not required and so there are other tools that use other formats as well. For example, Fitnesse (which is built around decision tables), has also been used to roll out BDD.[29]

There are several different examples of BDD software tools in use in projects today, for different platforms and programming languages.

Possibly the most well-known is JBehave, which was developed by Dan North, Elizabeth Keogh and several others.[30] The following is an example taken from that project:[20]

Consider an implementation of the Game of Life. A domain expert (or business analyst) might want to specify what should happen when someone is setting up a starting configuration of the game grid. To do this, he might want to give an example of a number of steps taken by a person who is toggling cells. Skipping over the narrative part, he might do this by writing up the following scenario into a plain text document (which is the type of input document that JBehave reads):

The bold print is not part of the input; it is included here to show which words are recognized as formal language. JBehave recognizes the terms Given (as a precondition which defines the start of a scenario), When (as an event trigger) and Then (as a postcondition which must be verified as the outcome of the action that follows the trigger). Based on this, JBehave is capable of reading the text file containing the scenario and parsing it into clauses (a set-up clause and then three event triggers with verifiable conditions). JBehave then takes these clauses and passes them on to code that is capable of setting a test, responding to the event triggers and verifying the outcome. This code must be written by the developers in the project team (in Java, because that is the platform JBehave is based on). In this case, the code might look like this:

The code has a method for every type of clause in a scenario. JBehave will identify which method goes with which clause through the use of annotations and will call each method in order while running through the scenario. The text in each clause in the scenario is expected to match the template text given in the code for that clause (for example, a Given in a scenario is expected to be followed by a clause of the form "a X by Y game"). JBehave supports the matching of clauses to templates and has built-in support for picking terms out of the template and passing them to methods in the test code as parameters. The test code provides an implementation for each clause type in a scenario which interacts with the code that is being tested and performs a test based on the scenario. In this case:

The theGameIsRunning method reacts to a Given clause by setting up the initial game grid.
The iToggleTheCellAt method reacts to a When clause by firing off the toggle event described in the clause.
The theGridShouldLookLike method reacts to a Then clause by comparing the state of the game grid to the expected state from the scenario.
The primary function of this code is to be a bridge between a text file with a story and the code being tested. Note that the test code has access to the code being tested (in this case an instance of Game) and is very simple in nature. The test code has to be simple, otherwise a developer would end up having to write tests for his tests.

Finally, in order to run the tests, JBehave requires some plumbing code that identifies the text files which contain scenarios and which inject dependencies (like instances of Game) into the test code. This plumbing code is not illustrated here, since it is a technical requirement of JBehave and does not relate directly to the principle of BDD-style testing.

A separate subcategory of behavior-driven development is formed by tools that use specifications as an input language rather than user stories. An example of this style is the RSpec tool that was also originally developed by Dan North. Specification tools don't use user stories as an input format for test scenarios but rather use functional specifications for units that are being tested. These specifications often have a more technical nature than user stories and are usually less convenient for communication with business personnel than are user stories.[6][31] An example of a specification for a stack might look like this:

Such a specification may exactly specify the behavior of the component being tested, but is less meaningful to a business user. As a result, specification-based testing is seen in BDD practice as a complement to story-based testing and operates at a lower level. Specification testing is often seen as a replacement for free-format unit testing.[31]

Specification testing tools like RSpec and JDave are somewhat different in nature from tools like JBehave. Since they are seen as alternatives to basic unit testing tools like JUnit, these tools tend to favor forgoing the separation of story and testing code and prefer embedding the specification directly in the test code instead. For example, an RSpec test for a hashtable might look like this:[32]

This example shows a specification in readable language embedded in executable code. In this case a choice of the tool is to formalize the specification language into the language of the test code by adding methods named it and should. Also there is the concept of a specification precondition – the before section establishes the preconditions that the specification is based on.

The result of test will be:

The three amigos, also referred to as a "Specification Workshop", is a meeting where the product owner discusses the requirement in the form of specification by example with different stakeholders like the QA and development team. The key goal for this discussion is to trigger conversation and identify any missing specifications. The discussion also gives a platform for QA, development team and product owner to converge and hear out each other's perspective to enrich the requirement and also make sure if they are building the right product.[33]

The three amigos are:

Business - Role of the business user is to define the problem only and not venture into suggesting a solution
Development - Role of the developers involve suggesting ways to fix the problem
Testing - Role of testers is to question the solution, bring up as many as different possibilities for brain storming through what-if scenarios and help make the solution more precise to fix the problem.
Specification by example
Behat (PHP framework)
Cynefin framework
Concordion (Java framework)
Gauge (software)
Jasmine (JavaScript testing framework)
Squish GUI Tester (BDD GUI Testing Tool for JavaScript, Python, Perl, Ruby and Tcl)
Use case
Software designSoftware development philosophiesSoftware testing
CS1 Dutch-language sources (nl)Webarchive template wayback linksArticles with short descriptionShort description is different from WikidataAll Wikipedia articles needing clarificationWikipedia articles needing clarification from May 2015Articles with example Java code






# Build_light_indicator.md




(Top)





1
History








2
Use




Toggle Use subsection





2.1
Beyond single indicators










3
References












2.1
Beyond single indicators










The topic of this article may not meet Wikipedia's general notability guideline. Please help to demonstrate the notability of the topic by citing reliable secondary sources that are independent of the topic and provide significant coverage of it beyond a mere trivial mention. If notability cannot be shown, the article is likely to be merged, redirected, or deleted.Find sources: "Build light indicator" – news · newspapers · books · scholar · JSTOR (August 2012) (Learn how and when to remove this message)
A build light indicator is a simple visual indicator used in Agile software development to inform a team of software developers about the current status of their project. The actual object used can vary from a pressure gauge to a lava lamp, but its purpose remains the same: to quickly communicate whether a software process (such as a 'build') is successful or not.

The build light indicator originated from CruiseControl,[citation needed] a continuous integration tool created by employees of ThoughtWorks. Though it primarily functioned as a web page dashboard that could report more detailed information about a build, the software could also control external devices for simpler reporting.[1]

The traditional use of a build light is to determine the success of a software build in a continuous integration (CI) system.[2] Different development teams have used different indicators, but a popular choice is the green and red lava lamp – green when the build is successful and red when something is wrong.[3] Build lights may even be remotely accessible through a webcam or other means.[4] However, since many of the tests in busy development offices will always be in a state of re-test after the latest changes, some indicators have a three state display[2] – pass, fail and being re-tested, to provide a more nuanced indicator for staff and managers.[5]

With the growth from continuous integration to continuous testing, the number of simultaneous build targets may increase, even for a single codebase. As well as a simple build (i.e. compilation) target, there will now be unit testing and various levels of system testing. As extensive tests are slow and it is desirable to keep fast tests running on a fast cycle to give rapid feedback to the developers, the number of build targets may increase to fifty or more. This is too many to show with a simple lava lamp display. Integration servers like Jenkins offer a web-accessible dashboard page and this may be permanently displayed on a wall-mounted flat screen monitor instead. The details of such a dashboard are too small to read across an office, but the colour changes present an overall picture of status.

With a methodology of continuous test-driven development, new tests are released before working code is developed to pass them. There is thus a period when some tests are known, and indeed required to be failing.[6] Failing tests are needed as they demonstrate the capability of the new tests to detect the situation of concern. Once the new code is developed and working, these tests begin to pass. A continuous testing environment into which new tests are released before their code thus requires two build targets: one tracks the latest code and tests, the other 'release candidate' is only updated in increments when all tests are fulfilled by passing code. For the build indicator this also implies that one of those targets will frequently be shown as "failing" its tests. As this anticipated "failure" would be misleading to naive watchers, the build indicator should either hide it or present it distinctly.

Where several code targets, such as old product versions, are still supported for CI, but are not under such active development, then a complete dashboard may become dominated by "stale" targets that rarely change. In this case a selected dashboard may be more appropriate, where only those targets that are either failing, or are recently active, are displayed. The full dashboard is available to developer's desktops, but the wall display shows only the significant highlights. Such dashboards are often coded locally by screen-scraping the main dashboard and applying relevant local filters to it, according to local needs. One drawback to a dynamic filtered dashboard, compared to a static dashboard, is that the position of icons for a particular target may shift on the screen, making it hard to read from across an office. In this case, distinctive icons, such as a product logo, may be displayed rather than simple colour blocks.

Agile software development
Webarchive template wayback linksArticles with topics of unclear notability from August 2012All articles with topics of unclear notabilityAll articles with unsourced statementsArticles with unsourced statements from April 2017Commons category link is on Wikidata






# Business_agility.md




(Top)





1
Overview








2
History








3
Topics in agile enterprise studies




Toggle Topics in agile enterprise studies subsection





3.1
Comparison with complex systems








3.2
Comparison with bureaucracies








3.3
Operating at the edge of chaos










4
See also








5
References








6
Further reading








7
External links














3.1
Comparison with complex systems








3.2
Comparison with bureaucracies








3.3
Operating at the edge of chaos




















Business agility refers to rapid, continuous, and systematic evolutionary adaptation and entrepreneurial innovation directed at gaining and maintaining competitive advantage.[1] Business agility can be sustained by maintaining and adapting the goods and services offered to meet with customer demands, adjusting to the marketplace changes in a business environment, and taking advantage of available human resources.[2]

In a business context, agility is the ability of an organization to rapidly adapt to market and environmental changes in productive and cost-effective ways. An extension of this concept is the agile enterprise, which refers to an organization that uses key principles of complex adaptive systems and complexity science to achieve success.[3] Business agility is the outcome of organizational intelligence.

Businesses which lack adaptability may be left paralyzed when faced with changing markets and environments. To counter this, business agility can be developed in the enterprise, making change a routine part of organizational life.[4] An agile enterprise may be able to nimbly adjust to and take advantage of emerging opportunities in a perpetually changing environment. The agile enterprise can be viewed as an integral component of a larger system whose activities produce a ripple effect of change within both the enterprise itself and the broader system.[5]

The discipline of enterprise architecture supports business agility through techniques including layering, separation of concerns, architecture frameworks, and the separation of dynamic and stable components. The model of hierarchical complexity—a framework for scoring the complexity of behavior—has been adapted to describe the stages of complexity in enterprise architecture.[6]

One type of enterprise architecture that supports agility is a non-hierarchical organization without a single point of control.[7] In such an organization, individuals function autonomously, constantly interact with each other to define the organization's vision and aims, maintain a common understanding of requirements, and monitor the work that needs to be done. Roles and responsibilities are not predetermined but in flux, and emerge from individuals' self-organizing activities. Projects are generated across in the enterprise and sometimes from outside affiliates. Key decisions are made collaboratively, on the spot, and on the fly. Because of this, knowledge, power, and intelligence are spread through the enterprise, making it capable of quickly recovering and adapting to the loss of any key enterprise component.

In business, projects can be complex with uncertain outcomes and goals that can change over time. Traditionally these issues were dealt with by planning experts who would attempt to pre-determine every possible detail prior to implementation; however, in many situations, even the most carefully conceived projects will be impossibly difficult to manage. Agile techniques, originating from the software development community, represent an alternative approach to the classic prescriptive planning approaches to management. The main focus of agile methods is to address the issues of complexity, uncertainty, and dynamic goals, by making planning and execution work in parallel rather than in sequence to eliminate unnecessary planning activity, and the resulting unnecessary work.

Pragmatic methods for achieving organizational agility should start from an organization's competitive bases and the organization's mission, vision, and values.[8][9] Agile methods integrate planning with execution, allowing an organization to find an optimal ordering of work tasks and to adjust to changing requirements. The major causes of chaos on a project include an incomplete understanding of project components, incomplete understanding of component interactions, and changing requirements. Sometimes requirements change as a greater understanding of the project components unfolds over time. Requirements also change due to the changing needs and wants of the stakeholders. The agile approach allows a team or organization of collective trust, competence, and motivation to implement successful projects quickly by focusing on only a small set of details in any change iteration. This is in contrast to non-agile in which all the details necessary for completion are generally taken to be foreseeable and have equal priority inside of one large iteration.

A concept of "agility" as an attribute of business organizations arose in response to the requirements of modern business to operate in predictable ways in the face of extreme complexity. In particular, software development organizations have created a specific set of techniques known as agile methods to address the problems of changing requirements, uncertain outcomes due to technological complexity, and uncertain system dynamics due to overall system complexity. Some of the ideas that have shaped thinking in the agile community arose from the studies of complexity science and the notion of complex adaptive systems (CAS).

As with CAS, the outcomes or products of agile organizations such as software teams are inherently unpredictable yet will eventually form an identifiable pattern. Despite their unpredictability, agile enterprises are thought to be best positioned to take advantage of hypercompetitive external environments.

Agile enterprises exist in corporate (e.g. W. L. Gore & Associates and Oticon), non-profit (e.g. Alcoholics Anonymous), community (e.g., Wikipedia, the Burning Man festival), and even terrorist (e.g. Al Qaeda) environments.[citation needed]

Interactions, self-organizing, co-evolution, and the edge of chaos are concepts borrowed from complexity science that can help define some of the processes that take place within an agile enterprise.

Interactions are exchanges among individuals, etc. holding a common vision and possessing the necessary resources, behaviors, competence, and experience in aggregate. They are an important driving force for agile enterprises, because new ideas, products, services, and solutions emerge from the multiple exchanges happening over time. The interactions themselves, rather than individuals or the external environment, are significant drivers of innovation and change in an agile enterprise.

Self-organizing describes the spontaneous, unchoreographed, feedback-driven exchanges that are often found within agile enterprises. Vital initiatives within the agile enterprise are not always managed by one single person; rather all parties involved collectively make decisions without guidance or management from an outside source. The creativity and innovation that arises from this self-organizing process give the agile enterprise an edge in developing (and redeveloping) products, services, and solutions for a hypercompetitive marketplace.

Co-evolution is a key process through which the enterprise learns from experience and adapts. The agile enterprise is constantly evolving in concert with (and in reaction to) external environmental factors. Products and services are in a constant state of change, because, once launched, they encounter competitors' products, regulators, suppliers, and customer responses that force adaptations. In one sense, nothing is ever completely "finished," although this does not mean that nothing is ever made, produced, or launched.

The edge of chaos is a borderline region that lies between complete anarchy or randomness and a state of punctuated equilibrium. The agile enterprise ideally operates in this region, needing the tension between constant change and the constraints that weaken change efforts to keep the organization perturbed enough for innovation and success. In other words, the edge of chaos is the space in which self-organizing and co-evolution flourish.

There are several key distinctions between the agile enterprise and the traditional bureaucratic organization.

The most notable is the agile enterprise's use of fluid role definitions that allow for dynamic decision-making structures. Unlike the rigid hierarchies which characterize traditional bureaucracies, organizational structures within agile enterprises are more likely to fluidly adapt to changing business conditions, forming them into structures that support the current direction and any emergent competitive advantage.[10]

Similarly, agile enterprises do not adhere to the concept of sustained competitive advantage that typifies the bureaucratic organization. Operating in hypercompetitive, continuously changing markets, agile enterprises pursue a series of temporary competitive advantages—capitalizing for a time on the strength of an idea, product, or service then readily discarding it when no longer tenable.[11]

Lastly, the agile enterprise is populated with individuals pursuing serial incompetence;[12] they work hard to obtain a certain level of proficiency in one area but are driven to move on to the next "new" area to develop expertise. There are no subject-matter experts specializing for years in one topical area, as found typically in a traditional bureaucracy.

Although agile enterprises by definition include numerous constantly co-evolving and moving parts, they do require some structure.

The enterprise must develop specific structures (also called system constraints) to serve as a counterbalance to randomness and anarchy, keeping the enterprise optimally functioning on the edge of chaos. These structures including a shared purpose or vision, resource management aids, reward systems, and shared operating platforms. These often emerge from three key organizational processes: strategizing, organizing, and mobilizing.[13]

Strategizing is an experimental process for the agile enterprise, in which individuals repeatedly generate ideas (exploration), identify ways to capitalize on ideas (exploitation), nimbly respond to environmental feedback (adaptation), and move on to the next idea (exit).

Organizing is an ongoing activity to develop structures and communication methods that promote serial execution. It often includes defining a shared vision, as well as systems and platforms, that ground the enterprise.

Mobilizing involves managing resources, ensuring the fluid movement of people between projects, and finding ways to enhance internal and external interactions. Typically, enterprise values, personal accountability, and motivational and reward systems are a key output of this process.

Agile software development
Complex systems
Complexity
Cynefin framework
Emergence
Holacracy
Participatory organization
Self-organization
Spontaneous order
Wikinomics
Change management
All articles with unsourced statementsArticles with unsourced statements from December 2019Articles with GND identifiers






# Change_control_board.md




(Top)





1
See also








2
References










This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Change control board" – news · newspapers · books · scholar · JSTOR (December 2009) (Learn how and when to remove this message)
In software development, projects and programs, a change control board (CCB) is a committee that consists of Subject Matter Experts (SME, e.g. software engineers, testing experts, etc.) and Managers (e.g. Quality Assurance managers), who decide whether to implement proposed changes to a project.[1] The main objective of a CCB is to ensure the client accepts the project. Factors affecting a CCB's decision can include the project's phase of development, budget, schedule, and quality goals. 

Change control (see Scope management) is also part of Requirements engineering. CCBs are most associated with the waterfall method of software development, but can be seen as having analogues in some implementations of Agile software development.[2]

The Change Control Board will review any proposed changes from the original baseline requirements that were agreed upon with the client. If any change is agreed upon by the committee, the change is communicated to the project team and the client, and the requirement is baselined with the change. The authority of the Change Control Board may vary from project to project (see e.g. Consensus-based decision making), but decisions reached by the Change Control Board are often accepted as final and binding. 

A typical Change Control Board might consist of the development manager, the test lead, and a product manager. Less commonly, the client might directly advocate their interests as part of the Change Control Board.[3]

Change management (ITSM)
Change-advisory board
Project management
Requirements engineering
Configuration management
Software development processSoftware engineering stubs
Webarchive template wayback linksArticles needing additional references from December 2009All articles needing additional referencesAll stub articles






# Code_refactoring.md




(Top)





1
Motivation








2
Benefits








3
Timing and responsibility








4
Challenges








5
Testing








6
Techniques








7
Hardware refactoring








8
History








9
Automated code refactoring








10
See also








11
References








12
Further reading








13
External links
































In computer programming and software design, code refactoring is the process of restructuring existing source code—changing the factoring—without changing its external behavior. Refactoring is intended to improve the design, structure, and/or implementation of the software (its non-functional attributes), while preserving its functionality. Potential advantages of refactoring may include improved code readability and reduced complexity; these can improve the source code's maintainability and create a simpler, cleaner, or more expressive internal architecture or object model to improve extensibility. Another potential goal for refactoring is improved performance; software engineers face an ongoing challenge to write programs that perform faster or use less memory.

Typically, refactoring applies a series of standardized basic micro-refactorings, each of which is (usually) a tiny change in a computer program's source code that either preserves the behavior of the software, or at least does not modify its conformance to functional requirements. Many development environments provide automated support for performing the mechanical aspects of these basic refactorings. If done well, code refactoring may help software developers discover and fix hidden or dormant bugs or vulnerabilities in the system by simplifying the underlying logic and eliminating unnecessary levels of complexity. If done poorly, it may fail the requirement that external functionality not be changed, and may thus introduce new bugs.

By continuously improving the design of code, we make it easier and easier to work with. This is in sharp contrast to what typically happens: little refactoring and a great deal of attention paid to expediently add new features. If you get into the hygienic habit of refactoring continuously, you'll find that it is easier to extend and maintain code.
Refactoring is usually motivated by noticing a code smell.[2] For example, the method at hand may be very long, or it may be a near duplicate of another nearby method. Once recognized, such problems can be addressed by refactoring the source code, or transforming it into a new form that behaves the same as before but that no longer "smells".

For a long routine, one or more smaller subroutines can be extracted; or for duplicate routines, the duplication can be removed and replaced with one shared function. Failure to perform refactoring can result in accumulating technical debt; on the other hand, refactoring is one of the primary means of repaying technical debt.[3]

There are two general categories of benefits to the activity of refactoring.

Maintainability. It is easier to fix bugs because the source code is easy to read and the intent of its author is easy to grasp.[4] This might be achieved by reducing large monolithic routines into a set of individually concise, well-named, single-purpose methods. It might be achieved by moving a method to a more appropriate class, or by removing misleading comments.
Extensibility. It is easier to extend the capabilities of the application if it uses recognizable design patterns, and it provides some flexibility where none before may have existed.[1]
Performance engineering can remove inefficiencies in programs, known as software bloat, arising from traditional software-development strategies that aim to minimize an application's development time rather than the time it takes to run. Performance engineering can also tailor software to the hardware on which it runs, for example, to take advantage of parallel processors and vector units.[5]

There are two possible times for refactoring.

Preventive refactoring – the original developer of the code makes the code more robust when it is still free of smells to prevent the formation of smells in the future.[6]
Corrective refactoring – a subsequent developer performs refactoring to correct code smells as they occur. [6]
A method that balances preventive and corrective refactoring is "shared responsibility for refactoring".
This approach splits the refactoring action into two stages and two
roles. The original developer of the code just prepares the code for refactoring, and when the code smells form, a subsequent developer carries out the actual refactoring action. [6]

Refactoring requires extracting software system structure, data models, and intra-application dependencies to get back knowledge of an existing software system.[7]
The turnover of teams implies missing or inaccurate knowledge of the current state of a system and about design decisions made by departing developers. Further code refactoring activities may require additional effort to regain this knowledge.[8]
Refactoring activities generate architectural modifications that deteriorate the structural architecture of a software system. Such deterioration affects architectural properties such as maintainability and comprehensibility which can lead to a complete re-development of software systems.
[9]

Code refactoring activities are secured with software intelligence when using tools and techniques providing data about algorithms and sequences of code execution.[10] Providing a comprehensible format for the inner-state of software system structure, data models, and intra-components dependencies is a critical element to form a high-level understanding and then refined views of what needs to be modified, and how.[11]

Automatic unit tests should be set up before refactoring to ensure routines still behave as expected.[12] Unit tests can bring stability to even large refactors when performed with a single atomic commit. A common strategy to allow safe and atomic refactors spanning multiple projects is to store all projects in a single repository, known as monorepo.[13]

With unit testing in place, refactoring is then an iterative cycle of making a small program transformation, testing it to ensure correctness, and making another small transformation. If at any point a test fails, the last small change is undone and repeated in a different way. Through many small steps the program moves from where it was to where you want it to be. For this very iterative process to be practical, the tests must run very quickly, or the programmer would have to spend a large fraction of their time waiting for the tests to finish. Proponents of extreme programming and other agile software development describe this activity as an integral part of the software development cycle.

Here are some examples of micro-refactorings; some of these may only apply to certain languages or language types. A longer list can be found in Martin Fowler's refactoring book[2][page needed] and website.[14] Many development environments provide automated support for these micro-refactorings. For instance, a programmer could click on the name of a variable and then select the "Encapsulate field" refactoring from a context menu. The IDE would then prompt for additional details, typically with sensible defaults and a preview of the code changes. After confirmation by the programmer it would carry out the required changes throughout the code.

Techniques that allow for more understanding
Program Dependence Graph - explicit representation of data and control dependencies [15]
System Dependence Graph - representation of procedure calls between PDG [16]
Software intelligence - reverse engineers the initial state to understand existing intra-application dependencies
Techniques that allow for more abstraction
Encapsulate field – force code to access the field with getter and setter methods
Generalize type – create more general types to allow for more code sharing
Replace type-checking code with state/strategy[17]
Replace conditional with polymorphism[18]
Techniques for breaking code apart into more logical pieces
Componentization breaks code down into reusable semantic units that present clear, well-defined, simple-to-use interfaces.
Extract class moves part of the code from an existing class into a new class.
Extract method, to turn part of a larger method into a new method. By breaking down code in smaller pieces, it is more easily understandable. This is also applicable to functions.
Techniques for improving names and location of code
Move method or move field – move to a more appropriate class or source file
Rename method or rename field – changing the name into a new one that better reveals its purpose
Pull up – in object-oriented programming (OOP), move to a superclass
Push down – in OOP, move to a subclass[14]
Automatic clone detection[19]
Program Dependence Graph - explicit representation of data and control dependencies [15]
System Dependence Graph - representation of procedure calls between PDG [16]
Software intelligence - reverse engineers the initial state to understand existing intra-application dependencies
Encapsulate field – force code to access the field with getter and setter methods
Generalize type – create more general types to allow for more code sharing
Replace type-checking code with state/strategy[17]
Replace conditional with polymorphism[18]
Componentization breaks code down into reusable semantic units that present clear, well-defined, simple-to-use interfaces.
Extract class moves part of the code from an existing class into a new class.
Extract method, to turn part of a larger method into a new method. By breaking down code in smaller pieces, it is more easily understandable. This is also applicable to functions.
Move method or move field – move to a more appropriate class or source file
Rename method or rename field – changing the name into a new one that better reveals its purpose
Pull up – in object-oriented programming (OOP), move to a superclass
Push down – in OOP, move to a subclass[14]
While the term refactoring originally referred exclusively to refactoring of software code, in recent years code written in hardware description languages has also been refactored. The term hardware refactoring is used as a shorthand term for refactoring of code in hardware description languages. Since hardware description languages are not considered to be programming languages by most hardware engineers,[20] hardware refactoring is to be considered a separate field from traditional code refactoring.

Automated refactoring of analog hardware descriptions (in VHDL-AMS) has been proposed by Zeng and Huss.[21] In their approach, refactoring preserves the simulated behavior of a hardware design. The non-functional measurement that improves is that refactored code can be processed by standard synthesis tools, while the original code cannot. Refactoring of digital hardware description languages, albeit manual refactoring, has also been investigated by Synopsys fellow Mike Keating.[22][23] His target is to make complex systems easier to understand, which increases the designers' productivity.

The first known use of the term "refactoring" in the published literature was in a September, 1990 article by William Opdyke and Ralph Johnson.[24]
Although refactoring code has been done informally for decades, William Griswold's 1991 Ph.D. dissertation[25]
is one of the first major academic works on refactoring functional and procedural programs, followed by William Opdyke's 1992 dissertation[26]
on the refactoring of object-oriented programs,[27] although all the theory and machinery have long been available as program transformation systems. All of these resources provide a catalog of common methods for refactoring; a refactoring method has a description of how to apply the method and indicators for when you should (or should not) apply the method.

Martin Fowler's book Refactoring: Improving the Design of Existing Code is the canonical reference. [according to whom?]

The terms "factoring" and "factoring out" have been used in this way in the Forth community since at least the early 1980s. Chapter Six of Leo Brodie's book Thinking Forth (1984)[28] is dedicated to the subject.

In extreme programming, the Extract Method refactoring technique has essentially the same meaning as factoring in Forth; to break down a "word" (or function) into smaller, more easily maintained functions.

Refactorings can also be reconstructed[29] posthoc to produce concise descriptions of complex software changes recorded in software repositories like CVS or SVN.

This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed.Find sources: "Code refactoring" – news · newspapers · books · scholar · JSTOR (July 2018) (Learn how and when to remove this message)
Many software editors and IDEs have automated refactoring support. Here is a list of a few of these editors, or so-called refactoring browsers.

DMS Software Reengineering Toolkit (Implements large-scale refactoring for C, C++, C#, COBOL, Java, PHP and other languages)
Eclipse based:
Eclipse (for Java, and to a lesser extent, C++, PHP, Ruby and JavaScript)
PyDev (for Python)
Photran (a Fortran plugin for the Eclipse IDE)
Embarcadero Delphi
IntelliJ based:
Resharper (for C#)
AppCode (for Objective-C, C and C++)
IntelliJ IDEA (for Java)
PyCharm (for Python)
WebStorm (for JavaScript)
PhpStorm (for PHP)
Android Studio (for Java and C++)
JDeveloper (for Java)
NetBeans (for Java)
Smalltalk: Most dialects include powerful refactoring tools. Many use the original refactoring browser produced in the early '90s by Ralph Johnson.
Visual Studio based:
Visual Studio (for .NET and C++)
Visual Assist (addon for Visual Studio with refactoring support for C# and C++)
Wing IDE (for Python)
Xcode (for C, Objective-C, and Swift)[30]
Qt Creator (for C++, Objective-C and QML)[31]
Eclipse (for Java, and to a lesser extent, C++, PHP, Ruby and JavaScript)
PyDev (for Python)
Photran (a Fortran plugin for the Eclipse IDE)
Resharper (for C#)
AppCode (for Objective-C, C and C++)
IntelliJ IDEA (for Java)
PyCharm (for Python)
WebStorm (for JavaScript)
PhpStorm (for PHP)
Android Studio (for Java and C++)
Visual Studio (for .NET and C++)
Visual Assist (addon for Visual Studio with refactoring support for C# and C++)
Amelioration pattern
Code review
Database refactoring
Decomposition (computer science)
Modular programming
Obfuscated code
Prefactoring
Rewrite (programming)
Separation of concerns
Software peer review
Test-driven development
Code refactoringExtreme programmingTechnology neologisms
Webarchive template wayback linksCS1 maint: bot: original URL status unknownArticles with short descriptionShort description is different from WikidataWikipedia articles needing page number citations from July 2018All articles with specifically marked weasel-worded phrasesArticles with specifically marked weasel-worded phrases from July 2018Articles needing additional references from July 2018All articles needing additional referencesArticles with Curlie linksArticles with FAST identifiersArticles with GND identifiersArticles with J9U identifiersArticles with LCCN identifiersArticles with NDL identifiersArticles with NKC identifiers






# Continuous_integration.md




(Top)





1
History








2
Practices








3
Related practices




Toggle Related practices subsection





3.1
Build automation








3.2
Atomic commits








3.3
Committing changes








3.4
Testing locally








3.5
Continuous delivery and continuous deployment








3.6
Version control








3.7
Automate the build








3.8
Commit frequently








3.9
Daily build








3.10
Every commit should be built








3.11
Every bug-fix commit should come with a test case








3.12
Keep the build fast








3.13
Test in a clone of the production environment








3.14
Make it easy to get the latest deliverables








3.15
Everyone can see the results of the latest build








3.16
Automate deployment










4
Benefits








5
Risks








6
See also








7
References








8
External links














3.1
Build automation








3.2
Atomic commits








3.3
Committing changes








3.4
Testing locally








3.5
Continuous delivery and continuous deployment








3.6
Version control








3.7
Automate the build








3.8
Commit frequently








3.9
Daily build








3.10
Every commit should be built








3.11
Every bug-fix commit should come with a test case








3.12
Keep the build fast








3.13
Test in a clone of the production environment








3.14
Make it easy to get the latest deliverables








3.15
Everyone can see the results of the latest build








3.16
Automate deployment
















































This article includes a list of general references, but it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations. (July 2016) (Learn how and when to remove this message)


Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Continuous integration (CI) is the practice of integrating source code changes frequently and ensuring that the integrated codebase is in a workable state.

Typically, developers merge changes to an integration branch, and an automated system builds and tests the software system.[1] 
Often, the automated process runs on each commit or runs on a schedule such as once a day. 

Grady Booch first proposed the term CI in 1991,[2] although he did not advocate integrating multiple times a day, but later, CI came to include that aspect.[3]

This section needs expansion. You can help by adding to it. (August 2014)
The earliest known work on continuous integration was the Infuse environment developed by G. E. Kaiser, D. E. Perry, and W. M. Schell.[4]

In 1994, Grady Booch used the phrase continuous integration in Object-Oriented Analysis and Design with Applications (2nd edition)[5] to explain how, when developing using micro processes, "internal releases represent a sort of continuous integration of the system, and exist to force closure of the micro process".

In 1997, Kent Beck and Ron Jeffries invented extreme programming (XP) while on the Chrysler Comprehensive Compensation System project, including continuous integration.[1][self-published source] Beck published about continuous integration in 1998, emphasising the importance of face-to-face communication over technological support.[6] In 1999, Beck elaborated more in his first full book on Extreme Programming.[7] CruiseControl, one of the first open-source CI tools,[8][self-published source] was released in 2001.

In 2010, Timothy Fitz published an article detailing how IMVU's engineering team had built and been using the first practical CI system. While his post was originally met with skepticism, it quickly caught on and found widespread adoption[9] as part of the lean software development methodology, also based on IMVU.

The core activities of CI are developers co-locate code changes in a shared, integration area frequently and that the resulting integrated codebase is verified for correctness. The first part generally involves merging changes to a common version control branch. The second part generally involves automated processes including: building, testing and many other processes.

Typically, a server builds from the integration area frequently; i.e. after each commit or periodically like once a day. The server may perform quality control checks such as running unit tests[10] and collect software quality metrics via processes such as static analysis and performance testing.

This section contains instructions, advice, or how-to content. Please help rewrite the content so that it is more encyclopedic or move it to Wikiversity, Wikibooks, or Wikivoyage. (May 2015)
This section lists best practices from practitioners for other practices that enhance CI.

Build automation is a best practice.[11][12]

CI requires the version control system to support atomic commits; i.e., all of a developer's changes are handled as a single commit.

When making a code change, a developer creates a branch that is a copy of the current codebase. As other changes are committed to the repository, this copy diverges from the latest version.

The longer development continues on a branch without merging to the integration branch, the greater the risk of multiple integration conflicts[13] and failures when the developer branch is eventually merged back. When developers submit code to the repository they must first update their code to reflect the changes in the repository since they took their copy. The more changes the repository contains, the more work developers must do before submitting their own changes.

Eventually, the repository may become so different from the developers' baselines that they enter what is sometimes referred to as "merge hell", or "integration hell",[14] where the time it takes to integrate exceeds the time it took to make their original changes.[15]

Proponents of CI suggest that developers should 
use test-driven development and to
ensure that all unit tests pass locally before committing to the integration branch so that one developer's work does not break another developer's copy. 

Incomplete features can be disabled before committing, using feature toggles.

Continuous delivery ensures the software checked in on an integration branch is always in a state that can be deployed to users, and continuous deployment automates the deployment process.

Continuous delivery and continuous deployment are often performed in conjunction with CI and together form a CI/CD pipeline. 

Proponents of CI recommend storing all files and information needed for building in version control, (for git a repository); that the system should be buildable from a fresh checkout and not require additional dependencies. 

Martin Fowler recommends that all developers commit to the same integration branch.[16]

Build automation tools automate building. 

Proponents of CI recommend that a single command should have the capability of building the system. 

Automation often includes automating the integration, which often includes deployment into a production-like environment. In many cases, the build script not only compiles binaries but also generates documentation, website pages, statistics and distribution media (such as Debian DEB, Red Hat RPM or Windows MSI files).

Developers can reduce the effort of resolving conflicting changes by synchronizing changes with each other frequently; at least daily. Checking in a week's worth of work risks conflict both in likelihood of occurrence and complexity to resolve. Relatively small conflicts are significantly easier to resolve than larger ones. Integrating (committing) changes at least once a day is considered good practice, and more often better.[17]

Building daily, if not more often, is generally recommended.[citation needed]

The system should build commits to the current working version to verify that they integrate correctly. A common practice is to use Automated Continuous Integration, although this may be done manually. Automated Continuous Integration employs a continuous integration server or daemon to monitor the revision control system for changes, then automatically run the build process.

When fixing a bug, it is a good practice to push a test case that reproduces the bug. This avoids the fix to be reverted, and the bug to reappear, which is known as a regression.

The build needs to complete rapidly so that if there is a problem with integration, it is quickly identified.

Having a test environment can lead to failures in tested systems when they deploy in the production environment because the production environment may differ from the test environment in a significant way. However, building a replica of a production environment is cost-prohibitive. Instead, the test environment or a separate pre-production environment ("staging") should be built to be a scalable version of the production environment to alleviate costs while maintaining technology stack composition and nuances. Within these test environments, service virtualisation is commonly used to obtain on-demand access to dependencies (e.g., APIs, third-party applications, services, mainframes, etc.) that are beyond the team's control, still evolving, or too complex to configure in a virtual test lab.

Making builds readily available to stakeholders and testers can reduce the amount of rework necessary when rebuilding a feature that doesn't meet requirements. Additionally, early testing reduces the chances that defects survive until deployment. Finding errors earlier can reduce the amount of work necessary to resolve them.

All programmers should start the day by updating the project from the repository. That way, they will all stay up to date.

It should be easy to find out whether the build breaks and, if so, who made the relevant change and what that change was.

Most CI systems allow the running of scripts after a build finishes. In most situations, it is possible to write a script to deploy the application to a live test server that everyone can look at. A further advance in this way of thinking is continuous deployment, which calls for the software to be deployed directly into production, often with additional automation to prevent defects or regressions.[18][19]

The neutrality of this section is disputed. Relevant discussion may be found on the talk page. Please do not remove this message until conditions to do so are met. (May 2016) (Learn how and when to remove this message)
This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (May 2016) (Learn how and when to remove this message)
CI benefits include:

Facilitates detecting bugs earlier
Reduces effort to find cause of bugs; if a CI test fails then changes since last good build contain causing change; if build after each change then exactly one change is the cause[1]
Avoids the chaos of integrating many changes
When a test fails or a bug is found, reverting the codebase to a good state results in fewer lost changes
Frequent availability of a known-good build for testing, demo, and release
Frequent code commit encourages modular, less complex code[20]
Quick feedback on system-wide impact of code changes
Supports collection of software metrics such as code coverage, code complexity
Risks of CI include:

Build system setup requires effort[21]
Writing and maintaining an automated test suite requires effort
Value added depends on the quality of tests[22]
High build latency (sitting in queue) limits value[22]
Implies that incomplete code should not be integrated which is counter to some developer's preferred practice[22]
Safety and mission-critical development assurance (e.g., DO-178C, ISO 26262) require documentation and review which may be difficult to achieve
Application release automation – Process of packaging and deploymentPages displaying short descriptions of redirect targets
Build light indicator – visual device used in agile software development to inform the team on the build progressPages displaying wikidata descriptions as a fallback
Comparison of continuous integration software
Continuous design – modular design process in which components can be freely substituted to improve the design, modify performance or change another feature at a later timePages displaying wikidata descriptions as a fallback
Continuous testing – process of executing automated tests as part of the software delivery pipeline to obtain immediate feedback on the business risks associated with a release candidatePages displaying wikidata descriptions as a fallback
Multi-stage continuous integration – Software development technique
Rapid application development – Concept of software development
Continuous integrationAgile software developmentExtreme programmingSoftware development process
Articles with short descriptionShort description is different from WikidataArticles lacking in-text citations from July 2016All articles lacking in-text citationsUse dmy dates from April 2022EngvarB from April 2022Articles to be expanded from August 2014All articles to be expandedArticles using small message boxesAll accuracy disputesAccuracy disputes from May 2020Articles needing cleanup from May 2015All pages needing cleanupArticles containing how-to sectionsAll articles with unsourced statementsArticles with unsourced statements from April 2012Wikipedia neutral point of view disputes from May 2016All Wikipedia neutral point of view disputesArticles needing additional references from May 2016All articles needing additional referencesPages displaying short descriptions of redirect targets via Module:Annotated linkPages displaying wikidata descriptions as a fallback via Module:Annotated linkCS1 errors: missing periodical






# DevOps.md




(Top)





1
Definition








2
History








3
Relationship to other approaches




Toggle Relationship to other approaches subsection





3.1
Agile








3.2
ArchOps








3.3
Continuous Integration and Delivery (CI/CD)








3.4
Mobile DevOps








3.5
Site-reliability engineering








3.6
Toyota production system, lean thinking, kaizen








3.7
DevSecOps, shifting security left










4
Cultural change




Toggle Cultural change subsection





4.1
Microservices








4.2
DevOps automation






4.2.1
Automation with version control












5
GitOps








6
See also








7
Notes








8
References








9
Further reading














3.1
Agile








3.2
ArchOps








3.3
Continuous Integration and Delivery (CI/CD)








3.4
Mobile DevOps








3.5
Site-reliability engineering








3.6
Toyota production system, lean thinking, kaizen








3.7
DevSecOps, shifting security left
























4.1
Microservices








4.2
DevOps automation






4.2.1
Automation with version control














4.2.1
Automation with version control




















DevOps is a methodology in the software development and IT industry. Used as a set of practices and tools, DevOps integrates and automates the work of software development (Dev) and IT operations (Ops) as a means for improving and shortening the systems development life cycle.[1] DevOps is complementary to agile software development; several DevOps aspects came from the agile way of working.

Automation is an important part of DevOps. Software programmers and architects should use "fitness functions" to keep their software in check.[2]

Other than it being a cross-functional combination (and a portmanteau) of the terms and concepts for "development" and "operations", academics and practitioners have not developed a universal definition for the term "DevOps".[a][b][c][d] Most often, DevOps is characterized by key principles: shared ownership, workflow automation, and rapid feedback.
From an academic perspective, Len Bass, Ingo Weber, and Liming Zhu—three computer science researchers from the CSIRO and the Software Engineering Institute—suggested defining DevOps as "a set of practices intended to reduce the time between committing a change to a system and the change being placed into normal production, while ensuring high quality".[6]
However, the term is used in multiple contexts. At its most successful, DevOps is a combination of specific practices, culture change, and tools.[7]

Proposals to combine software development methodologies with deployment and operations concepts began to appear in the late 80s and early 90s.[8]

Around 2007 and 2008, concerns were raised by those within the software development and IT communities that the separation between the two industries, where one wrote and created software entirely separate from those that deploy and support the software was creating a fatal level of dysfunction within the industry.[9]

In 2009, the first conference named DevOps Days was held in Ghent, Belgium. The conference was founded by Belgian consultant, project manager and agile practitioner Patrick Debois.[10][11] The conference has now spread to other countries.[12]

In 2012, a report called "State of DevOps" was first published by Alanna Brown at Puppet Labs.[13][14]

As of 2014, the annual State of DevOps report was published by Nicole Forsgren, Gene Kim, Jez Humble and others. They stated that the adoption of DevOps was accelerating.[15][16] Also in 2014, Lisa Crispin and Janet Gregory wrote the book More Agile Testing, containing a chapter on testing and DevOps.[17][18]

In 2016, the DORA metrics for throughput (deployment frequency, lead time for changes), and stability (mean time to recover, change failure rate) were published in the State of DevOps report.[13] However, the research methodology and metrics were criticized by experts.[19][20][21][22] In response to these criticisms, the 2023 State of DevOps report [23] published changes that updated the stability metric "mean time to recover" to "failed deployment recovery time" acknowledging the confusion the former metric has caused.[24]

Many of the ideas fundamental to DevOps practices are inspired by, or mirror, other well known practices such as Lean and Deming's Plan-Do-Check-Act cycle, through to The Toyota Way and the Agile approach of breaking down components and batch sizes.[25] Contrary to the "top-down" prescriptive approach and rigid framework of ITIL in the 1990s, DevOps is "bottom-up" and flexible, having been created by software engineers for their own needs.[26]

The motivations for what has become modern DevOps and several standard DevOps practices such as automated build and test, continuous integration, and continuous delivery originated in the Agile world, which dates (informally) to the 1990s, and formally to 2001. Agile development teams using methods such as extreme programming couldn't "satisfy the customer through early and continuous delivery of valuable software"[27] unless they took responsibility for operations and infrastructure for their applications, automating much of that work. Because Scrum emerged as the dominant Agile framework in the early 2000s and it omitted the engineering practices that were part of many Agile teams, the movement to automate operations and infrastructure functions splintered from Agile and expanded into what has become modern DevOps. Today, DevOps focuses on the deployment of developed software, whether it is developed using Agile oriented methodologies or other methodologies.

ArchOps presents an extension for DevOps practice, starting from software architecture artifacts, instead of source code, for operation deployment.[28] ArchOps states that architectural models are first-class entities in software development, deployment, and operations.

Automation is a core principle for achieving DevOps success and CI/CD is a critical component.[29] Plus, improved collaboration and communication between and within teams helps achieve faster time to market, with reduced risks.[30]

Mobile DevOps is a set of practices that applies the principles of DevOps specifically to the development of mobile applications. Traditional DevOps focuses on streamlining the software development process in general, but mobile development has its own unique challenges that require a tailored approach.[31] Mobile DevOps is not simply as a branch of DevOps specific to mobile app development, instead an extension and reinterpretation of the DevOps philosophy due to very specific requirements of the mobile world.

In 2003, Google developed site reliability engineering (SRE), an approach for releasing new features continuously into large-scale high-availability systems while maintaining high-quality end-user experience.[32] While SRE predates the development of DevOps, they are generally viewed as being related to each other.

Toyota production system, also known under the acronym TPS, was the inspiration for lean thinking with its focus on continuous improvement, kaizen, flow and small batches. The andon cord principle to create fast feedback, swarm and solve problems stems from TPS.[33][34]

DevSecOps is an augmentation of DevOps to allow for security practices to be integrated into the DevOps approach. Contrary to a traditional centralized security team model, each delivery team is empowered to factor in the correct security controls into their software delivery. Security practices and testing are performed earlier in the development lifecycle, hence the term "shift left". Security is tested in three main areas: static, software composition, and dynamic.

Checking software statically via static application security testing (SAST) is white-box testing with special focus on security. Depending on the programming language, different tools are needed to do such static code analysis. The software composition is analyzed, especially libraries, and the version of each component is checked against vulnerability lists published by CERT and other expert groups. When giving software to clients, library licenses and their match to the license of the software distributed are in focus, especially copyleft licenses.

In dynamic testing, also called black-box testing, software is tested without knowing its inner functions. In DevSecOps this practice may be referred to as dynamic application security testing (DAST) or penetration testing. The goal is early detection of defects including cross-site scripting and SQL injection vulnerabilities. Threat types are published by the open web application security project, e.g. its TOP10,[35] and by other bodies. 

DevSecOps has also been described as a cultural shift involving a holistic approach to producing secure software by integrating security education, security by design, and security automation.[36]

DevOps initiatives can create cultural changes in companies[37] by transforming the way operations, developers, and testers collaborate during the development and delivery processes.[38] Getting these groups to work cohesively is a critical challenge in enterprise DevOps adoption.[39][40] DevOps is as much about culture as it is about the toolchain.[41]

Although in principle it is possible to practice DevOps with any architectural style, the microservices architectural style is becoming the standard for building continuously deployed systems. Small size service allows the architecture of an individual service to emerge through continuous refactoring.[42]

It also supports consistency, reliability, and efficiency within the organization, and is usually enabled by a shared code repository or version control. As DevOps researcher Ravi Teja Yarlagadda hypothesizes, "Through DevOps, there is an assumption that all functions can be carried out, controlled, and managed in a central place using a simple code."[43]

Many organizations use version control to power DevOps automation technologies like virtual machines, containerization (or OS-level virtualization), and CI/CD. The paper "DevOps: development of a toolchain in the banking domain" notes that with teams of developers working on the same project, "All developers need to make changes to the same codebase and sometimes edit even the same files. For efficient working, there has to be a system that helps engineers avoid conflicts and retain the codebase history,"[44] with the Git version control system and the GitHub platform referenced as examples.

GitOps evolved from DevOps. The specific state of deployment configuration is version-controlled. Because the most popular version-control is Git, GitOps' approach has been named after Git. Changes to configuration can be managed using code review practices, and can be rolled back using version-controlling. Essentially, all of the changes to a code are tracked, bookmarked, and making any updates to the history can be made easier. As explained by Red Hat, "visibility to change means the ability to trace and reproduce issues quickly, improving overall security."[45]

DataOps
DevOps toolchain
Twelve-factor app
Infrastructure as code
Lean software development
Site reliability engineering
Value stream
List of build automation software

^ Dyck et al. (2015) "To our knowledge, there is no uniform definition for the terms release engineering and DevOps. As a consequence, many people use their own definitions or rely on others, which results in confusion about those terms."[3]

^ Jabbari et al. (2016) "The research results of this study showed the need for a definition as individual studies do not consistently define DevOps."[4]

^ Erich et al. (2017) "We noticed that there are various gaps in the study of DevOps: There is no consensus of what concepts DevOps covers, nor how DevOps is defined."[5]

^ Erich et al. (2017) "We discovered that there exists little agreement about the characteristics of DevOps in the academic literature."[5]


Agile software developmentSoftware development processInformation technology managementSoftware development
CS1 errors: missing periodicalArticles with short descriptionShort description is different from WikidataWikipedia pending changes protected pagesCS1 maint: location missing publisher






# Disciplined_agile_delivery.md




(Top)





1
History








2
Key aspects




Toggle Key aspects subsection





2.1
People-first








2.2
Hybrid








2.3
Full delivery lifecycle








2.4
Support for multiple lifecycles








2.5
Complete








2.6
Context-sensitive








2.7
Consumable solutions over working software








2.8
Self-organization with appropriate governance










3
Lifecycles








4
Process goals








5
Roles




Toggle Roles subsection





5.1
Primary roles








5.2
Potential supporting roles










6
References








7
Further reading












2.1
People-first








2.2
Hybrid








2.3
Full delivery lifecycle








2.4
Support for multiple lifecycles








2.5
Complete








2.6
Context-sensitive








2.7
Consumable solutions over working software








2.8
Self-organization with appropriate governance






























5.1
Primary roles








5.2
Potential supporting roles














This article may rely excessively on sources too closely associated with the subject, potentially preventing the article from being verifiable and neutral. Please help improve it by replacing them with more appropriate citations to reliable, independent, third-party sources. (November 2019) (Learn how and when to remove this message)
Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Disciplined agile delivery (DAD) is the software development portion of the Disciplined Agile Toolkit. DAD enables teams to make simplified process decisions around incremental and iterative solution delivery. DAD builds on the many practices espoused by advocates of agile software development, including scrum, agile modeling, lean software development, and others.

The primary reference for disciplined agile delivery is the book Choose Your WoW!,[1] written by Scott Ambler and Mark Lines. WoW refers to "way of working" or "ways of working".[2]

In particular, DAD has been identified as a means of moving beyond scrum.[3] According to Cutter Senior Consultant Bhuvan Unhelkar, "DAD provides a carefully constructed mechanism that not only streamlines IT work, but more importantly, enables scaling."[4] Paul Gorans and Philippe Kruchten call for more discipline in implementation of agile approaches and indicate that DAD, as an example framework, is "a hybrid agile approach to enterprise IT solution delivery that provides a solid foundation from which to scale."[5]

Scott Ambler and Mark Lines initially led the development of DAD, and continue to lead its evolution. DAD was developed to provide a more cohesive approach to agile software development; one that tries to fill in the process gaps that are (purposely) ignored by scrum, and one that is capable of enterprise-level scale. According to Ambler, "Many agile methodologies—including scrum, XP, AM, Agile Data, kanban, and more—focus on a subset of the activities required to deliver a solution from project initiation to delivery. Before DAD was developed, you needed to cobble together your own agile methodology to get the job done."[6]

DAD was developed as a result of observing common patterns where agility was applied at scale successfully.[7]

In 2015 the Disciplined Agile (DA) framework, later to become the Disciplined Agile Toolkit, was developed.[8] This was called Disciplined Agile 2.x. DAD formed the foundation for DA.[citation needed] A second layer, disciplined DevOps, was added as was a third layer called Disciplined Agile IT (DAIT).[citation needed] These layers, respectively, addressed how to address DevOps and IT processes in an enterprise-class setting.

Disciplined Agile 3.x was released in August 2017 to introduce a fourth layer, Disciplined Agile Enterprise (DAE), to address the full process range required for business agility.[9]

In December 2018, Disciplined Agile 4, now referred to as the Disciplined Agile Toolkit, was released.[citation needed] It focused on a completely revamped description of DAD and a team-based improvement strategy called guided continuous improvement (GCI).[citation needed]

In August 2019, Disciplined Agile was acquired by Project Management Institute.[10]

Many of the challenges that teams are facing are out of scope for scrum and the teams need to look to other methods with overlapping parts and conflicting terminology. DAD attempts to address these challenges by using a people-first, learning-oriented, hybrid approach to IT solution delivery.[11]

Disciplined agile delivery (DAD) identifies that "People, and the way they interact with each other, are the primary determinant of success for a solution delivery team."[12] DAD supports a robust set of roles (see below section), rights, and responsibilities that you can tailor to meet the needs of your situation. DAD promotes the ideas that team members should collaborate closely and learn from each other, that the team should invest effort to learn from their experiences and evolve their approach, and that individuals should do so as well.[13]

DAD is a hybrid toolkit that adopts and tailors proven strategies from existing methods such as scrum, extreme programming (XP), SAFe, agile modeling (AM), Unified Process (UP), Kanban, outside-in software development, agile data (AD) and Spotify's development model. Rather than taking the time to adapt one of these existing frameworks, with DAD all of the effort of combining relevant pieces of each technique has already been done.

Unlike first generation agile methods that typically focus on the construction aspects of the lifecycle, DAD addresses the full delivery lifecycle, from team initiation all the way to delivering a solution to your end users.

DAD supports six lifecycles to choose from: agile, lean, continuous delivery, exploratory, and large-team versions of the lifecycle. DAD does not prescribe a single lifecycle because it recognizes that one approach does not fit all.

DAD shows how development, modeling, architecture, management, requirements/outcomes, documentation, governance and other strategies fit together in a streamlined whole. DAD does the "process heavy lifting" that other methods leave up to you. 

The approach is goal-driven or outcome-driven rather than prescriptive. In doing so, DAD provides contextual advice regarding viable alternatives - what works, what doesn't and more importantly why - and their trade-offs, enabling you to tailor your way of working to address the situation in which you find yourself and do so in a streamlined manner.

DAD matures focus from simply producing software to providing consumable solutions that provide real business value to stakeholders. While software is clearly an important part of the deliverable, being solution focused means taking a holistic view of the overall problem. This can lead to suggested updates in hardware, business and organizational processes, and overall organizational structures.

Agile and lean teams are self-organizing, which means that the people who do the work are the ones who plan and estimate it. They must still work in an enterprise aware manner that reflects the priorities of their organization, and to do that they will need to be governed appropriately by senior leadership.

Disciplined originally supported an agile (scrum-based) project lifecycle and a Lean (Kanban-based) project lifecycle. It has since been extended to support six lifecycles:

Agile. A three-phase project lifecycle based on scrum. The phases are Inception (what is sometimes called "Sprint 0"), Construction, and Transition (what is sometimes called a Release sprint).
Lean. A three-phase project lifecycle based on Kanban.
Continuous delivery: Agile. An Agile-based product lifecycle that supports a continuous flow of work resulting in incremental releases (typically once a week).
Continuous delivery: Lean. A lean-based product lifecycle that supports a continuous flow of work.
Exploratory. An experimentation-based lifecycle based on lean startup that has been extended to address the parallel development of minimum viable products as per the advice of cynefin.
Program. A lifecycle for coordinating a team of teams.
DAD is described as a collection of twenty-one process goals, or process outcomes.[14] These goals guides teams through a leaner process to decisions that address the context of the situation they face. It enables teams to focus on outcomes and not on process compliance and on guesswork of extending agile methods. It enables scaling by providing sophisticated-enough strategies to address the complexities you face. 


Inception phase
Construction phase
Transition phase


Get the team going in the right direction.

Incrementally build a consumable solution.

Release the solution into production.



Form Team
Align with enterprise direction
Develop common project vision
Explore scope
Identify architecture strategy
Plan the release
Develop test strategy
Develop common vision
Secure funding


Prove architecture early
Address changing stakeholder needs
Produce potentially consumable solution
Improve quality
Accelerate value delivery


Ensure production readiness
Deploy the Solution


Ongoing goals



Improve and work in an enterprise aware manner.




Grow team members
Coordinate activities
Address risk
Evolve ways of working (WoW)
Leverage and enhance existing infrastructure
Govern delivery team

Form Team
Align with enterprise direction
Develop common project vision
Explore scope
Identify architecture strategy
Plan the release
Develop test strategy
Develop common vision
Secure funding
Prove architecture early
Address changing stakeholder needs
Produce potentially consumable solution
Improve quality
Accelerate value delivery
Ensure production readiness
Deploy the Solution
Improve and work in an enterprise aware manner.

Grow team members
Coordinate activities
Address risk
Evolve ways of working (WoW)
Leverage and enhance existing infrastructure
Govern delivery team
These five primary roles[15] in the disciplined agile delivery are typically found regardless of scale.

Stakeholder. Someone who is materially impacted by the outcome of the solution. More than just an end-user or customer, this is anyone potentially affected by the development and deployment of a software project.
Product owner. The person on the team who speaks as the "one voice of the customer", representing the needs of the stakeholder community to the agile delivery team.
Team member. The team member focuses on producing the actual solution for stakeholders, including but not limited to: testing, analysis, architecture, design, programming, planning, and estimation. They will have a subset of the overall needed skills and they will strive to gain more to become generalizing specialists.
Team lead. The team lead is a host leader and also the agile coach, responsible for facilitating communication, empowering them to choose their way of working, and ensuring the team has the resources it needs and is free of obstacles.
Architecture owner. Owns the architecture decisions for the team and facilitates the creation and evolution of the overall solution design.
These supporting roles[16] are introduced (sometimes on a temporary basis) to address scaling issues.

Specialist. Although most agile team members are generalizing specialists,[17] sometimes other specialists are required depending on the needs of the project.
Domain expert. While the product owner represents a wide range of stakeholders, a domain expert is sometimes required for complex domains where a more nuanced understanding is required.
Technical expert. In cases where a particularly difficult problem is encountered, a technical expert can be brought in as needed. These could be build-masters, agile database administrators, user experience (UX) designers, or security experts.
Independent tester. Although the majority of testing is done by the DAD team members, in cases with complex domains or technology an independent testing team can be brought in to work in parallel to validate the work.
Integrator. For complex technical solutions at scale, an integrator (or multiple integrators) can be used to build the entire system from its various subsystems.
Agile software development
Articles with short descriptionShort description is different from WikidataArticles lacking reliable references from November 2019All articles lacking reliable referencesAll articles with unsourced statementsArticles with unsourced statements from July 2019






# Distributed_agile_software_development.md




(Top)





1
History / Research








2
Opportunities




Toggle Opportunities subsection





2.1
Enhanced inter and intra cultural diversity








2.2
Flexible working plans








2.3
Traversing time-zones








2.4
Individuals with incapacities and mobility limitations








2.5
Increased levels of prosperity








2.6
Reduced travel costs








2.7
Iterative idea of agile








2.8
Extensive pool of HR








2.9
Reduces office space










3
Challenges & Risks




Toggle Challenges & Risks subsection





3.1
Challenges






3.1.1
Documentation








3.1.2
Pair programming








3.1.3
Different time zones








3.1.4
Teaching








3.1.5
Distribution of work










3.2
Risks






3.2.1
Software Development Life Cycle








3.2.2
Project Management








3.2.3
Group Awareness








3.2.4
External Stakeholder Collaboration








3.2.5
Technology Setup












4
Tools and best practices




Toggle Tools and best practices subsection





4.1
Communication








4.2
Time-zone differences








4.3
Keeping up with agile practices








4.4
Use of tools






4.4.1
Communication








4.4.2
Project management








4.4.3
Development tools








4.4.4
Knowledge management












5
Compatibility with the Agile Manifesto








6
References








7
External links












2.1
Enhanced inter and intra cultural diversity








2.2
Flexible working plans








2.3
Traversing time-zones








2.4
Individuals with incapacities and mobility limitations








2.5
Increased levels of prosperity








2.6
Reduced travel costs








2.7
Iterative idea of agile








2.8
Extensive pool of HR








2.9
Reduces office space




























3.1
Challenges






3.1.1
Documentation








3.1.2
Pair programming








3.1.3
Different time zones








3.1.4
Teaching








3.1.5
Distribution of work










3.2
Risks






3.2.1
Software Development Life Cycle








3.2.2
Project Management








3.2.3
Group Awareness








3.2.4
External Stakeholder Collaboration








3.2.5
Technology Setup












3.1.1
Documentation








3.1.2
Pair programming








3.1.3
Different time zones








3.1.4
Teaching








3.1.5
Distribution of work




















3.2.1
Software Development Life Cycle








3.2.2
Project Management








3.2.3
Group Awareness








3.2.4
External Stakeholder Collaboration








3.2.5
Technology Setup




















4.1
Communication








4.2
Time-zone differences








4.3
Keeping up with agile practices








4.4
Use of tools






4.4.1
Communication








4.4.2
Project management








4.4.3
Development tools








4.4.4
Knowledge management


















4.4.1
Communication








4.4.2
Project management








4.4.3
Development tools








4.4.4
Knowledge management




















Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Distributed agile software development is a research area that considers the effects of applying the principles of agile software development to a globally distributed development setting, with the goal of overcoming challenges in projects which are geographically distributed.

The principles of agile software development provide structures to promote better communication, which is an important factor in successfully working in a distributed setting. However, not having face-to-face interaction takes away one of the core agile principles. This makes distributed agile software development more challenging than agile software development in general.

The increasing globalization with the aid of novel capabilities provided by the technological efficacy of the Internet has led software development companies to offshore their development efforts to more economically attractive areas. This phenomenon began in the 90s, while its strategic importance was realized in the 2000s.[1] Most initial related studies also date from around this time.[2]

During this time, the Agile Manifesto was released,[3] which represents an evolution from the prevailing heavyweight approaches to software development. This naturally led to the question, "can distributed software development be agile?". One of the first comprehensive reviews trying to answer this question was done in 2006.[4] By studying three organizations, they found that “careful incorporation of agility in distributed software development environments is essential in addressing several challenges to communication, control, and trust across distributed teams.” Later, in 2014, a systematic literature review (SLR) was done to identify the main problems in getting agile to work in a distributed fashion.[5] In 2019, a similar SLR was done.[6] Moreover, a general review on the subject was done in.[7] However, a 2023 systematic review found "that Distributed Scrum has no impact, positive or negative on overall project success" in distributed software development. [8]

The results of some of this research will be discussed in the section Challenges & Risks.

In all, distributed agile software development remains a highly dynamic field. Research continues to be done on all of its facets, indicating that it offers unique opportunities and advantages over more traditional methods, but not without imposing its own challenges and risks.

In the distributed environment, one might have difficulties in keeping track of everyone's workload and contribution towards the deliverable. Through adoption of agile principles and practices, the visibility is made clearer as there are multiple iterations where one can visualize the issues or criticalities on the initial stages of the project. Continuous integration of programming code, which is one of the focal pieces of agile software development, additionally serves to reduce setup of the executive issues. Adopting of agile principles appears to positively affect correspondence between groups as advancement in cycles makes it simpler for members to see the short-term objectives. Sprint reviews can be seen as a powerful method to improve external correspondence whilst they help to share data about the features and prerequisite conditions between partners or stakeholders. 
Agile practices also assist in building trust between various teams associated with the process by stimulating consistent communication and conveyance of programming deliverables. As indicated by an investigation made by Passivara, Durasiewicz and, Lassenius, the software quality and correspondence are improved and communication and coordinated effort are more regular comparatively as a result of the Scrum approach utilized in the undertaking. Additionally, the inspiration of colleagues was accounted for to have expanded.[9] Along these lines, adopting agile practices in a distributed environment has demonstrated to be valuable for the quality of the project and its execution. Thus, these can be seen as some of the advantages achieved by combining agile in distributed development,[10] however, the list is exhaustive. The main benefits can be listed as follows:

The distributed environment brings about a sense of global mindset over the local mindset, where the team can exchange and accept the other's ideas, perceptions, culture, aesthetics etc. Members from a wide range of cultures get the opportunity to gain and share knowledge from their associates, from an alternate point of view. In this manner, they can carry new plans to the task by considering out of the box.

The team members can be benefited with abundant freedom and opportunities on the way of working, with the sole aim being completing the tasks and handing in the deliverables on time. This also makes way for an expanded duty to the organization. In that way, the employees can balance both their professional and personal lives, and hence, the work-life balance can also be achieved that way.

The teams can span multiple time-zones, in this manner access as long as the 24-hour limit can be achieved. This increases productivity as people are hired all around the globe. The job to be done is never put to a halt as someone is always around to handle the issue. This also ensures the work is carried out 24/7 around the Sun and there is almost no down-time. As a distributed environment focuses more on productivity and performance, the handing-off of the work helps in accomplishing the task.

As mentioned, the distributed agile environment establishes more importance on productivity and performance, rather than presence. This benefits people with disabilities as they have the freedom to work from an environment that is comfortable for them and contribute to the deliverable. This scenario is also applicable when the employee cannot be present in office and clock-in the hours, he can work from home to complete the tasks, thus, not affecting the deliverable.

Working in a distributed agile environment ensures an enhanced level of prosperity and well-being, both of the individuals and of the company. This is because there is not much stress on only one individual to complete the work as the work is distributed to multiple people across the globe. Thus, this ensures physical and mental well-being. Also, as multiple people contribute their part and it goes through a number of iterations, the end quality of the work is enhanced, which is beneficial for the company. Hence, it is a win-win situation for both the company and its employees.

Working in a distributed environment often brings up the need for discussions and meetings on the targets, deadlines, work, etc. However, this adoption of agile principles and practices in a distributed environment helps in reducing the travel costs as it opens up the platform to communicate via video conferencing and other feasible options. This breaks down the need for physical presence, and enhances the idea of face-to-face interaction, so the meetings can be conducted from any part of the world and be made accessible to the others in the team.

As the progress of the work is in an iterative fashion, a regular check can be done to track the status of the deliverable and if all the members are on the same page in the level of understanding. Also, this way makes it easier in identifying errors and bugs and can be corrected in the earlier stages as the process goes through multiple iterations. The increased input in each stage of the work results in improved quality of deliverable.

As the same work is being carried out in different parts of the world, it increases the range of abilities of the group by getting to a more extensive pool of Human Resources worldwide. This introduces the need for all the HRs acting as one mind to enforce collaborations and decision-making in different verticals and horizontals within an organization, as well as to communicating with stakeholders and prioritizing the deliverable.

The distributed agile environment enhances the idea of remote working, hence the need for expanding office spaces to accommodate more employees is not required anymore. Also, the different work-related things like electricity, computers, car-parking lots, etc. are not of major concern as the employees have the liberty to work from their desired environment. This, in a way, is beneficial as it helps in saving a huge amount of money that would be spent on these overhead expenses otherwise. 
Iterative improvement with continuous delivery to the client is a central practice in agile software improvement, and one that legitimately identifies one of the significant difficulties of an offshore turn of events: diminished perceivability into project status. Regular physical meetings allow team leaders, project managers, clients, and customers to keep track of the progress of the project by the measure of working programming they have obtained.

Distributed software development has its own inherent challenges due to spatial, temporal, and socio-cultural differences between distributed teams. Combining it with agile principles and practices, in turn, increases the severity of the risks involved, as both methods are in direct contrast with each other. Agile software development was originally designed to be used by co-located teams, as it is based on informal communication and close collaboration. Distributed development, however, requires formal communication, clear standards, set guidelines and rigid structure.[11] This section describes the risks and challenges involved in distributed agile software development as a result of the aforementioned compatibility issues.

As a result of the incompatibility with which one is faced in combining agile principles and practices in a distributed setting, some of the challenges which can arise are as follows:[12]

Offshore organizations favor plan-driven design where detailed requirements are sent offshore to be constructed.[13] This conflicts with the common practice of agile teams who give documentation a lower priority. The result of this situation is that misunderstandings are a lot more likely to arise.

Pair programming, where two programmers work side by side to work on a particular problem is a common agile practice. It has been shown to yield better products in less time while keeping the programmers content in the process.[14] Because of the distance between teams this is a lot harder to achieve.

Depending on the time zone of each distributed team it makes it more challenging to arrange meetings at times when both teams are available. The situation can easily arise in which one team member is available and the other is not for meetings. This especially is a problem if an immediate task has components of the program which are tightly coupled, in such a case one team would not be able to proceed without the feedback of the other.

In a distributed setting the downside of not being able to practice close communication is most felt with inexperienced developers who need to go through a training phase. Training employees who are not co-located is challenging, think of the differences in background and cultural differences which make it difficult to bring these inexperienced team members up to speed. Because of this, alternative ways of teaching need to be considered.

With regards to distribution of work we want to avoid the architecture to reflect the team's geographical distribution by distributing the work based on the location. It is better to distribute tasks relating to a single user story across the whole team, thinking in terms of the stories, not the components. Over specialization by geographical location and/or component is a sign that your team is dealing badly with the communication challenges posed to the distributed teams. This over specialization has the unintended consequence of changing the product to suit the development, not the customer's requirements.[15]

A study done in 2013 has tried to consolidate the literature on risk management in distributed Agile development.[11] A more comprehensive study has tried to categorize the risk factors for distributed Agile projects in,[16] this was done utilizing both research literature and real-world experience from thirteen IT organizations. For the sake of brevity, the full list of 45 risk factors, with corresponding management techniques is omitted. Instead, a brief summary of the main categories and overall management techniques is given.

This category comprises the risk factors related to various activities of software development like customer specification of requirements and planning, modeling, construction and deployment of software application.[17] Many of the risk factors in this category stem from ineffective knowledge sharing. Unclear objectives, requirements, differences in practices of standard processes or inconsistencies across designs to name a few. Many of these risks can be managed by making sure that knowledge is shared effectively. More specifically, make sure that the objective of the project is crystal clear across teams, as well as the requirements. Automate and standardize as much of the development cycle as possible, so that each team is working with the same technology stack and infrastructure. In short, ensure that everyone is on the same page.

Project management relates to tasks such as project planning, project organizing, project staffing, project directing and control. This category involves risks due to interactions between development activities, and managerial activities. The adoption of distributed Agile development will transform the way in which the project needs to be managed. If this is not done carefully, risks might include a lower initial velocity, teams reorganizing every sprint or, a lack of uniformity in multisite team's capabilities.

Risk factors related to a lack of group awareness are grouped in this category. Group awareness requires intensive communication, coordination, collaboration, and trust among the group members. Co-located teams achieve this awareness more easily, as it flows more naturally from being in the same physical location. To manage the risks involved with a lack of group awareness, spatially dispersed teams will have to use a more disciplined approach in communication using the latest technological tools. Practices such as co-locating initially, to set the track for the project, have proved to be effective in managing risk.

These factors relate to the collaboration with customers, vendors, and third-party developers. Managing its risks boils down to making sure that the coordination and communication with these external actors are done efficiently and clearly.

Risk factors that arise due to inappropriate tool usage are grouped in this category. For example, a lack of communication structure can be solved by providing the teams with the means to do video conference calls. Besides that, choosing the right tools to use during a project is important. This can vary across projects, teams and use cases, so an analysis beforehand on the tools to use is recommended.

One of the most important factors in overcoming the challenges faced with distributed agile software development is to improve communication.[12] This means minimizing the time it takes to set up and tear down a communication session and favor video conferencing over voice conferencing if it is available.

Face-to-face contact opportunities with the whole team should be encouraged in order to help build rapport. It is beneficial to do this at the start to set out a plan to which the team can adhere throughout the project. In addition, it is also beneficial in the last few iterations before the release of the final deliverable.[15]

One option with regards to dealing with the problem of availability for meetings due to time zones is to appoint a representative for the team which serves as an intermediary for the two teams having formed good rapport with both. Another option is to use nested Scrum with multilevel reporting and multiple daily Scrum meetings.[18]

A solution for having Scrum meetings in teams which cope with time-zone differences is making a distinction between local team meetings and global Scrum meetings.[19] Each team has a local meeting at the start of their day and a global meeting at another time of the day. This is only possible if their working days have overlapping time.

Due to the distributed nature, a team might veer off of solid established agile practices. Therefore, there should be someone with the role of the coach that keeps the team on track. They should also take it upon themselves to think of alternatives for the distributed work environment using agile practices.

To keep every team member informed about the adopted agile approach, it is important to maintain documentation for the project. This improves the group collaboration in using agile principles and practices in a distributed software development setting [18]
[20]
[21] 
.[22] For this, various tools can be used which support the team in maintaining the documentation.[20]

Various tools and platforms can be used to improve communication in a distributed setting. These are even more essential than in a non-distributed setting in order to minimize the virtual distance between the distributed teams.

There are various tools available to support communication in distributed software development. Asynchronous tools like e-mail, synchronous tools like audio and video conferencing software and hybrid tools like instant messaging provide team members with the means to have the necessary meetings and communications. Another example is tools that support social networking to create a shared experience between team members across locations.

To guide the project and make sure that all teams and team members have a clear vision of what work has to be done, project management platforms like issue management tools should be used.

To provide a shared experience for every team member, every team member should have access to the same tools for their development.[23] Having the same software configuration management tools linked to project management tools enables developers to work at the same pace and communicate about the development in a similar way.

To give every team member access to the same knowledge about the product and the development, tools like Wiki software or knowledge bases can be used.

The values and principles of the Agile Manifesto have been explored in their applicability in a distributed work environment in 12 case studies.[24] The studies have followed software companies that applied distributed agile software development in their projects. Among the 12 cases, 10 onshore companies were located in the U.S. and seven offshore companies were located in India. The findings are summarized in the following table:


Characteristics promoted by the Agile Manifesto

Case 1

Case 2

Case 3

Case 4

Case 5

Case 6

Case 7

Case 8

Case 9

Case 10

Case 11

Case 12


Values


























Individuals and interactions over processes andtools

✓

✓

✓

✓

✓

✓

✓

✓

✓

✓

✓

✓


Working software over comprehensivedocumentation

✓

✓

✓

✓

✓





✓

✓

✓

✓

✓


Customer collaboration over contract negotiation







✓

✓

✓





✓








Responding to change over following a plan

x







x

x









✓




Principles


























Early and continuous delivery of valuable software

✓

✓

✓

x

x

x



✓





✓




Welcome changing requirements even late indevelopment


























Deliver working software frequently

✓

✓

✓







✓

✓

✓

✓

✓

✓


Business people and developers work togetherthroughout project

✓





✓

✓

✓





✓








Build projects around motivated individuals andsupport and trust them







✓

✓

✓



✓










Face-to-face conversation within the developmentteam

✓

✓

✓

✓

✓

✓

✓

✓

✓

✓

✓

✓


Working software is the primary measure ofprogress

✓

✓

✓

✓

✓

✓

✓



✓

✓



✓


Promote sustainable development to maintainconstant pace indefinitely



✓

✓













✓

✓

✓


Continuous attention to technical excellence andgood design





✓

✓

✓





✓



✓






Simplicity is essential





















✓




Self-organizing teams





✓







✓





✓

✓




Team regularly adjusts behavior to enhanceeffectiveness



















✓

✓



From this we learn that all case studies emphasized the first value of the Agile Manifesto which states that individuals and interactions should be valued over processes and tools. The Agile Manifesto prefers working software over comprehensive documentation without necessarily negating documentation completely. This value is also reflected in the majority of the cases. Only four cases have been identified which emphasize the importance of customer collaboration over contract negotiation. As can clearly be seen from the table the fourth value has been adopted the least out of all the values by the software companies: “instead of strictly following the agile development practices as commonly defined, the companies continuously tweak them to fit the evolving needs of their projects”.[25] With regards to agile principles it isn't a surprise that face-to-face conversation with the development team has been valued by all the studies. This was simulated electronically between the onshore and offshore teams. On whether to be open to change requirements even late in development none of the software companies in the study provided details. By this we can assume that it wasn't considered as important as some of the other principles.

Software project managementAgile software development
Articles with short descriptionShort description matches Wikidata






# Dynamic_systems_development_method.md




(Top)





1
History








2
Description




Toggle Description subsection





2.1
Principles








2.2
Core techniques








2.3
Roles








2.4
Critical success factors










3
Comparison to other development frameworks








4
See also








5
References








6
Further reading








7
External links












2.1
Principles








2.2
Core techniques








2.3
Roles








2.4
Critical success factors
























This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these template messages)

This article relies excessively on references to primary sources. Please improve this article by adding secondary or tertiary sources. Find sources: "Dynamic systems development method" – news · newspapers · books · scholar · JSTOR (March 2016) (Learn how and when to remove this message)
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Dynamic systems development method" – news · newspapers · books · scholar · JSTOR (October 2008) (Learn how and when to remove this message)

 (Learn how and when to remove this message)
This article relies excessively on references to primary sources. Please improve this article by adding secondary or tertiary sources. Find sources: "Dynamic systems development method" – news · newspapers · books · scholar · JSTOR (March 2016) (Learn how and when to remove this message)
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Dynamic systems development method" – news · newspapers · books · scholar · JSTOR (October 2008) (Learn how and when to remove this message)
Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Dynamic systems development method (DSDM) is an agile project delivery framework, initially used as a software development method.[1][2] First released in 1994, DSDM originally sought to provide some discipline to the rapid application development (RAD) method.[3] In later versions the DSDM Agile Project Framework was revised and became a generic approach to project management and solution delivery rather than being focused specifically on software development and code creation[clarification needed][citation needed] and could be used for non-IT projects.[4] The DSDM Agile Project Framework covers a wide range of activities across the whole project lifecycle and includes strong foundations and governance, which set it apart from some other Agile methods.[5] The DSDM Agile Project Framework is an iterative and incremental approach that embraces principles of Agile development, including continuous user/customer involvement.

DSDM fixes cost, quality and time at the outset and uses the MoSCoW prioritisation of scope into musts, shoulds, coulds and will not haves to adjust the project deliverable to meet the stated time constraint. DSDM is one of a number of agile methods for developing software and non-IT solutions, and it forms a part of the Agile Alliance.

In 2014, DSDM released the latest version of the method in the 'DSDM Agile Project Framework'. At the same time the new DSDM manual recognised the need to operate alongside other frameworks for service delivery (esp. ITIL) PRINCE2, Managing Successful Programmes, and PMI.[6] The previous version (DSDM 4.2) had only contained guidance on how to use DSDM with extreme programming.

In the early 1990s, rapid application development (RAD) was spreading across the IT industry. The user interfaces for software applications were moving from the old green screens to the graphical user interfaces that are used today. New application development tools were coming on the market, such as PowerBuilder. These enabled developers to share their proposed solutions much more easily with their customers – prototyping became a reality and the frustrations of the classical, sequential (waterfall) development methods could be put to one side.

However, the RAD movement was very unstructured: there was no commonly agreed definition of a suitable process and many organizations came up with their own definition and approach. Many major corporations were very interested in the possibilities but they were also concerned that they did not lose the level of quality in the end deliverables that free-flow development could give rise to

The DSDM Consortium was founded in 1994 by an association of vendors and experts in the field of software engineering and was created with the objective of "jointly developing and promoting an independent RAD framework" by combining their best practice experiences. The origins were an event organized by the Butler Group in London. People at that meeting all worked for blue-chip organizations such as British Airways, American Express, Oracle, and Logica (other companies such as Data Sciences and Allied Domecq have since been absorbed by other organizations).

In July 2006, DSDM Public Version 4.2[7] was made available for individuals to view and use; however, anyone reselling DSDM must still be a member of the not-for-profit consortium.

In 2014, the DSDM handbook was made available online and public.[8] Additionally, templates for DSDM can be downloaded.[9]

In October 2016 the DSDM Consortium rebranded as the Agile Business Consortium (ABC).[10] The Agile Business Consortium is a not-for-profit, vendor-independent organisation which owns and administers the DSDM framework.[11]

DSDM is a vendor-independent approach that recognises that more projects fail because of people problems than technology. DSDM's focus is on helping people to work effectively together to achieve the business goals. DSDM is also independent of tools and techniques enabling it to be used in any business and technical environment without tying the business to a particular vendor.[8]

There are eight principles underpinning DSDM.[12] These principles direct the team in the attitude they must take and the mindset they must adopt to deliver consistently.

Focus on the business need
Deliver on time
Collaborate
Never compromise quality
Build incrementally from firm foundations
Develop iteratively
Communicate continuously and clearly
Demonstrate control
This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (March 2016) (Learn how and when to remove this message)
Timeboxing: is the approach for completing the project incrementally by breaking it down into splitting the project in portions, each with a fixed budget and a delivery date. For each portion a number of requirements are prioritised and selected. Because time and budget are fixed, the only remaining variables are the requirements. So if a project is running out of time or money the requirements with the lowest priority are omitted. This does not mean that an unfinished product is delivered, because of the Pareto principle that 80% of the project comes from 20% of the system requirements, so as long as those most important 20% of requirements are implemented into the system, the system therefore meets the business needs and that no system is built perfectly in the first try.
MoSCoW: is a technique for prioritising work items or requirements. It is an acronym that stands for:
Must have
Should have
Could have
Won't have
Must have
Should have
Could have
Won't have
Prototyping: refers to the creation of prototypes of the system under development at an early stage of the project. It enables the early discovery of shortcomings in the system and allows future users to 'test-drive' the system. This way good user involvement is realised, one of the key success factors of DSDM, or any system development project for that matter.
Testing: helps ensure a solution of good quality, DSDM advocates testing throughout each iteration. Since DSDM is a tool and technique independent method, the project team is free to choose its own test management method.
Workshop: brings project stakeholders together to discuss requirements, functionalities and mutual understanding.
Modeling: helps visualise a business domain and improve understanding. Produces a diagrammatic representation of specific aspects of the system or business area that is being developed.
Configuration management: with multiple deliverables under development at the same time and being delivered incrementally at the end of each time-box, the deliverables need to be well managed towards completion.
This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (March 2016) (Learn how and when to remove this message)
There are some roles introduced within DSDM environment. It is important that the project members need to be appointed to different roles before they commence the project. Each role has its own responsibility. The roles are:

Executive sponsor: So called the project champion. An important role from the user organisation who has the ability and responsibility to commit appropriate funds and resources. This role has an ultimate power to make decisions.
Visionary: The one who has the responsibility to initialise the project by ensuring that essential requirements are found early on. Visionary has the most accurate perception of the business objectives of the system and the project. Another task is to supervise and keep the development process in the right track.
Ambassador user: Brings the knowledge of the user community into the project, ensures that the developers receive enough user feedback during the development process.
Advisor user: Can be any user that represents an important viewpoint and brings daily knowledge of the project.
Project manager: Can be anyone from the user community or IT staff who manages the project in general.
Technical co-ordinator: Responsible in designing the system architecture and control the technical quality of the project.
Team leader: Leads their team and ensures that the team works effectively as a whole.
Solution developer: Interpret the system requirements and model it including developing the deliverable codes and build the prototypes.
Solution tester: Checks the correctness in a technical extent by performing some testing, raise defects where necessary and retest once fixed. Tester will have to provide some comment and documentation.
Scribe: Responsible for gathering and recording the requirements, agreements, and decisions made in every workshop.
Facilitator: Responsible for managing the workshops' progress, acts as a motivator for preparation and communication.
Specialist roles: Business architect, quality manager, system integrator, etc.
Within DSDM a number of factors are identified as being of great importance to ensure successful projects.

Factor 1: First there is the acceptance of DSDM by senior management and other employees. This ensures that the different actors of the project are motivated from the start and remain involved throughout the project.
Factor 2: Directly derived from factor 1: The commitment of the management to ensure end-user involvement. The prototyping approach requires a strong and dedicated involvement by end users to test and judge the functional prototypes.
Factor 3: The project team has to be composed of skillful members that form a stable union. An important issue is the empowerment of the project team. This means that the team (or one or more of its members) has to possess the power and possibility to make important decisions regarding the project without having to write formal proposals to higher management, which can be very time-consuming. In order to enable the project team to run a successful project, they also need the appropriate technology to conduct the project. This means a development environment, project management tools, etc.
Factor 4: Finally, DSDM also states that a supportive relationship between customer and vendor is required. This goes for both projects that are realised internally within companies or by external contractors. An aid in ensuring a supporting relationship could be ISPL.
DSDM can be considered as part of a broad range of iterative and incremental development frameworks, especially those supporting agile and object-oriented methods. These include (but are not limited to) scrum, extreme programming (XP), disciplined agile delivery (DAD), and rational unified process (RUP).

Like DSDM, these share the following characteristics: 

They all prioritise requirements and work though them iteratively, building a system or product in increments.
They are tool-independent frameworks. This allows users to fill in the specific steps of the process with their own techniques[5] and software aids of choice.
The variables in the development are not time/resources, but the requirements. This approach ensures the main goals of DSDM, namely to stay within the deadline and the budget.
A strong focus on communication between and the involvement of all the stakeholders in the system. Although this is addressed in other methods, DSDM strongly believes in commitment to the project to ensure a successful outcome.
Agile software development
Lean software development
Dynamic systems development method
Webarchive template wayback linksCS1 errors: missing titleCS1 errors: bare URLArticles with short descriptionShort description matches WikidataArticles lacking reliable references from March 2016All articles lacking reliable referencesArticles needing additional references from October 2008All articles needing additional referencesArticles with multiple maintenance issuesWikipedia articles needing clarification from November 2014All articles with unsourced statementsArticles with unsourced statements from November 2014Articles needing additional references from March 2016Commons category link is on Wikidata






# Extreme_programming.md




(Top)





1
History




Toggle History subsection





1.1
Origins








1.2
Current state










2
Concept




Toggle Concept subsection





2.1
Goals








2.2
Activities






2.2.1
Coding








2.2.2
Testing








2.2.3
Listening








2.2.4
Designing










2.3
Values






2.3.1
Communication








2.3.2
Simplicity








2.3.3
Feedback








2.3.4
Courage








2.3.5
Respect










2.4
Rules








2.5
Principles






2.5.1
Feedback








2.5.2
Assuming simplicity








2.5.3
Embracing change












3
Practices




Toggle Practices subsection





3.1
Fine-scale feedback








3.2
Continuous process








3.3
Shared understanding








3.4
Programmer welfare










4
Controversial aspects




Toggle Controversial aspects subsection





4.1
Scalability








4.2
Severability and responses










5
Criticism








6
See also








7
References








8
Further reading








9
External links










1.1
Origins








1.2
Current state














2.1
Goals








2.2
Activities






2.2.1
Coding








2.2.2
Testing








2.2.3
Listening








2.2.4
Designing










2.3
Values






2.3.1
Communication








2.3.2
Simplicity








2.3.3
Feedback








2.3.4
Courage








2.3.5
Respect










2.4
Rules








2.5
Principles






2.5.1
Feedback








2.5.2
Assuming simplicity








2.5.3
Embracing change














2.2.1
Coding








2.2.2
Testing








2.2.3
Listening








2.2.4
Designing


















2.3.1
Communication








2.3.2
Simplicity








2.3.3
Feedback








2.3.4
Courage








2.3.5
Respect






















2.5.1
Feedback








2.5.2
Assuming simplicity








2.5.3
Embracing change
















3.1
Fine-scale feedback








3.2
Continuous process








3.3
Shared understanding








3.4
Programmer welfare


















4.1
Scalability








4.2
Severability and responses






















Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Extreme programming (XP) is a software development methodology intended to improve software quality and responsiveness to changing customer requirements. As a type of agile software development,[1][2][3] it advocates frequent releases in short development cycles, intended to improve productivity and introduce checkpoints at which new customer requirements can be adopted.

Other elements of extreme programming include programming in pairs or doing extensive code review, unit testing of all code, not programming features until they are actually needed, a flat management structure, code simplicity and clarity, expecting changes in the customer's requirements as time passes and the problem is better understood, and frequent communication with the customer and among programmers.[2][3][4] The methodology takes its name from the idea that the beneficial elements of traditional software engineering practices are taken to "extreme" levels. As an example, code reviews are considered a beneficial practice; taken to the extreme, code can be reviewed continuously (i.e. the practice of pair programming).

Kent Beck developed extreme programming during his work on the Chrysler Comprehensive Compensation System (C3) payroll project.[5] Beck became the C3 project leader in March 1996. He began to refine the development methodology used in the project and wrote a book on the methodology (Extreme Programming Explained, published in October 1999).[5] Chrysler cancelled the C3 project in February 2000, after seven years, when Daimler-Benz acquired the company.[6] Ward Cunningham was another major influence on XP.

Many extreme-programming practices have been around for some time; the methodology takes "best practices" to extreme levels. For example, the "practice of test-first development, planning and writing tests before each micro-increment" was used as early as NASA's Project Mercury, in the early 1960s.[7] To shorten the total development time, some formal test documents (such as for acceptance testing) have been developed in parallel with (or shortly before) the software being ready for testing. A NASA independent test group can write the test procedures, based on formal requirements and logical limits, before programmers write the software and integrate it with the hardware. XP takes this concept to the extreme level, writing automated tests (sometimes inside software modules) which validate the operation of even small sections of software coding, rather than only testing the larger features.

Two major influences shaped software development in the 1990s: 

Internally, object-oriented programming replaced procedural programming as the programming paradigm favored by some developers.
Externally, the rise of the Internet and the dot-com boom emphasized speed-to-market and company growth as competitive business factors.
Rapidly changing requirements demanded shorter product life-cycles, and often clashed with traditional methods of software development.

The Chrysler Comprehensive Compensation System (C3) started in order to determine the best way to use object technologies, using the payroll systems at Chrysler as the object of research, with Smalltalk as the language and GemStone as the data access layer. Chrysler brought in Kent Beck,[5] a prominent Smalltalk practitioner, to do performance tuning on the system, but his role expanded as he noted several problems with the development process. He took this opportunity to propose and implement some changes in development practices - based on his work with his frequent collaborator, Ward Cunningham. Beck describes the early conception of the methods:[8]

The first time I was asked to lead a team, I asked them to do a little bit of the things I thought were sensible, like testing and reviews. The second time there was a lot more on the line. I thought, "Damn the torpedoes, at least this will make a good article," [and] asked the team to crank up all the knobs to 10 on the things I thought were essential and leave out everything else.
Beck invited Ron Jeffries to the project to help develop and refine these methods. Jeffries thereafter acted as a coach to instill the practices as habits in the C3 team.

Information about the principles and practices behind XP disseminated to the wider world through discussions on the original wiki, Cunningham's WikiWikiWeb. Various contributors discussed and expanded upon the ideas, and some spin-off methodologies resulted (see agile software development). Also, XP concepts have been explained[by whom?], for several years, using a hypertext system map on the XP website at http://www.extremeprogramming.org c. 1999.

Beck edited a series of books on XP, beginning with his own Extreme Programming Explained (1999, ISBN 0-201-61641-6), spreading his ideas to a much larger audience. Authors in the series went through various aspects attending XP and its practices. The series included a book critical of the practices.

XP generated significant interest among software communities in the late 1990s and early 2000s, seeing adoption in a number of environments radically different from its origins.

The high discipline required by the original practices often went by the wayside, causing some of these practices, such as those thought too rigid, to be deprecated or reduced, or even left unfinished, on individual sites. For example, the practice of end-of-day integration tests for a particular project could be changed to an end-of-week schedule, or simply reduced to testing on mutually agreed dates. Such a more relaxed schedule could avoid people feeling rushed to generate artificial stubs just to pass the end-of-day testing. A less-rigid schedule allows, instead, the development of complex features over a period of several days.

Meanwhile, other agile-development practices have not stood still, and as of 2019[update] XP continues to evolve, assimilating more lessons from experiences in the field, to use other practices. In the second edition of Extreme Programming Explained (November 2004), five years after the first edition, Beck added more values and practices and differentiated between primary and corollary practices.

Extreme Programming Explained describes extreme programming as a software-development discipline that organizes people to produce higher-quality software more productively.

XP attempts to reduce the cost of changes in requirements by having multiple short development cycles, rather than a long one.
In this doctrine, changes are a natural, inescapable and desirable aspect of software-development projects, and should be planned for, instead of attempting to define a stable set of requirements.

Extreme programming also introduces a number of basic values, principles and practices on top of the agile methodology.

XP describes four basic activities that are performed within the software development process: coding, testing, listening, and designing. Each of those activities is described below.

The advocates of XP argue that the only truly important product of the system development process is code – software instructions that a computer can interpret. Without code, there is no working product.

Coding can be used to figure out the most suitable solution. Coding can also help to communicate thoughts about programming problems. A programmer dealing with a complex programming problem, or finding it hard to explain the solution to fellow programmers, might code it in a simplified manner and use the code to demonstrate what they mean. Code, say the proponents of this position, is always clear and concise and cannot be interpreted in more than one way. Other programmers can give feedback on this code by also coding their thoughts.

Testing is central to extreme programming.[9] Extreme programming's approach is that if a little testing can eliminate a few flaws, a lot of testing can eliminate many more flaws.

Unit tests determine whether a given feature works as intended. Programmers write as many automated tests as they can think of that might "break" the code; if all tests run successfully, then the coding is complete. Every piece of code that is written is tested before moving on to the next feature.
Acceptance tests verify that the requirements as understood by the programmers satisfy the customer's actual requirements.
System-wide integration testing was encouraged, initially, as a daily end-of-day activity, for early detection of incompatible interfaces, to reconnect before the separate sections diverged widely from coherent functionality. However, system-wide integration testing has been reduced, to weekly, or less often, depending on the stability of the overall interfaces in the system.[citation needed]

Programmers must listen to what the customers need the system to do, what "business logic" is needed. They must understand these needs well enough to give the customer feedback about the technical aspects of how the problem might be solved, or cannot be solved. Communication between the customer and programmer is further addressed in the planning game.

From the point of view of simplicity, of course one could say that system development doesn't need more than coding, testing and listening. If those activities are performed well, the result should always be a system that works. In practice, this will not work. One can come a long way without designing but at a given time one will get stuck. The system becomes too complex and the dependencies within the system cease to be clear. One can avoid this by creating a design structure that organizes the logic in the system. Good design will avoid many dependencies within a system; this means that changing one part of the system will not affect other parts of the system.[citation needed]

Extreme programming initially recognized four values in 1999: communication, simplicity, feedback, and courage. A new value, respect, was added in the second edition of Extreme Programming Explained. Those five values are described below.

Building software systems requires communicating system requirements to the developers of the system. In formal software development methodologies, this task is accomplished through documentation. Extreme programming techniques can be viewed as methods for rapidly building and disseminating institutional knowledge among members of a development team. The goal is to give all developers a shared view of the system which matches the view held by the users of the system. To this end, extreme programming favors simple designs, common metaphors, collaboration of users and programmers, frequent verbal communication, and feedback.

Extreme programming encourages starting with the simplest solution. Extra functionality can then be added later. The difference between this approach and more conventional system development methods is the focus on designing and coding for the needs of today instead of those of tomorrow, next week, or next month. This is sometimes summed up as the "You aren't gonna need it" (YAGNI) approach.[10] Proponents of XP acknowledge the disadvantage that this can sometimes entail more effort tomorrow to change the system; their claim is that this is more than compensated for by the advantage of not investing in possible future requirements that might change before they become relevant. Coding and designing for uncertain future requirements implies the risk of spending resources on something that might not be needed, while perhaps delaying crucial features. Related to the "communication" value, simplicity in design and coding should improve the quality of communication. A simple design with very simple code could be easily understood by most programmers in the team.

Within extreme programming, feedback relates to different dimensions of the system development:

Feedback from the system: by writing unit tests,[5] or running periodic integration tests, the programmers have direct feedback from the state of the system after implementing changes.
Feedback from the customer: The functional tests (aka acceptance tests) are written by the customer and the testers. They will get concrete feedback about the current state of their system. This review is planned once in every two or three weeks so the customer can easily steer the development.
Feedback from the team: When customers come up with new requirements in the planning game the team directly gives an estimation of the time that it will take to implement.
Feedback is closely related to communication and simplicity. Flaws in the system are easily communicated by writing a unit test that proves a certain piece of code will break. The direct feedback from the system tells programmers to recode this part. A customer is able to test the system periodically according to the functional requirements, known as user stories.[5] To quote Kent Beck, "Optimism is an occupational hazard of programming. Feedback is the treatment."[11]



Several practices embody courage. One is the commandment to always design and code for today and not for tomorrow. This is an effort to avoid getting bogged down in design and requiring a lot of effort to implement anything else. Courage enables developers to feel comfortable with refactoring their code when necessary.[5] This means reviewing the existing system and modifying it so that future changes can be implemented more easily. Another example of courage is knowing when to throw code away: courage to remove source code that is obsolete, no matter how much effort was used to create that source code. Also, courage means persistence: a programmer might be stuck on a complex problem for an entire day, then solve the problem quickly the next day, but only if they are persistent.

The respect value includes respect for others as well as self-respect. Programmers should never commit changes that break compilation, that make existing unit-tests fail, or that otherwise delay the work of their peers. Members respect their own work by always striving for high quality and seeking for the best design for the solution at hand through refactoring.

Adopting the four earlier values leads to respect gained from others in the team. Nobody on the team should feel unappreciated or ignored. This ensures a high level of motivation and encourages loyalty toward the team and toward the goal of the project. This value is dependent upon the other values, and is oriented toward teamwork.

The first version of rules for XP was published in 1999 by Don Wells[12] at the XP website. 29 rules are given in the categories of planning, managing, designing, coding, and testing. Planning, managing and designing are called out explicitly to counter claims that XP doesn't support those activities.

Another version of XP rules was proposed by Ken Auer[13] in XP/Agile Universe 2003. He felt XP was defined by its rules, not its practices (which are subject to more variation and ambiguity). He defined two categories: "Rules of Engagement" which dictate the environment in which software development can take place effectively, and "Rules of Play" which define the minute-by-minute activities and rules within the framework of the Rules of Engagement.

Here are some of the rules (incomplete):

Coding

The customer is always available
Code the unit test first
Only one pair integrates code at a time
Leave optimization until last
No overtime
Testing

All code must have unit tests
All code must pass all unit tests before it can be released.
When a bug is found, tests are created before the bug is addressed (a bug is not an error in logic; it is a test that was not written)
Acceptance tests are run often and the results are published
The principles that form the basis of XP are based on the values just described and are intended to foster decisions in a system development project. The principles are intended to be more concrete than the values and more easily translated to guidance in a practical situation.

Extreme programming sees feedback as most useful if it is done frequently and promptly. It stresses that minimal delay between an action and its feedback is critical to learning and making changes. Unlike traditional system development methods, contact with the customer occurs in more frequent iterations. The customer has clear insight into the system that is being developed, and can give feedback and steer the development as needed. With frequent feedback from the customer, a mistaken design decision made by the developer will be noticed and corrected quickly, before the developer spends much time implementing it.

Unit tests contribute to the rapid feedback principle. When writing code, running the unit test provides direct feedback as to how the system reacts to the changes made. This includes running not only the unit tests that test the developer's code, but running in addition all unit tests against all the software, using an automated process that can be initiated by a single command. That way, if the developer's changes cause a failure in some other portion of the system that the developer knows little or nothing about, the automated all-unit-test suite will reveal the failure immediately, alerting the developer of the incompatibility of their change with other parts of the system, and the necessity of removing or modifying their change. Under traditional development practices, the absence of an automated, comprehensive unit-test suite meant that such a code change, assumed harmless by the developer, would have been left in place, appearing only during integration testing – or worse, only in production; and determining which code change caused the problem, among all the changes made by all the developers during the weeks or even months previous to integration testing, was a formidable task.

This is about treating every problem as if its solution were "extremely simple". Traditional system development methods say to plan for the future and to code for reusability. Extreme programming rejects these ideas.

The advocates of extreme programming say that making big changes all at once does not work. Extreme programming applies incremental changes: for example, a system might have small releases every three weeks. When many little steps are made, the customer has more control over the development process and the system that is being developed.

The principle of embracing change is about not working against changes but embracing them. For instance, if at one of the iterative meetings it appears that the customer's requirements have changed dramatically, programmers are to embrace this and plan the new requirements for the next iteration.

Extreme programming has been described as having 12 practices, grouped into four areas:

Pair programming[5]
Planning game
Test-driven development
Whole team
Continuous integration
Refactoring or design improvement[5]
Small releases
Coding standards
Collective code ownership[5]
Simple design[5]
System metaphor
Sustainable pace
The practices in XP have been heavily debated.[5] Proponents of extreme programming claim that by having the on-site customer[5] request changes informally, the process becomes flexible, and saves the cost of formal overhead. Critics of XP claim this can lead to costly rework and project scope creep beyond what was previously agreed or funded.[citation needed]

Change-control boards are a sign that there are potential conflicts in project objectives and constraints between multiple users. XP's expedited methods are somewhat dependent on programmers being able to assume a unified client viewpoint so the programmer can concentrate on coding, rather than documentation of compromise objectives and constraints.[14] This also applies when multiple programming organizations are involved, particularly organizations which compete for shares of projects.[citation needed]

Other potentially controversial aspects of extreme programming include:

Requirements are expressed as automated acceptance tests rather than specification documents.
Requirements are defined incrementally, rather than trying to get them all in advance.
Software developers are usually required to work in pairs.
There is no big design up front. Most of the design activity takes place on the fly and incrementally, starting with "the simplest thing that could possibly work" and adding complexity only when it's required by failing tests. Critics characterize this as "debugging a system into appearance" and fear this will result in more re-design effort than only re-designing when requirements change.
A customer representative is attached to the project. This role can become a single-point-of-failure for the project, and some people have found it to be a source of stress. Also, there is the danger of micro-management by a non-technical representative trying to dictate the use of technical software features and architecture.
Critics have noted several potential drawbacks,[5] including problems with unstable requirements, no documented compromises of user conflicts, and a lack of an overall design specification or document.

Thoughtworks has claimed reasonable success on distributed XP projects with up to sixty people.[citation needed]

In 2004, industrial extreme programming (IXP)[15] was introduced as an evolution of XP. It is intended to bring the ability to work in large and distributed teams. It now has 23 practices and flexible values.

In 2003, Matt Stephens and Doug Rosenberg published Extreme Programming Refactored: The Case Against XP, which questioned the value of the XP process and suggested ways in which it could be improved.[6] This triggered a lengthy debate in articles, Internet newsgroups, and web-site chat areas. The core argument of the book is that XP's practices are interdependent but that few practical organizations are willing/able to adopt all the practices; therefore the entire process fails. The book also makes other criticisms, and it draws a likeness of XP's "collective ownership" model to socialism in a negative manner.

Certain aspects of XP have changed since the publication of Extreme Programming Refactored; in particular, XP now accommodates modifications to the practices as long as the required objectives are still met. XP also uses increasingly generic terms for processes. Some argue that these changes invalidate previous criticisms; others claim that this is simply watering the process down.

Other authors have tried to reconcile XP with the older methodologies in order to form a unified methodology. Some of these XP sought to replace, such as the waterfall methodology; example: Project Lifecycles: Waterfall, Rapid Application Development (RAD), and All That. JPMorgan Chase & Co. tried combining XP with the computer programming methods of capability maturity model integration (CMMI), and Six Sigma. They found that the three systems reinforced each other well, leading to better development, and did not mutually contradict.[16]

Extreme programming's initial buzz and controversial tenets, such as pair programming and continuous design, have attracted particular criticisms, such as the ones coming from McBreen,[17] Boehm and Turner,[18] Matt Stephens and Doug Rosenberg.[19] Many of the criticisms, however, are believed by Agile practitioners to be misunderstandings of agile development.[20]

In particular, extreme programming has been reviewed and critiqued by Matt Stephens's and Doug Rosenberg's Extreme Programming Refactored.[6]

Agile software development
Continuous obsolescence
EXtreme Manufacturing
Extreme project management
Extreme programming practices
Kaizen
List of software development philosophies
Pair programming
Scrum (development)
Software craftsmanship
Stand-up meeting
Timeboxing
Extreme programmingSoftware development philosophiesAgile software development
Webarchive template wayback linksCS1 errors: periodical ignoredArticles with short descriptionShort description is different from WikidataUse mdy dates from May 2021Articles with specifically marked weasel-worded phrases from August 2019Articles containing potentially dated statements from 2019All articles containing potentially dated statementsAll articles with unsourced statementsArticles with unsourced statements from January 2013Articles with unsourced statements from June 2009Articles with unsourced statements from February 2020Articles with unsourced statements from July 2008Articles with unsourced statements from August 2009Commons category link is on WikidataArticles with BNE identifiersArticles with BNF identifiersArticles with BNFdata identifiersArticles with GND identifiersArticles with J9U identifiersArticles with LCCN identifiersArticles with NKC identifiers






# Extreme_project_management.md




(Top)





1
About XPM








2
Extreme vs traditional project management








3
Mindset








4
Extreme project manager








5
Books








6
Literature








7
See also








8
References








9
External links
























This article includes a list of general references, but it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations. (December 2012) (Learn how and when to remove this message)

Extreme project management (XPM) refers to a method of managing very complex and very uncertain projects.

Extreme project management differs from traditional project management mainly in its open, elastic and nondeterministic approach. The main focus of XPM is on the human side of project management (e.g. managing project stakeholders), rather than on intricate scheduling techniques and heavy formalism.

Extreme project management corresponds to extreme programming. Advanced approaches to extreme project management utilize the principles of human interaction management to deal with the complexities of human collaboration.

The term "Extreme project management" has not been picked up by any of the international organizations developing Project Management Standards. What might be understood as a similar concept is "Agile Project Management". The ISO Standard ISO 21502:2020[1] refers to the term "agile" as a delivery approach (of products; related to project scope), and the PMBoK Standard published by the Project Management Institute refers to an "adaptive" type of development lifecycle also called "agile" or "change-driven" with regard to the product development lifecycle of a project (an element of the project lifecycle).[2]

As it is known, the software industry is a fast growing domain and in constant development and change. Despite the fact that there are plenty of methodologies and techniques used when it comes to project management, some new, and others that have been used for decades, extreme project management is one of the modern approaches to project management in this industry.

Given that requirements are constantly changing and technology is evolving very rapidly, extreme projects move forward very fast and allow for teams to work in shorter timelines, being able to better understand and approve each other's ideas and work.[3][4]

For extreme project management to produce rapid change, it is necessary for all team members to communicate and reach full understanding. This method is used during the project execution and change control process and it is not allowed to be used for overall strategy or project prioritization.[5]

To produce project plans, XPM uses a concept similar to rapid application development (RAD) called rapid application planning (RAP). Stakeholders are invited by the project manager to the RAP session where a sequence of steps (including planning the project) is run so that the best decisions are taken.[6]

Extreme project management contributes to success in three different ways:

1. With it, you manage the unknown and unpredictable.

2. It instills desire and confidence among stakeholders and it focuses on gaining and sustaining commitment to the project mission.

3. It is a holistic approach, based on reality, managed by specialists.[3]

Traditional project management is defined as an approach which assesses the project through five process groups: initiation, planning, execution, monitoring and completion.[7]

The main characteristics of a traditional project management are:

Few scope change requests
Well-understood technology infrastructure
Low risk
Experienced and skilled project teams
Plan-driven TPM projects[8]
While traditional project management is used for linear work, without any significant changes, extreme project management is ideal for fast-speed projects with unpredictable results.[3][7]

One challenge faced by the traditional approach is that most software development projects' requirements change during the project execution period.

Extreme projects are “a complex, self-correcting venture in search of a desired result” (Doug DeCarlo),[8] where requirements are constantly changing throughout the project as a response to environmental factors such as competition, technology, and economic conditions.

Extreme projects are characterized by: 

Low possibility of failure
Short deadlines
Paramount innovation
Important quality of life
Traditional project management utilizes the "waterfall method", whose purpose is to plan project activity in a straight line. In the traditional approach, each process runs linearly, resulting with what was planned from the beginning.[4][9]

The extreme approach, conversely, does not run constantly, instead adapting the project activity during the process, which leads in the final stage to a desired result.[3]
[3]
An extreme project management life cycle model is one that proceeds from phase to phase based on very limited knowledge of goal and solution. Each phase learns from the proceeding ones and redirects the next phase in an attempt to converge on an acceptable goal and solution.[10]

Fundamental to success on an extreme project is the application of both the appropriate complex method and the required mindset. 
Mindset is one of the most important and critical factors related to the extreme project management. In order to change the mindset of a team, there are some main rules for extreme approach for project management:

Chaotic project activities are normal
Uncertainty is one of the most common characteristic of an extreme project
Uncontrollable project
Spontaneous changes happen during the processes
XPM increases the security[10]
Mindset is defined as “a set of beliefs and assumptions about how the world works” (Douglas DeCarlo). Mindset is the project’s internal programming.

A quantum mindset is needed to manage extreme projects in order to provide the project team an opening to change and unpredictability.[3]

A project manager is a professional in the field of project management whose responsibility is to plan, execute and manage any project. An extreme project manager has to complete all duties and tasks at a high-speed level, following the proper extreme project methodology.

The first step of any management methodology is that extreme project managers have to meet the client or the project stakeholders. Also, a specific analysis must be made to accentuate the value being provided to the client, emphasizing the benefits the client will gain as soon as the project is over.
[11]

The extreme project manager is charged with responsibilities to the organization they represent, to the team, and to the project itself. Necessary skills include administrative credibility, political sensitivity and leadership.[12]

The main tasks that an extreme project manager has to fulfill for the project to be successful are:

negotiating
communicating with all parties
dealing with obstacles
keeping a balance between team members and motivating them[12]
One of the rules that a manager needs to know is that extreme analysis is a way for the clients to know the benefits he will gain, emphasizing its value once the project is completed.[11]

Ajani, Shaun H. Extreme Project Management: Unique Methodologies - Resolute Principles - Astounding Results
Kevin Aguanno (2005). Managing Agile Projects. Multi-Media Publications. Archived from the original on 25 June 2012. Retrieved 5 November 2012.
Doug DeCarlo Xtreme Project Management: Using Leadership and Tools to Deliver Value in the Face of Volatility
Thomsett, Rob. Radical Project Management
Wysocki, Robert K., Rudd McGary. Effective Project Management: Traditional, Adaptive, Extreme
Whitty, S.J.; Maylor, H. (2007). And then came Complex Project Management. 21st IPMA World Congress on Integrated Project Management Approach.
Agile software development
Project management by typeExtreme programming
Articles lacking in-text citations from December 2012All articles lacking in-text citationsUse dmy dates from July 2022






# Fail-fast_system.md




(Top)





1
Hardware and software




Toggle Hardware and software subsection





1.1
Examples










2
Business








3
See also








4
References








5
External links










1.1
Examples
















This article includes a list of general references, but it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations. (June 2016) (Learn how and when to remove this message)
In systems design, a fail-fast system is one that immediately reports at its interface any condition that is likely to indicate a failure. Fail-fast systems are usually designed to stop normal operation rather than attempt to continue a possibly flawed process. Such designs often check the system's state at several points in an operation, so that any failures can be detected early. The responsibility of a fail-fast module is detecting errors, and then letting the next-highest level of the system handle them.

Fail-fast systems or modules are desirable in several circumstances:

Fail-fast architectures are based on an error handling policy where any detected error or non-contemplated state makes the system fail (fast). In some sense, the error-handling policy is the opposite of that used in a fault-tolerant system. In a fault-tolerant system, an error handling policy is established to have redundant components and move computation requests to alive components when some component fails. Paradoxically fail-fast systems make fault-tolerant systems more resilient. We can have 10 redundant servers for a given database, but if the shared configuration for the 10 servers is updated with wrong authentication data for clients, all of them will "redundantly fail". In that sense, a fail-fast system will make sure that all the 10 redundant servers fail as soon as possible to make the DevOps react fast.
Fail-fast components are often used in situations where failure in one component might not be visible until it leads to failure in another component as a consequence of lazy initialization. e.g. "The system that is "doomed" to fail because a file-system path is wrongly set up, does it not fail at startup because the file-system path is not checked at startup. Only when a client-request arrives the system fails, at random, later on.
Finding the cause of a failure is easier in a fail-fast system because the system reports the failure with as much information as possible as close to the time of failure as possible. In a fault-tolerant system, the failure might go undetected, whereas in a system that is neither fault-tolerant nor fail-fast, the failure might be temporarily hidden until it causes some seemingly unrelated problem later.
A fail-fast system that is designed to halt as well as report the error on failure is less likely to erroneously perform an irreversible or costly operation.
Developers also refer to code as fail-fast if it tries to fail as soon as possible at a variable or object initialization. In object-oriented programming, a fail-fast-designed object initializes the internal state of the object in the constructor, launching an exception if something is wrong (rather than allowing non-initialized or partially initialized objects that will fail later due to a wrong "setter"). The object can then be made immutable if no more changes to the internal state are expected. In functions, fail-fast code will check input parameters in the precondition. In client-server architectures, fail-fast will check the client request just upon arrival, before processing or redirecting it to other internal components, returning an error if the request fails (incorrect parameters, ...). Fail-fast-designed code decreases the internal software entropy and reduces debugging effort.

A fail-fast application/system checks that all input/output resources needed for future computations are ready before any computation request arrives.
A fail-fast application/system checks that all immutable initial configurations are correct at startup.
A fail-fast function is a function that checks all input to the function in a Precondition before proceeding with any computation or business logic in such function.
A fail-fast function will normally throw a runtime exception, when some abnormal computation, is found making the system fail if no "catch" has been contemplated by any other, versus returning some error value without making any (optimistic) assumption about the correct management of the raised error.
From the field of software engineering, a fail-fast iterator is an iterator that attempts to raise an error if the sequence of elements processed by the iterator is changed during iteration.
Given an initial state in a state machine, a fail-fast system will check such a state and fail fast.
Given a state-change in a state machine, the fail-fast system will halt the machine if the state-change is forbidden. It could be the case that the forbidden state-change is due to a wrong external input. In that case, the fail-fast system will stop processing the request as soon as the wrong input is detected (vs. delegating to the state-machine implementation).
The term has been widely employed as a metaphor in business, dating back to at least 2001,[1] meaning that businesses should undertake bold experiments to determine the long-term viability of a product or strategy, rather than proceeding cautiously and investing years in a doomed approach. It became adopted as a kind of "mantra" within startup culture, i.e. "Fail fast, fail often."[2]

Crash-only software
Design by contract
Failing badly vs. failing well
Fail-safe
Fail-stop
Fail-silent system
Engineering failuresProgramming principles
Articles with short descriptionShort description is different from WikidataArticles lacking in-text citations from June 2016All articles lacking in-text citations






# Feature-driven_development.md




(Top)





1
History








2
Overview




Toggle Overview subsection





2.1
Develop overall model








2.2
Build feature list








2.3
Plan by feature








2.4
Design by feature








2.5
Build by feature










3
Milestones








4
Best practices








5
Metamodel (Metamodelling)








6
See also








7
References








8
External links












2.1
Develop overall model








2.2
Build feature list








2.3
Plan by feature








2.4
Design by feature








2.5
Build by feature




























Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Feature-driven development (FDD) is an iterative and incremental software development process. It is a lightweight[according to whom?] or Agile method for developing software. FDD blends several industry-recognized[according to whom?] best practices into a cohesive whole. These practices are driven from a client-valued functionality (feature) perspective[clarification needed]. Its main purpose[according to whom?] is to deliver tangible, working software repeatedly in a timely manner in accordance with the Principles behind the Agile Manifesto.[1]

FDD was initially devised by Jeff De Luca to meet the specific needs of a 15-month, 50-person software development project at a large Singapore bank in 1997. This resulted in a set of five processes that covered the development of an overall model and the listing, planning, design, and building of features. The first process is heavily influenced by Peter Coad's approach to object modeling. The second process incorporates Coad's ideas of using a feature list to manage functional requirements and development tasks. The other processes are a result of Jeff De Luca's experience. There have been several implementations of FDD since its successful use on the Singapore project.

The description of FDD was first introduced to the world in Chapter 6 of the book Java modelling in Color with UML[1] by Peter Coad, Eric Lefebvre, and Jeff De Luca in 1999. Later, in Stephen Palmer and Mac Felsing's book A Practical Guide to Feature-Driven Development[2] (published in 2002), a more general description of FDD was given decoupled from Java modelling.

FDD is a model-driven short-iteration process that consists of five basic activities. For accurate state reporting and keeping track of the software development project, milestones that mark the progress made on each feature are defined. This section gives a high-level overview of the activities. In the figure on the right, the meta-process model for these activities is displayed. During the first two sequential activities, an overall model shape is established. The final three activities are iterated for each feature.

The FDD project starts with a high-level walkthrough of the scope of the system and its context. Next, detailed domain models are created for each modelling area by small groups and presented for peer review. One or more of the proposed models are selected to become the model for each domain area. Domain area models are progressively merged into an overall model.

Knowledge gathered during the initial modeling is used to identify a list of features by functionally decomposing the domain into subject areas. Subject areas each contain business activities, and the steps within each business activity form the basis for a categorized feature list. Features in this respect are small pieces of client-valued functions expressed in the form "  ", for example: 'Calculate the total of a sale' or 'Validate the password of a user'. Features should not take more than two weeks to complete, else they should be broken down into smaller pieces.

After the feature list is completed, the next step is to produce the development plan and assign ownership of features (or feature sets) as classes to programmers.

A design package is produced for each feature. A chief programmer selects a small group of features that are to be developed within two weeks. Together with the corresponding class owners, the chief programmer works out detailed sequence diagrams for each feature and refines the overall model. Next, the class and method prologues are written, and finally a design inspection is held.

After a successful design inspection for each activity to produce a feature is planned, the class owners develop code for their classes. After unit testing and successful code inspection, the completed feature is promoted to the main build.

Since features are small, completing a feature is a relatively small task. For accurate state reporting and keeping track of the software development project, it is important to mark the progress made on each feature. FDD therefore defines six milestones per feature that are to be completed sequentially. The first three milestones are completed during the Design By Feature activity, and the last three are completed during the Build By Feature activity. To track progress, a percentage complete is assigned to each milestone. In the table below the milestones and their completion percentage are shown. At the point that coding begins, a feature is already 44% complete (Domain Walkthrough 1%, Design 40% and Design Inspection 3% = 44%).


Domain Walkthrough

Design

Design Inspection

Code

Code Inspection

Promote To Build


1%

40%

3%

45%

10%

1%

Feature-driven development is built on a core set of software engineering best practices aimed at a client-valued feature perspective.

Domain Object modelling. Domain Object modeling consists of exploring and explaining the domain of the problem to be solved. The resulting domain object model provides an overall framework in which to add features.
Developing by Feature. Any function that is too complex to be implemented within two weeks is further decomposed into smaller functions until each sub-problem is small enough to be called a feature. This makes it easier to deliver correct functions and to extend or modify the system.
Individual Class (Code) Ownership. Individual class ownership means that distinct pieces or grouping of code are assigned to a single owner. The owner is responsible for the consistency, performance, and conceptual integrity of the class.
Feature Teams. A feature team is a small, dynamically formed team that develops a small activity. Multiple minds are always applied to each design decision, and multiple design options are evaluated before one is chosen.
Inspections. Inspections are carried out to ensure good quality design and code primarily by the detection of defects.
Configuration Management. Configuration management helps with identifying the source code for all features that have been completed to date and maintaining a history of changes to classes as feature teams enhance them.
Regular Builds. Regular builds ensure there is always an up-to-date system that can be demonstrated to the client and help highlight integration errors of source code for the features early.
Visibility of progress and results. Managers steer a project using frequent, appropriate, and accurate progress reporting from all levels inside and outside the project based on completed work.
Metamodelling helps visualize both the processes and the data of a method. This allows methods to be compared, and method fragments in the method engineering process can easily be reused. The usage of this technique is consistent with UML standards.

The left side of the metadata model shows the five basic activities involved in a software development project using FDD. The activities all contain sub-activities that corresponding to sub-activities in the FDD process description. The right side of the model shows the concepts involved. These concepts originate from the activities depicted in the left side of the diagram.

Agile software development
Behavior-driven development
Project lifecycle
Software architecture
Software development process
Software engineering
Agile software developmentSoftware project managementSoftware features
Articles with short descriptionShort description is different from WikidataAll articles with specifically marked weasel-worded phrasesArticles with specifically marked weasel-worded phrases from January 2021Wikipedia articles needing clarification from January 2021Articles with Curlie links






# Iterative_and_incremental_development.md




(Top)





1
Overview




Toggle Overview subsection





1.1
Phases








1.2
Usage/History








1.3
Contrast with Waterfall development








1.4
Implementation guidelines










2
Use in hardware and embedded systems








3
See also








4
Notes








5
References










1.1
Phases








1.2
Usage/History








1.3
Contrast with Waterfall development








1.4
Implementation guidelines






















Iterative and incremental development is any combination of both iterative design (or iterative method) and incremental build model for development.

Usage of the term began in software development, with a long-standing combination of the two terms iterative and incremental[1] having been widely suggested for large development efforts. For example, the 1985 DOD-STD-2167[2]
mentions (in section 4.1.2): "During software development, more than one iteration of the software development cycle may be in progress at the same time." and "This process may be described as an 'evolutionary acquisition' or 'incremental build' approach." In software, the relationship between iterations and increments is determined by the overall software development process.

Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
The basic idea behind this method is to develop a system through repeated cycles (iterative) and in smaller portions at a time (incremental), allowing software developers to take advantage of what was learned during development of earlier parts or versions of the system. Learning comes from both the development and use of the system, where possible key steps in the process start with a simple implementation of a subset of the software requirements and iteratively enhance the evolving versions until the full system is implemented. At each iteration, design modifications are made and new functional capabilities are added.[3]

The procedure itself consists of the initialization step, the iteration step, and the Project Control List. The initialization step creates a base version of the system. The goal for this initial implementation is to create a product to which the user can react. It should offer a sampling of the key aspects of the problem and provide a solution that is simple enough to understand and implement easily. To guide the iteration process, a project control list is created that contains a record of all tasks that need to be performed. It includes items such as new features to be implemented and areas of redesign of the existing solution. The control list is constantly being revised as a result of the analysis phase.

An iteration involves redesign and implementation, which is meant to be simple, straightforward, and modular, supporting redesign at that stage or as a future task added to the project control list.[clarification needed] The level of design detail is not dictated by the iterative approach. In a light-weight iterative project the code may represent the major source of documentation of the system; however, in a critical iterative project a formal Software Design Document may be used. The analysis of an iteration is based upon user feedback and the program analysis facilities available. It involves analysis of the structure, modularity, usability, reliability, efficiency, and achievement of goals. The project control list is modified in light of the analysis results.

Incremental development slices the system functionality into increments (portions). In each increment, a slice of functionality is delivered through cross-discipline work, from the requirements to the deployment. The Unified Process groups increments/iterations into phases: inception, elaboration, construction, and transition.

Inception identifies project scope, requirements (functional and non-functional) and risks at a high level but in enough detail that work can be estimated.
Elaboration delivers a working architecture that mitigates the top risks and fulfills the non-functional requirements.
Construction incrementally fills-in the architecture with production-ready code produced from analysis, design, implementation, and testing of the functional requirements.
Transition delivers the system into the production operating environment.
Each of the phases may be divided into 1 or more iterations, which are usually time-boxed rather than feature-boxed. Architects and analysts work one iteration ahead of developers and testers to keep their work-product backlog full.

Many examples of early usage are provided in Craig Larman and Victor Basili's article "Iterative and Incremental Development: A Brief History",[4] with one of the earliest being NASA's 1960s Project Mercury.

Some of those Mercury engineers later formed a new division within IBM, where "another early and striking example of a major IID success [was] the very heart of NASA’s space shuttle software—the primary avionics software system, which [they] built from 1977 to 1980. The team applied IID in a series of 17 iterations over 31 months, averaging around eight weeks per iteration. Their motivation for avoiding the waterfall life cycle was that the shuttle program’s requirements changed during the software development process."[4]

Some organizations, such as the US Department of Defense, have a preference for iterative methodologies, starting with MIL-STD-498 "clearly encouraging evolutionary acquisition and IID".


The DoD Instruction 5000.2 released in 2000 stated a clear preference for IID: 
There are two approaches, evolutionary and single step [waterfall], to full capability. An evolutionary approach is preferred. … [In this] approach, the ultimate capability delivered to the user is divided into two or more blocks, with increasing increments of capability...software development shall follow an iterative spiral development process in which continually expanding software versions are based on learning from earlier development. It can also be done in phases.
 Recent revisions to DoDI 5000.02 no longer refer to "spiral development," but do advocate the general approach as a baseline for software-intensive development/procurement programs.[5] In addition, the United States Agency for International Development (USAID) also employs an iterative and incremental developmental approach to its programming cycle to design, monitor, evaluate, learn and adapt international development projects with a project management approach that focuses on incorporating collaboration, learning, and adaptation strategies to iterate and adapt programming.[6]

The main cause of the software development projects failure is the choice of the model, so should be made with a great care.[vague][7]

For example, the Waterfall development paradigm completes the project-wide work-products of each discipline in one step before moving on to the next discipline in a succeeding step. Business value is delivered all at once, and only at the very end of the project, whereas backtracking[clarification needed] is possible in an iterative approach. Comparing the two approaches, some patterns begin to emerge:[citation needed]

User involvement: In the waterfall model, the user is involved in two stages of the model, i.e. requirements and acceptance testing, and possibly creation of user education material. Whereas in the incremental model, the client is involved at each and every stage.
Variability: The software is delivered to the user only after the build stage of the life cycle is completed, for user acceptance testing. On the other hand, every increment is delivered to the user and after the approval of user, the developer is allowed to move towards the next module.
Human resources: In the incremental model fewer staff are potentially required as compared to the waterfall model.
Time limitation: An operational product is delivered after months while in the incremental model the product is given to the user within a few weeks.
Project size: Waterfall model is unsuitable for small projects while the incremental model is suitable for small, as well as large projects.
Guidelines that drive software implementation and analysis include:[citation needed]

Any difficulty in design, coding and testing a modification should signal the need for redesign or re-coding.
Modifications should fit easily into isolated and easy-to-find modules. If they do not, some redesign is possibly needed.
Modifications to tables should be especially easy to make. If any table modification is not quickly and easily done, redesign is indicated.
Modifications should become easier to make as the iterations progress. If they are not, there is a basic problem such as a design flaw or a proliferation of patches.
Patches should normally be allowed to exist for only one or two iterations. Patches may be necessary to avoid redesigning during an implementation phase.
The existing implementation should be analyzed frequently to determine how well it measures up to project goals.
Program analysis facilities should be used whenever available to aid in the analysis of partial implementations.
User reaction should be solicited and analyzed for indications of deficiencies in the current implementation.
While the term iterative and incremental development got started in the software industry, many hardware and embedded software development efforts are using iterative and incremental techniques.

Examples of this may be seen in a number of industries. One sector that has recently been substantially affected by this shift of thinking has been the space launch industry, with substantial new competitive forces at work brought about by faster and more extensive technology innovation brought to bear by the formation of private companies pursuing space launch. These companies, such as SpaceX[8] and Rocket Lab,[9] are now both providing commercial orbital launch services in the past decade, something that only six nations had done prior to a decade[10] ago. New innovation in technology development approaches, pricing, and service offerings—including the ability that has existed only since 2016 to fly to space on a previously flown (reusable) booster stage—further decreasing the price of obtaining access to space.[11][8]

SpaceX has been explicit about its effort to bring iterative design practices into the space industry, and uses the technique on spacecraft, launch vehicles, electronics and avionics, and operational flight hardware operations.[12]

As the industry has begun to change, other launch competitors are beginning to change their long-term development practices with government agencies as well. For example, the large US launch service provider United Launch Alliance (ULA) began in 2015 a decade-long project to restructure its launch business—reducing two launch vehicles to one—using an iterative and incremental approach to get to a partially-reusable and much lower-cost launch system over the next decade.[13]

Adaptive management
Agile software development
Continuous integration
DevOps § Incremental adoption
Dynamic systems development method
Goal-Driven Software Development Process
Interaction design
Kaizen
Microsoft Solutions Framework
Object-oriented analysis and design
PDCA
Rapid application development
Release early, release often

^ Larman, Craig (June 2003). "Iterative and Incremental Development: A Brief History" (PDF). Computer. 36 (6): 47–56. doi:10.1109/MC.2003.1204375. ISSN 0018-9162. S2CID 9240477. We were doing incremental development as early as 1957, in Los Angeles, under the direction of Bernie Dimsdale [at IBM's ServiceBureau Corporation]. He was a colleague of John von Neumann, so perhaps he learned it there, or assumed it as totally natural. I do remember Herb Jacobs (primarily, though we all participated) developing a large simulation for Motorola, where the technique used was, as far as I can tell ...'

^ 
DOD-STD-2167 Defense Systems Software Development (04 JUN 1985) on everyspec.com

^ Farcic, Viktor (January 21, 2014). "Software Development Models: Iterative and Incremental Development". Technology Conversations.

^ a b Iterative and Incremental Development: A Brief History, Craig Larman and Victor Basili, IEEE Computer, June 2003

^ Kendall, Frank; Gilmore, J. Michael; Halvorsen, Terry (2017-02-02). "Operation of the Defense Acquisition System" (PDF). DoD Issuances. Under Secretary of Defense for Acquisition, Technology, and Logistics. pp. 12–14. Archived from the original (PDF) on 2017-08-09. Retrieved 2017-08-09.

^ USAID. "ADS Chapter 201 Program Cycle Operational Policy" Archived 2019-10-23 at the Wayback Machine. Retrieved April 19, 2017

^ Kudryashov, Alexey (February 29, 2024). "Incremental vs Waterfall Model in Software Development". Cyfrania: Custom Software Development & Consulting. Choosing the incremental model for stable-requirement projects can lead to scope creep and increased complexity, while selecting the waterfall model might cause rigidity and inefficiency in adapting to changes.

^ a b Belfiore, Michael (9 December 2013). "The Rocketeer". Foreign Policy. Archived from the original on 10 December 2013. Retrieved 11 November 2018.

^ "Exclusive Inside Look at Rocket Lab's Previously-secret new Mega Factory!". Everyday Astronaut. 11 October 2018. Archived from the original on 12 October 2018. Retrieved 11 November 2018.

^ 
Clark, Stephen (28 September 2008). "Sweet Success at Last for Falcon 1 Rocket". Spaceflight Now. Retrieved 11 November 2018. the first privately developed liquid-fueled rocket to successfully reach orbit.

^ 
Berger, Eric (2018-06-25). "Russia's Proton rocket, which predates Apollo, will finally stop flying Technical problems, rise of SpaceX are contributing factors". arsTechica. Retrieved 2018-06-26. the rapid rise of low-cost alternatives such as SpaceX's Falcon 9 rocket, have caused the number of Proton launches in a given year to dwindle from eight or so to just one or two.

^ 
Fernholz, Tim (21 October 2014). "What it took for Elon Musk's SpaceX to disrupt Boeing, leapfrog NASA, and become a serious space company". Quartz. Retrieved 11 November 2018. But SpaceX always thought of itself as a tech firm, and its clashes with NASA often took a form computer developers—or anyone familiar with the troubled roll-out of healthcare.gov—would recognize as generational. SpaceX followed an iterative design process, continually improving prototypes in response to testing. Traditional product management calls for a robust plan executed to completion, a recipe for cost overruns.

^ 
Gruss, Mike (2015-04-24). "Evolution of a Plan : ULA Execs Spell Out Logic Behind Vulcan Design Choices". Space News. Retrieved 25 April 2015. ULA's April 13 announcement that it would develop a rocket dubbed Vulcan using an incremental approach whose first iteration essentially is an Atlas 5 outfitted with a new first stage.


This article includes a list of general references, but it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations. (September 2010) (Learn how and when to remove this message)
Software development philosophiesSoftware project management
Webarchive template wayback linksArticles with short descriptionShort description is different from WikidataWikipedia articles needing clarification from October 2018All Wikipedia articles needing clarificationWikipedia articles needing clarification from November 2019Wikipedia articles needing clarification from November 2018All articles with unsourced statementsArticles with unsourced statements from November 2018Articles lacking in-text citations from September 2010All articles lacking in-text citations






# Kanban_(development).md




(Top)





1
Kanban boards








2
Kanban practices








3
Managing workflow








4
Evolution and documentation of method








5
See also








6
References








7
Further reading




















 A major contributor to this article appears to have a close connection with its subject. It may require cleanup to comply with Wikipedia's content policies, particularly neutral point of view. Please discuss further on the talk page. (August 2022) (Learn how and when to remove this message)
Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte

Kanban (Japanese: 看板, meaning signboard or billboard) is a lean method to manage and improve work across human systems. This approach aims to manage work by balancing demands with available capacity, and by improving the handling of system-level bottlenecks. 

Work items are visualized to give participants a view of progress and process, from start to finish—usually via a kanban board. Work is pulled as capacity permits, rather than work being pushed into the process when requested.

In knowledge work and in software development, the aim is to provide a visual process management system which aids decision-making about what, when, and how much to produce. The underlying kanban method originated in lean manufacturing,[1] which was inspired by the Toyota Production System.[2] It has its origin in the late 1940s when the Toyota automotive company implemented a production system called just-in-time, which had the objective of producing according to customer demand and identifying possible material shortages within the production line. But it was a team at Corbis that realized how this method devised by Toyota could become a process applicable to any type of organizational process. Kanban is commonly used in software development in combination with methods and frameworks such as Scrum.[3]

The diagram here shows a software development workflow on a kanban board.[4]

Kanban boards, designed for the context in which they are used, vary considerably and may show work item types ("features" and "user stories" here), columns delineating workflow activities, explicit policies, and swimlanes (rows crossing several columns, used for grouping user stories by feature here). The aim is to make the general workflow and the progress of individual items clear to participants and stakeholders.

A Kanban Board represents the system's Definition of Workflow[5] and requires the following minimum elements:

A definition of the individual units of value that are moving through the workflow. These units of value are referred to as work items (or items).
A definition for when work items are started and finished within the workflow. Your workflow may have more than one started or finished points depending on the work item.
One or more defined states that the work items flow through from started to finished. Any work items between a started point and a finished point are considered work in progress (WIP).
A definition of how WIP will be controlled from started to finished.
Explicit policies about how work items can flow through each state from started to finished.
A service level expectation (SLE), which is a forecast of how long it should take a work item to flow from started to finished.
The Practices of Kanban as described in the Kanban Guide[6] are 

Defining and visualizing a workflow
Actively managing items in a workflow
Improving a workflow
Kanban is a strategy that aims to follow these in order to create systems that are efficient, effective, and predictable.

The Kanban Method is a specialized and detailed extrapolation of Kanban. As described in books on The Kanban Method for software development,[7][3] the two primary practices of The Kanban Method are to visualize work and to limit work in progress (WIP). Four additional general practices of The Kanban Method listed in Essential Kanban Condensed are to make policies explicit, manage flow, implement feedback loops, and improve collaboratively.[8]

The kanban board in the diagram above highlights the first three general practices of The Kanban Method.

It visualizes the work of the development team (the features and user stories).
It captures WIP limits for development steps: the circled values below the column headings that limit the number of work items under that step.
It documents policies, also known as done rules,[9] inside blue rectangles under some of the development steps.
It also shows some kanban flow management for the "user story preparation", "user story development", and "feature acceptance" steps, which have "in progress" and "ready" sub-columns. Each step's WIP limit applies to both sub-columns, preventing work items from overwhelming the flow into or out of those steps.
Kanban manages workflow directly on the kanban board. The WIP limits for development steps provide development teams immediate feedback on common workflow issues.[7][9]

For example, on the kanban board shown above, the "deployment" step has a WIP limit of five and there are currently five epics[clarification needed] shown in that step. No more work items can move into deployment until one or more epics complete that step (moving to "delivered"). This prevents the "deployment" step from being overwhelmed. Team members working on "feature acceptance" (the previous step) might get stuck because they can't deploy new epics. They can see why immediately on the board and help with the current epic deployments.

Once the five epics in the "deployment" step are delivered, the two epics from the "ready" sub-column of "feature acceptance" (the previous step) can be moved to the "deployment" column. When those two epics are delivered, no other epics can be deployed (assuming no new epics are ready). Now, team members working on deployment are stuck. They can see why immediately and help with feature acceptance.

This workflow control works similarly for every step. Problems are visual and evident immediately, and re-planning can be done continuously. The work management is made possible by limiting work in progress in a way team members can see and track at all times.

David Anderson's 2010 book, Kanban,[7] describes an evolution of the approach from a 2004 project at Microsoft[10] using a theory-of-constraints approach and incorporating a drum-buffer-rope (comparable to the kanban pull system), to a 2006–2007 project at Corbis in which the kanban method was[by whom?] identified. In 2009, Don Reinertsen published a book on second-generation lean product-development[11] which describes the adoption of the kanban system and the use of data collection and an economic model for management decision-making. Another early contribution came from Corey Ladas, whose 2008 book Scrumban[3] suggested that kanban could improve scrum for software development. Ladas saw scrumban as the transition from scrum to kanban. Jim Benson and Tonianne DeMaria Barry published Personal Kanban,[12] applying kanban to individuals and small teams, in 2011. In Kanban from the Inside (2014),[13] Mike Burrows explained kanban's principles, practices and underlying values and related them to earlier theories and models. In Agile Project Management with Kanban (2015),[9] Eric Brechner provides an overview of kanban in practice at Microsoft and Xbox. Kanban Change Leadership (2015), by Klaus Leopold and Siegfried Kaltenecker,[14] explained the method from the perspective of change management and provided guidance to change-initiatives. In 2016 Lean Kanban University Press published a condensed guide to the method, incorporating improvements and extensions from the early kanban projects.[8]

In 2020 John Coleman and Daniel Vacanti published The Kanban Guide[6] to describe the minimal conditions needed to operate a Kanban system. Colleen Johnson, Daniel Vacanti, and Prateek Singh published The Kanban Pocket Guide[15] in 2022, which helps practitioners navigate the Kanban practices. Will Seele and Daniel Vacanti also published the Flow Metrics for Scrum Teams[16] book in 2022 to bring the benefits of metrics commonly used in Kanban to Scrum teams.

List of software development philosophies
Agile software developmentJapanese business termsSoftware development philosophiesToyota Production System
Wikipedia articles with possible conflicts of interest from August 2022Articles with short descriptionShort description is different from WikidataUse dmy dates from January 2021Articles containing Japanese-language textWikipedia articles needing clarification from January 2022Articles with specifically marked weasel-worded phrases from June 2020Articles with GND identifiers






# Lean_software_development.md




(Top)





1
Origin








2
Lean principles




Toggle Lean principles subsection





2.1
Eliminate waste








2.2
Amplify learning








2.3
Decide as late as possible








2.4
Deliver as fast as possible








2.5
Empower the team








2.6
Build integrity in








2.7
Optimize the whole










3
Lean software practices








4
See also








5
References








6
Further reading












2.1
Eliminate waste








2.2
Amplify learning








2.3
Decide as late as possible








2.4
Deliver as fast as possible








2.5
Empower the team








2.6
Build integrity in








2.7
Optimize the whole




























This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Lean software development" – news · newspapers · books · scholar · JSTOR (July 2014) (Learn how and when to remove this message)


Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Lean software development is a translation of lean manufacturing principles and practices to the software development domain. Adapted from the Toyota Production System,[1] it is emerging with the support of a pro-lean subculture within the agile community. Lean offers a solid conceptual framework, values and principles, as well as good practices, derived from experience, that support agile organizations.

The expression "lean software development" originated in a book by the same name, written by Mary Poppendieck and Tom Poppendieck in 2003.[2] The book restates traditional lean principles, as well as a set of 22 tools and compares the tools to corresponding agile practices. The Poppendiecks' involvement in the agile software development community, including talks at several Agile conferences [3] has resulted in such concepts being more widely accepted within the agile community.

Lean development can be summarized by seven principles, very close in concept to lean manufacturing principles:[4]

Eliminate waste
Amplify learning
Decide as late as possible
Deliver as fast as possible
Empower the team
Build integrity in
Optimize the whole
Lean philosophy regards everything not adding value to the customer as waste (muda). Such waste may include:[5]

Partially done work
Extra features
Relearning
Task switching
Waiting
Handoffs
Defects
Management activities
In order to eliminate waste, one should be able to recognize it. If some activity could be bypassed or the result could be achieved without it, it is waste. Partially done coding eventually abandoned during the development process is waste. Extra features like paperwork and features not often used by customers are waste. Switching people between tasks is waste (because of time spent, and often lost, by people involved in context-switching). Waiting for other activities, teams, processes is waste. Relearning requirements to complete work is waste. Defects and lower quality are waste. Managerial overhead not producing real value is waste.

A value stream mapping technique is used to identify waste. The second step is to point out sources of waste and to eliminate them. Waste-removal should take place iteratively until even seemingly essential processes and procedures are liquidated.

Software development is a continuous learning process based on iterations when writing code. Software design is a problem-solving process involving the developers writing the code and what they have learned. Software value is measured in fitness for use and not in conformance to requirements.

Instead of adding more documentation or detailed planning, different ideas could be tried by writing code and building. The process of user requirements gathering could be simplified by presenting screens to the end-users and getting their input. The accumulation of defects should be prevented by running tests as soon as the code is written.

The learning process is sped up by usage of short iteration cycles – each one coupled with refactoring and integration testing. Increasing feedback via short feedback sessions with customers helps when determining the current phase of development and adjusting efforts for future improvements. During those short sessions, both customer representatives and the development team learn more about the domain problem and figure out possible solutions for further development. Thus the customers better understand their needs, based on the existing result of development efforts, and the developers learn how to better satisfy those needs. Another idea in the communication and learning process with a customer is set-based development – this concentrates on communicating the constraints of the future solution and not the possible solutions, thus promoting the birth of the solution via dialogue with the customer.[jargon]

As software development is always associated with some uncertainty, better results should be achieved with a set-based or options-based approach, delaying decisions as much as possible until they can be made based on facts and not on uncertain assumptions and predictions. The more complex a system is, the more capacity for change should be built into it, thus enabling the delay of important and crucial commitments. The iterative approach promotes this principle – the ability to adapt to changes and correct mistakes, which might be very costly if discovered after the release of the system.

An agile software development approach can move the building of options earlier for customers, thus delaying certain crucial decisions until customers have realized their needs better. This also allows later adaptation to changes and the prevention of costly earlier technology-bounded decisions. This does not mean that no planning should be involved – on the contrary, planning activities should be concentrated on the different options and adapting to the current situation, as well as clarifying confusing situations by establishing patterns for rapid action. Evaluating different options is effective as soon as it is realized that they are not free, but provide the needed flexibility for late decision making.

In the era of rapid technology evolution, it is not the biggest that survives, but the fastest. The sooner the end product is delivered without major defects, the sooner feedback can be received, and incorporated into the next iteration. The shorter the iterations, the better the learning and communication within the team. With speed, decisions can be delayed. Speed assures the fulfilling of the customer's present needs and not what they required yesterday. This gives them the opportunity to delay making up their minds about what they really require until they gain better knowledge. Customers value rapid delivery of a quality product.

The just-in-time production ideology could be applied to software development, recognizing its specific requirements and environment. This is achieved by presenting the needed result and letting the team organize itself and divide the tasks for accomplishing the needed result for a specific iteration. At the beginning, the customer provides the needed input. This could be simply presented in small cards or stories – the developers estimate the time needed for the implementation of each card. Thus the work organization changes into self-pulling system – each morning during a stand-up meeting, each member of the team reviews what has been done yesterday, what is to be done today and tomorrow, and prompts for any inputs needed from colleagues or the customer. This requires transparency of the process, which is also beneficial for team communication.

The myth underlying this principle is haste makes waste. However, lean implementation has shown that it is a good practice to deliver fast in order to see and analyze the output as early as possible.

There has been a traditional belief in most businesses about the decision-making in the organization – the managers tell the workers how to do their own job. In a work-out technique, the roles are turned – the managers are taught how to listen to the developers, so they can explain better what actions might be taken, as well as provide suggestions for improvements. The lean approach follows the agile principle[6] "build projects around motivated individuals [...] and trust them to get the job done",[7] encouraging progress, catching errors, and removing impediments, but not micro-managing.

Another mistaken belief has been the consideration of people as resources. People might be resources from the point of view of a statistical data sheet, but in software development, as well as any organizational business, people do need something more than just the list of tasks and the assurance that they will not be disturbed during the completion of the tasks. People need motivation and a higher purpose to work for – purpose within the reachable reality, with the assurance that the team might choose its own commitments. The developers should be given access to the customer; the team leader should provide support and help in difficult situations, as well as ensure that skepticism does not ruin the team's spirit. Respecting people and acknowledging their work is one way to empower the team.

The customer needs to have an overall experience of the system. This is the so-called perceived integrity: how it is being advertised, delivered, deployed, accessed, how intuitive its use is, its price and how well it solves problems.

Conceptual integrity means that the system's separate components work well together as a whole with balance between flexibility, maintainability, efficiency, and responsiveness. This could be achieved by understanding the problem domain and solving it at the same time, not sequentially. The needed information is received in small batch pieces – not in one vast chunk - preferably by face-to-face communication and not any written documentation. The information flow should be constant in both directions – from customer to developers and back, thus avoiding the large stressful amount of information after long development in isolation.

One of the healthy ways towards integral architecture is refactoring. As more features are added to the original code base, the harder it becomes to add further improvements. Refactoring is about keeping simplicity, clarity, minimum number of features in the code. Repetitions in the code are signs of bad code designs and should be avoided (i.e. by applying the DRY rule). The complete and automated building process should be accompanied by a complete and automated suite of developer and customer tests, having the same versioning, synchronization and semantics as the current state of the system. At the end the integrity should be verified with thorough testing, thus ensuring the System does what the customer expects it to. Automated tests are also considered part of the production process, and therefore if they do not add value they should be considered waste. Automated testing should not be a goal, but rather a means to an end, specifically the reduction of defects.

Modern software systems are not simply the sum of their parts, but also the product of their interactions. Defects in software tend to accumulate during the development process – by decomposing the big tasks into smaller tasks, and by standardizing different stages of development, the root causes of defects should be found and eliminated. The larger the system, the more organizations that are involved in its development and the more parts are developed by different teams, the greater the importance of having well defined relationships between different vendors, in order to produce a system with smoothly interacting components. During a longer period of development, a stronger subcontractor network is far more beneficial than short-term profit optimizing, which does not enable win-win relationships.

Lean thinking has to be understood well by all members of a project, before implementing in a concrete, real-life situation. "Think big, act small, fail fast; learn rapidly"[8] – these slogans summarize the importance of understanding the field and the suitability of implementing lean principles along the whole software development process. Only when all of the lean principles are implemented together, combined with strong "common sense" with respect to the working environment, is there a basis for success in software development.

Lean software development practices, or what the Poppendiecks call "tools" are restated slightly from the original equivalents in agile software development. Examples of such practices include:

Seeing waste
Value stream mapping
Set-based development
Pull systems
Queueing theory
Motivation
Measurements
Test-driven development
Since agile software development is an umbrella term for a set of methods and practices based on the values and principles expressed in the Agile Manifesto, lean software development is considered an agile software development method.[9]

Extreme programming
DevOps
Kanban
Kanban board
Lean integration
Lean services
Scrum (development)
Software development philosophiesAgile software developmentLean manufacturing
Articles with short descriptionShort description is different from WikidataArticles needing additional references from July 2014All articles needing additional referencesAll articles that are too technicalWikipedia articles that are too technical from June 2018All articles needing expert attentionArticles needing expert attention from June 2018






# Lean_startup.md




(Top)





1
Overview








2
Precursors




Toggle Precursors subsection





2.1
Lean manufacturing








2.2
Customer development










3
Principles




Toggle Principles subsection





3.1
Minimum viable product








3.2
Continuous deployment (only for software development)








3.3
Split testing








3.4
Actionable metrics








3.5
Pivot








3.6
Innovation accounting








3.7
Build-Measure-Learn










4
Business model templates




Toggle Business model templates subsection





4.1
Business Model Canvas








4.2
Other canvases






4.2.1
Lean Canvas








4.2.2
Value Proposition Canvas








4.2.3
Mission Model Canvas












5
The movement




Toggle The movement subsection





5.1
In the government






5.1.1
Hacking for Defense












6
Lean concepts








7
History








8
Reception








9
See also








10
References












2.1
Lean manufacturing








2.2
Customer development














3.1
Minimum viable product








3.2
Continuous deployment (only for software development)








3.3
Split testing








3.4
Actionable metrics








3.5
Pivot








3.6
Innovation accounting








3.7
Build-Measure-Learn
























4.1
Business Model Canvas








4.2
Other canvases






4.2.1
Lean Canvas








4.2.2
Value Proposition Canvas








4.2.3
Mission Model Canvas














4.2.1
Lean Canvas








4.2.2
Value Proposition Canvas








4.2.3
Mission Model Canvas
















5.1
In the government






5.1.1
Hacking for Defense












5.1.1
Hacking for Defense


















Lean startup is a methodology for developing businesses and products that aims to shorten product development cycles and rapidly discover if a proposed business model is viable; this is achieved by adopting a combination of business-hypothesis-driven experimentation, iterative product releases, and validated learning. Lean startup emphasizes customer feedback over intuition and flexibility over planning. This methodology enables recovery from failures more often than traditional ways of product development.[1]

Central to the lean startup methodology is the assumption that when startup companies invest their time into iteratively building products or services to meet the needs of early customers, the company can reduce market risks and sidestep the need for large amounts of initial project funding and expensive product launches and financial failures.[2][3] While the events leading up to the launch can make or break a new business, it is important to start with the end in mind, which means thinking about the direction in which you want your business to grow and how to put all the right pieces in place to make this possible.[4]

Similar to the precepts of lean manufacturing and lean software development, the lean startup methodology seeks to eliminate wasteful practices and increase value-producing practices during the earliest phases of a company so that the company can have a better chance of success without requiring large amounts of outside funding, elaborate business plans, or a perfect product.[5] Customer feedback during the development of products or services is integral to the lean startup process, and ensures that the company does not invest time designing features or services that consumers do not want.[6] This is done primarily through two processes: using key performance indicators and a continuous deployment process.[3][7][8]

When a startup company cannot afford to have its entire investment depend upon the success of a single product or service, the lean startup methodology proposes that by releasing a minimum viable product that is not yet finalized, the company can then make use of customer feedback to help further tailor the product or service to the specific needs of its customers.[3][5]

The lean startup methodology asserts that "lean has nothing to do with how much money a company raises"; rather it has everything to do with assessing the specific demands of consumers and how to meet that demand using the least amount of resources possible.[9]

Use of the word lean to describe the streamlined production system of lean manufacturing was popularized by the 1990 book The Machine That Changed the World.[10][11] The Toyota Production System pioneered by Taiichi Ohno combined flow principles that had been used by Henry Ford since the early 1900s with innovations such as the TWI programs introduced to Japan in 1951.[11]

Lean manufacturing systems consider the expenditure of resources for any goal other than the creation of value for the end customer as waste, and they continually seek ways to eliminate such waste. In particular, such systems focus on:

Minimizing inventory throughout the assembly line,
Using Kanban cards to signal only when the necessary inputs to production are needed, and in so doing, reduce assembly waste (inventory) and increase productivity,[12]
Identifying mistakes or imperfections during assembly as early as possible at immediate quality control checkpoints to ensure that the least amount of time is expended developing a faulty product,[13] and
Maintaining close connections with suppliers in order to understand their customers' desires.
Lean manufacturing was later applied to software as lean software development.

The lean startup methodology is based on the customer development methodology of Silicon Valley serial entrepreneur-turned-academic Steve Blank. In his book The Four Steps to the Epiphany: Successful Strategies for Products that Win (2005, 5th edition 2013), Blank pointed out the pitfalls of a narrow emphasis on product development; instead he argued that startups should focus on what he called "customer development", which emphasizes "learning about customers and their problems as early in the development process as possible".[14]: 12  Blank's customer development methodology proposed four steps:[14]: 16–19 

Customer discovery tests hypotheses about the nature of the problem, interest in the product or service solution, and business viability.
Customer validation tests the business viability through customer purchases and in the process creates a "sales road map", a proven and repeatable sales process. Customer discovery and customer validation corroborate the business model.
Customer creation executes the business plan by scaling through customer acquisition, creating user demand and directing it toward the company's sales channels.
Company building formalizes and standardizes company departments and operations.
In an article published in the Harvard Business Review in 2013, Steve Blank described how the lean startup methodology also drew inspiration from the work of people like Ian C. MacMillan and Rita Gunther McGrath who developed a technique called discovery-driven planning, which was an attempt to bring an entrepreneurial mindset to planning.[15]

In his blog and book The Lean Startup, entrepreneur Eric Ries used specific terms to refer to the core lean startup principles, as described below.

A minimum viable product (MVP) is the "version of a new product which allows a team to collect the maximum amount of validated learning about customers with the least effort" (similar to a pilot experiment).[16][17][18] The goal of an MVP is to test fundamental business hypotheses (or leap-of-faith assumptions) and to help entrepreneurs begin the learning process as quickly as possible.[16]

As an example, Ries noted that Zappos founder Nick Swinmurn wanted to test the hypothesis that customers were ready and willing to buy shoes online.[16]: 57–58  Instead of building a website and a large database of footwear, Swinmurn approached local shoe stores, took pictures of their inventory, posted the pictures online, bought the shoes from the stores at full price after he'd made a sale, and then shipped them directly to customers. Swinmurn deduced that customer demand was present, and Zappos would eventually grow into a billion dollar business based on the model of selling shoes online.[16]: 57–58 

Continuous deployment, similar to continuous delivery, is a process "whereby all code that is written for an application is immediately deployed into production," which results in a reduction of cycle times.[19] Ries stated that some of the companies he's worked with deploy new code into production as often as 50 times a day.[19] The phrase was coined by Timothy Fitz, one of Ries's colleagues and an early engineer at IMVU.[16][20]

A split or A/B test is an experiment in which "different versions of a product are offered to customers at the same time."[16] The goal of a split test is to observe differences in behavior between the two groups and to measure the impact of each version on an actionable metric.

A/B testing is sometimes incorrectly performed in serial fashion, where a group of users one week may see one version of the product while the next week users see another. This undermines the statistical validity of the results, since external events may influence user behavior in one time period but not the other. For example, a split test of two ice cream flavors performed in serial during the summer and winter would see a marked decrease in demand during the winter where that decrease is mostly related to the weather and not to the flavor offer.

Another way to incorrectly A/B test is to assign users to one or another A/B version of the product using any non-random method.

Actionable metrics can lead to informed business decisions and subsequent action.[16][21] These are in contrast to vanity metrics—measurements that give "the rosiest picture possible" but do not accurately reflect the key drivers of a business.

Vanity metrics for one company may be actionable metrics for another. For example, a company specializing in creating web based dashboards for financial markets might view the number of web page views[8] per person as a vanity metric as their revenue is not based on number of page views. However, an online magazine with advertising would view web page views as a key metric as page views are directly correlated to revenue.

A typical example of a vanity metric is "the number of new users gained per day". While a high number of users gained per day seems beneficial to any company, if the cost of acquiring each user through expensive advertising campaigns is significantly higher than the revenue gained per user, then gaining more users could quickly lead to bankruptcy.

A pivot is a "structured course correction designed to test a new fundamental hypothesis about the product, strategy, and engine of growth."[16] A notable example of a company employing the pivot is Groupon; when the company first started, it was an online activism platform called The Point.[2] After receiving almost no traction, the founders opened a WordPress blog and launched their first coupon promotion for a pizzeria located in their building lobby.[2] Although they only received 20 redemptions, the founders realized that their idea was significant, and had successfully empowered people to coordinate group action.[2] Three years later, Groupon would grow into a billion dollar business.

Steve Blank defines a pivot as "changing (or even firing) the plan instead of the executive (the sales exec, marketing or even the CEO)."[22][23]

This topic focuses on how entrepreneurs can maintain accountability and maximize outcomes by measuring progress, planning milestones, and prioritizing.[24] The topic was later expanded upon to include three levels of innovation accounting related to the types of assumptions being validated.[25]

The Build–Measure–Learn loop emphasizes speed as a critical ingredient to customer development. A team or company's effectiveness is determined by its ability to ideate, quickly build a minimum viable product of that idea, measure its effectiveness in the market, and learn from that experiment. In other words, it is a learning cycle of turning ideas into products, measuring customers' reactions and behaviors against built products, and then deciding whether to persevere or pivot the idea; this process repeats as many times as necessary. The process can also be viewed as a test of hypotheses. The phases of the loop are: Ideas → Build → Product → Measure → Data → Learn.[26][27]

The Business Model Canvas is a strategic management template invented by Alexander Osterwalder around 2008 for developing new business models or documenting existing ones.[28] It is a visual chart with elements describing a firm's value proposition, infrastructure, customers, and finances. It assists firms in aligning their activities by illustrating potential trade-offs.[29]

The template consists of nine blocks: activities, partners, resources, value proposition, customers, customer channels, customer relationships, costs and revenue.[29] Startups use the template (and/or other templates described below) to formulate hypotheses and change their business model based on the success or failure of tested hypotheses.

The Lean Canvas is a version of the Business Model Canvas adapted by Ash Maurya in 2010 specifically for startups.[26][30] The Lean Canvas focuses on addressing broad customer problems and solutions and delivering them to customer segments through a unique value proposition.[31] "Problem" and "solution" blocks replace the "key partners" and "key activities" blocks in the Business Model Canvas, while "key metrics" and "unfair advantage" blocks replace the "key resources" and "customer relationships" blocks, respectively.[26][31]

The Value Proposition Canvas is a supplement to the Business Model Canvas ("customer segment" and "value proposition" blocks) published in 2012[32] to address the customer–product relationship, the perceived value of the product or service, and potential product/market fit.[33] The "value proposition" block is divided into three categories—products and services, gain creators, and pain relievers—that correspond to three categories in the "customer segment" block—customer jobs, gains, and pains.[33]

The Mission Model Canvas is a version of the Business Model Canvas developed by Alexander Osterwalder and Steve Blank for entities such as government agencies that have a predetermined budget instead of a goal of raising revenue.[34] It was published in 2016.[34] Earlier publications by Osterwalder and colleagues had suggested how to adapt the Business Model Canvas for nonprofit enterprises that depend on raising revenue.[35][29][36] "Mission budget/cost" and "mission achievement/impact factors" blocks replace the "cost structure" and "revenue streams" blocks in the Business Model Canvas, while "beneficiaries", "buy-in/support" and "deployment" blocks replace the "customer segments", "customer relationships" and "channels" blocks, respectively.[34]

Ries and others created an annual technology conference called Startup Lessons Learned which has subsequently changed its name to the Lean Startup Conference.[37] Lean startup meetups in cities around the world have garnered 20,000 regular participants.[38] The first lean startup meetup named Lean Startup Circle was created by Rich Collins on June 26, 2009[39] hosting speaking events, workshops, and roundtable discussions. As of 2012, there are lean startup meetups in over 100 cities and 17 countries as well as an online discussion forum with over 5500 members.[40] Third-party organizers have led lean startup meetups in San Francisco, Chicago, Boston, Austin, Beijing, Dublin, and Rio de Janeiro, among others—many of which are personally attended by Ries—with the Chicago and New York City Lean Startup Meetups attracting over 4,000 members each.[41] The Lean Startup Machine created a new spin on the lean startup meetups by having attendees start a new company in three days.[42] As of 2012, the Lean Startup Machine claimed to have created over 600 new startups this way.[43]

Prominent high-tech companies have begun to publicly employ the lean startup methodology, including Intuit, Dropbox, Wealthfront, Votizen, Aardvark, and Grockit.[44][6][45] The lean startup principles are also taught in classes at Harvard Business School and UC Berkeley and are implemented in municipal governments through Code for America.[46]

Academic researchers in Finland have applied the lean startup methodology to accelerating research innovation.[47]

The United States Government has employed lean startup ideas. The Federal Chief Information Officer of the United States, Steven VanRoekel noted in 2012 that he was taking a "lean-startup approach to government".[48] Ries has worked with the former and current Chief Technology Officers of the United States—Aneesh Chopra and Todd Park respectively—to implement aspects of the lean startup model.[49][50] In particular, Park noted that in order to understand customer demand, the Department of Health and Human Services recognized "the need to rapidly prototype solutions, engage customers in those solutions as soon as possible, and then quickly and repeatedly iterate those solutions based on working with customers".[51][52] In May 2012, Ries and The White House announced the Presidential Innovation Fellows program, which brings together top citizen innovators and government officials to work on high-level projects and deliver measurable results in six months.[53]

Steve Blank, working with retired United States Army colonel Pete Newell and former United States Army Special Forces colonel Joe Felter, adapted lean startup principles for U.S. government innovation under the moniker "Hacking for Defense", a program in which university students solve problems that the Department of Defense, the United States Armed Forces, and the United States Intelligence Community submit to participating universities.[54][55][56] Hacking for Defense and variants like Hacking for Diplomacy have expanded to the United States Department of State, Department of Energy, NASA, and nonprofits.[57][58]

Lean startup principles have been applied to specific competencies within typical startups and larger organizations:[15]

Lean analytics
Lean brand management
Lean hardware
Lean events
Lean manufacturing
Lean marketing
Lean product management
Lean sales
Lean software development
Lean UX
The lean startup methodology was first proposed in 2008 by Eric Ries, using his personal experiences adapting lean management and customer development principles to high-tech startup companies.[59][9][5][44] The methodology has since been expanded to apply to any individual, team, or company looking to develop new products, services, or systems without unlimited resources.[38] The lean startup's reputation is due in part to the success of Ries' bestselling book, The Lean Startup, published in September 2011.[16][60][61]

Ries' said that his first company, Catalyst Recruiting, failed because he and his colleagues did not understand the wants of their target customers, and because they focused too much time and energy on the initial product launch.[9][62] Next, Ries was a senior software engineer with There, Inc.,[9][62] which Ries described as a classic example of a Silicon Valley startup with five years of stealth R&D, $40 million in financing, and nearly 200 employees at the time of product launch.[62] In 2003, There, Inc. launched its product, There.com, but they were unable to garner popularity beyond the initial early adopters.[62] Ries claimed that despite the many proximate causes for failure, the most important mistake was that the company's "vision was almost too concrete", making it impossible to see that their product did not accurately represent consumer demand.[62]

Although the lost money differed by orders of magnitude, Ries concluded that the failures of There, Inc. and Catalyst Recruiting shared similar origins: "it was working forward from the technology instead of working backward from the business results you're trying to achieve."[38]

After Ries later co-founded IMVU Inc., IMVU investor Steve Blank insisted that IMVU executives audit Blank's class on entrepreneurship at UC Berkeley.[46] Ries applied Blank's customer development methodology and integrated it with ideas from lean software development and elsewhere to form the lean startup methodology.[59]

Ben Horowitz, the co-founder of venture capital firm Andreessen Horowitz, wrote an article in 2010 criticizing the lean startup method for over-emphasizing "running lean" (constantly cutting and reducing non-essential parts of the company to save time and money). He specifically disagreed with portraying "running lean" as an end rather than a means to winning the market without running out of cash. Horowitz gave as an example his startup Loudcloud, which by "running fat" was able to outperform 20 direct competitors and after 8 years reach a value of $1.6 billion.[63] However, at least since 2008, numerous advocates of lean methods have pointed out that "running lean" does not mean cost cutting.[64][65][66][67][68][69][70][71]

Trey Griffith, the VP of technology at Teleborder, stated in 2012 that the majority of backing for the lean startup methodology was anecdotal and had not been rigorously validated when first presented. However, he went on to note that better support of the method comes out of a 2011 analysis of the factors of success in growth companies as described in the 2011 book Great by Choice.[72]

Lean startup has also been the source of attention in the academic literature. For example, Stanford professor Riitta Katila finds empirical support for lean startup.[73] However, a group of prominent strategy and innovation scholars—Teppo Felin, Alfonso Gambardella, Scott Stern and Todd Zenger—argue that the application of lean manufacturing principles to startups is highly problematic and only creates incremental outcomes for startups that use the method.[74] Other scholars, including Wharton's Dan Levinthal, argue that many of the insights of lean startup have already been anticipated by the technology evolution, organizational learning and other literatures.[75] The value of lean startup continues to be debated and discussed in the academic literature.[76]


Business portal
Design thinking
EntrepreneurshipLean manufacturing
Articles with short descriptionShort description matches Wikidata






# Management_fad.md




(Top)





1
Common characteristics








2
Origins








3
Examples








4
See also








5
References








6
Further reading


















Management fad is a term used to characterize a change in philosophy or operations implemented by a business or institution. It amounts to a fad in the management culture of an institution. 

The term is subjective and tends to be used in a pejorative sense, as it implies that such a change is being implemented (often by management on its employees, with little or no input from them) solely because it is (at the time) "popular" within managerial circles, and not necessarily due to any real need for organizational change. The term further implies that once the underlying philosophy is no longer "popular", it will be replaced by the newest "popular" idea, in the same manner and for the same reason as the previous idea.

Alternatively, the pejorative use of the term expresses a cynical belief that the organization desires change that would be resisted by the rank and file if presented directly, so it is dressed up in a dramatic change of management style, to remain in place only as long as it serves the underlying agenda. 

Several authors have argued that new management ideas should be subject to greater critical analysis, and for the need for greater conceptual awareness of new ideas by managers.[1] Authors Leonard J. Ponzi and Michael Koenig believe that a key determinant of whether any management idea is a "management fad" is the number and timing of published articles on the idea. In their research,[2] Ponzi and Koenig argue that once an idea has been discussed for around 3–5 years, if after this time the number of articles on the idea in a given year decreases significantly (similar to the right-hand side of a bell curve), then the idea is most likely a "management fad".

This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (March 2018) (Learn how and when to remove this message)
Management fads are often characterized by the following:

New jargon for existing business processes.
External consultants who specialize in the implementation of the fad.
A certification or appraisal process performed by an external agency for a fee.
Amending the job titles of existing employees to include references to the fad.
Claims of a measurable business improvement via measurement of a metric (e.g. key performance indicator) that is defined by the fad itself.
An internal sponsoring department or individual that gains influence due to the fad's implementation.
Big words and complex phrases (puffery).
Consultants and even academics have developed new management ideas. Journalists may popularize new concepts.[3]

Like other fashions, trends in management thought may grow, decline, and recur. Judy Wajcman sees the human relations movement of the 1930s as a precursor of the later fashion of "transformational management".[4]

The following management theories and practices appeared on a 2004 list of management fashions and fads compiled by Adrian Furnham,[5] who arranged them in rough chronological order by their date of appearance, 1950s to 1990s:

Management by objectives
Matrix management
Theory Z
 One-minute management
Management by wandering around
Total quality management
Business process reengineering
Delayering
Empowerment
360-degree feedback
 Re-engineering
Teamwork[6]
Other theories and practices which observers have tagged as fads include:

ISO 9000[citation needed]
Six Sigma[7]
the tendency to replace every occurrence of "data" in compound managerial terminology with "information",[citation needed] see e.g. information integration vs. data integration
Knowledge management[8]
Design thinking
DevOps[9]
Lean six sigma
Transformational leadership[10]
5S
Agile software development[11]
Enterprise architecture frameworks[12][13][14]
"thriving on chaos"[15]
Open-plan offices [16]
Stack ranking, where employees are encouraged to rat each other out in order to secure their own advancement and budget
Consensus management[17]
Best practice[17]
The Tao of Leadership[18]
Philosophy of business
Organizational performance
Management consulting: Criticism section
Dilbert
Hype cycle
Business fable
Business termsManagement theory
Articles with short descriptionShort description is different from WikidataArticles needing additional references from March 2018All articles needing additional referencesAll articles with unsourced statementsArticles with unsourced statements from October 2013Articles with unsourced statements from May 2019






# PDCA.md




(Top)





1
Meaning




Toggle Meaning subsection





1.1
Plan








1.2
Do








1.3
Check








1.4
Act










2
About








3
See also








4
References








5
Further reading










1.1
Plan








1.2
Do








1.3
Check








1.4
Act






















PDCA or plan–do–check–act (sometimes called plan–do–check–adjust) is an iterative design and management method used in business for the control and continual improvement of processes and products.[1] It is also known as the Shewhart cycle, or the control circle/cycle. Another version of this PDCA cycle is OPDCA.[2] The added "O" stands for observation or as some versions say: "Observe the current condition." This emphasis on observation and current condition has currency with the literature on lean manufacturing and the Toyota Production System.[3] The PDCA cycle, with Ishikawa's changes, can be traced back to S. Mizuno of the Tokyo Institute of Technology in 1959.[4]

The PDCA cycle is also known as PDSA cycle (where S stands for study). It was an early means of representing the task areas of traditional quality management. The cycle is sometimes referred to as the Shewhart / Deming cycle since it originated with physicist Walter Shewhart at the Bell Telephone Laboratories in the 1920s. W. Edwards Deming modified the Shewhart cycle in the 1940s and subsequently applied it to management practices in Japan in the 1950s.[5]

Deming found that the focus on Check is more about the implementation of a change, with success or failure. His focus was on predicting the results of an improvement effort, studying the actual results, and comparing them to possibly revise the theory.

Establish objectives and processes required to deliver the desired results.

Carry out the objectives from the previous step.

During the check phase, the data and results gathered from the do phase are evaluated. Data is compared to the expected outcomes to see any similarities and differences. The testing process is also evaluated to see if there were any changes from the original test created during the planning phase. If the data is placed in a chart it can make it easier to see any trends if the plan–do–check–act cycle is conducted multiple times. This helps to see what changes work better than others and if said changes can be improved as well.

Example: Gap analysis or appraisals

Also called "adjust", this act phase is where a process is improved. Records from the "do" and "check" phases help identify issues with the process. These issues may include problems, non-conformities, opportunities for improvement, inefficiencies, and other issues that result in outcomes that are evidently less-than-optimal. Root causes of such issues are investigated, found, and eliminated by modifying the process. Risk is re-evaluated. At the end of the actions in this phase, the process has better instructions, standards, or goals. Planning for the next cycle can proceed with a better baseline. Work in the next do phase should not create a recurrence of the identified issues; if it does, then the action was not effective.

Plan–do–check–act is associated with W. Edwards Deming, who is considered by many to be the father of modern quality control; however, he used PDSA (Plan-Do-Study-Act) and referred to it as the "Shewhart cycle".[6] Later in Deming's career, he modified PDCA to "Plan, Do, Study, Act" (PDSA) because he felt that "check" emphasized inspection over analysis.[7] The PDSA cycle was used to create the model of know-how transfer process,[8] and other models.[9]

The concept of PDCA is based on the scientific method, as developed from the work of Francis Bacon (Novum Organum, 1620). The scientific method can be written as "hypothesis–experiment–evaluation" or as "plan–do–check". Walter A. Shewhart described manufacture under "control"—under statistical control—as a three-step process of specification, production, and inspection.[10]: 45  He also specifically related this to the scientific method of hypothesis, experiment, and evaluation. Shewhart says that the statistician "must help to change the demand [for goods] by showing [...] how to close up the tolerance range and to improve the quality of goods."[10]: 48  Clearly, Shewhart intended the analyst to take action based on the conclusions of the evaluation. According to Deming, during his lectures in Japan in the early 1920s, the Japanese participants shortened the steps to the now traditional plan, do, check, act.[4] Deming preferred plan, do, study, act because "study" has connotations in English closer to Shewhart's intent than "check".[11]

A fundamental principle of the scientific method and plan–do–check–act is iteration—once a hypothesis is confirmed (or negated), executing the cycle again will extend the knowledge further. Repeating the PDCA cycle can bring its users closer to the goal, usually a perfect operation and output.[11]

Plan–do–check–act (and other forms of scientific problem solving) is also known as a system for developing critical thinking. At Toyota this is also known as "Building people before building cars".[12] Toyota and other lean manufacturing companies propose that an engaged, problem-solving workforce using PDCA in a culture of critical thinking is better able to innovate and stay ahead of the competition through rigorous problem solving and the subsequent innovations.[12]

Deming continually emphasized iterating towards an improved system, hence PDCA should be implemented in spirals of increasing knowledge of the system that converge on the ultimate goal, each cycle closer than the previous.[13] One can envision an open coil spring, with each loop being one cycle of the scientific method, and each complete cycle indicating an increase in our knowledge of the system under study. This approach is based on the belief that our knowledge and skills are limited, but improving. Especially at the start of a project, key information may not be known; the PDCA—scientific method—provides feedback to justify guesses (hypotheses) and increase knowledge. Rather than enter "analysis paralysis" to get it perfect the first time, it is better to be approximately right than exactly wrong. With improved knowledge, one may choose to refine or alter the goal (ideal state). The aim of the PDCA cycle is to bring its users closer to whatever goal they choose.[3]: 160 

When PDCA is used for complex projects or products with a certain controversy, checking with external stakeholders should happen before the Do stage, since changes to projects and products that are already in detailed design can be costly; this is also seen as Plan-Check-Do-Act.[citation needed]

The rate of change, that is, the rate of improvement, is a key competitive factor in today's world.[citation needed] PDCA allows for major "jumps" in performance ("breakthroughs" often desired in a Western approach), as well as kaizen (frequent small improvements).[14] In the United States a PDCA approach is usually associated with a sizable project involving numerous people's time,[citation needed] and thus managers want to see large "breakthrough" improvements to justify the effort expended. However, the scientific method and PDCA apply to all sorts of projects and improvement activities.[3]: 76 

COBIT, a business-focused framework for IT management and governance
Decision cycle, sequence of steps used on a repeated basis
DMAIC (define, measure, analyze, improve and control), an improvement cycle originally from Six Sigma process improvement system
Intelligence cycle, model of military and law enforcement intelligence processing
Kolb's experiential learning
Lean manufacturing
Learning cycle
Lesson study, a teaching improvement process
Monitoring and evaluation
OODA loop (observe–orient–decide–act loop), feedback loop used at operational level in combat operations
Performance management
Quality storyboard
Robert S. Kaplan (closed loop management system)
Six Sigma
Software development process
Theory of constraints
Total security management
American inventionsQuality managementProject management techniquesSystems analysis
Articles with short descriptionShort description is different from WikidataAll articles with unsourced statementsArticles with unsourced statements from October 2017Commons category link is on Wikidata






# Pair_programming.md




(Top)





1
Economics








2
Design quality








3
Satisfaction








4
Learning








5
Team-building and communication








6
Studies








7
Indicators of non-performance








8
Pairing variations








9
Remote pair programming








10
See also








11
References








12
External links






























Pair programming is a software development technique in which two programmers work together at one workstation. One, the driver, writes code while the other, the observer or navigator,[1] reviews each line of code as it is typed in. The two programmers switch roles frequently.

While reviewing, the observer also considers the "strategic" direction of the work, coming up with ideas for improvements and likely future problems to address. This is intended to free the driver to focus all of their attention on the "tactical" aspects of completing the current task, using the observer as a safety net and guide.

Pair programming increases the man-hours required to deliver code compared to programmers working individually.[2] However, the resulting code has fewer defects.[3] Along with code development time, other factors like field support costs and quality assurance also figure into the return on investment. Pair programming might theoretically offset these expenses by reducing defects in the programs.[3]

In addition to preventing mistakes as they are made, other intangible benefits may exist. For example, the courtesy of rejecting phone calls or other distractions while working together, taking fewer breaks at agreed-upon intervals or sharing breaks to return phone calls (but returning to work quickly since someone is waiting). One member of the team might have more focus and help drive or awaken the other if they lose focus, and that role might periodically change. One member might know about a topic or technique that the other does not, which might eliminate delays to finding or testing a solution, or allow for a better solution, thus effectively expanding the skill set, knowledge, and experience of a programmer as compared to working alone. Each of these intangible benefits, and many more, may be challenging to accurately measure but can contribute to more efficient working hours.[citation needed]

A system with two programmers possesses greater potential for the generation of more diverse solutions to problems for three reasons:

the programmers bring different prior experiences to the task;
they may assess information relevant to the task in different ways;
they stand in different relationships to the problem by their functional roles.
In an attempt to share goals and plans, the programmers must overtly negotiate a shared course of action when a conflict arises between them. In doing so, they consider a larger number of ways of solving the problem than a single programmer alone might do. This significantly improves the design quality of the program as it reduces the chances of selecting a poor method.[4]

In an online survey of pair programmers from 2000, 96% of programmers stated that they enjoyed working more while pair programming than programming alone. Furthermore, 95% said that they were more confident in their work when they pair programmed. However, as the survey was among self-selected pair programmers, it did not account for programmers who were forced to pair program.[5]

Knowledge is constantly shared between pair programmers, whether in the industry or in a classroom. Many sources suggest that students show higher confidence when programming in pairs,[5] and many learn whether it be from tips on programming language rules to overall design skills.[6] In "promiscuous pairing", each programmer communicates and works with all the other programmers on the team rather than pairing only with one partner, which causes knowledge of the system to spread throughout the whole team.[3] Pair programming allows programmers to examine their partner's code and provide feedback, which is necessary to increase their own ability to develop monitoring mechanisms for their own learning activities.[6]

Pair programming allows team members to share quickly, making them less likely to have agendas hidden from each other. This helps pair programmers learn to communicate more easily. "This raises the communication bandwidth and frequency within the project, increasing overall information flow within the team."[3]

There are both empirical studies and meta-analyses of pair programming. The empirical studies tend to examine the level of productivity and the quality of the code, while meta-analyses may focus on biases introduced by the process of testing and publishing.

A meta-analysis found pairs typically consider more design alternatives than programmers working alone, arrive at simpler, more maintainable designs, and catch design defects earlier. However, it raised concerns that its findings may have been influenced by "signs of publication bias among published studies on pair programming." It concluded that "pair programming is not uniformly beneficial or effective."[7]

Although pair programmers may complete a task faster than a solo programmer, the total number of man-hours increases.[2] A manager would have to balance faster completion of the work and reduced testing and debugging time against the higher cost of coding. The relative weight of these factors can vary by project and task.

The benefit of pairing is greatest on tasks that the programmers do not fully understand before they begin: that is, challenging tasks that call for creativity and sophistication, and for novices as compared to experts.[2] Pair programming could be helpful for attaining high quality and correctness on complex programming tasks, but it would also increase the development effort (cost) significantly.[7]

On simple tasks, which the pair already fully understands, pairing results in a net drop in productivity.[2][8] It may reduce the code development time but also risks reducing the quality of the program.[7] Productivity can also drop when novice–novice pairing is used without sufficient availability of a mentor to coach them.[9]

A study of programmers using AI assistance tools such as GitHub Copilot found that while some programmers conceived of AI assistance as similar to pair programming, in practice the use of such tools is very different in terms of the programmer experience, with the human programmer having to transition repeatedly between driver and navigator roles.[10]

There are indicators that a pair is not performing well: [opinion]

Disengagement may present as one of the members physically withdraws away from the keyboard, accesses email, or even falls asleep.
The "Watch the Master" phenomenon can arise if one member is more experienced than the other. In this situation, the junior member may take the observer role, deferring to the senior member of the pair for the majority of coding activity. This can easily lead to disengagement.
Remote pair programming, also known as virtual pair programming or distributed pair programming, is pair programming in which the two programmers are in different locations,[12] working via a collaborative real-time editor, shared desktop, or a remote pair programming IDE plugin. Remote pairing introduces difficulties not present in face-to-face pairing, such as extra delays for coordination, depending more on "heavyweight" task-tracking tools instead of "lightweight" ones like index cards, and loss of verbal communication resulting in confusion and conflicts over such things as who "has the keyboard".[13]

Tool support could be provided by:

Whole-screen sharing software[14][15][self-published source?]
Terminal multiplexers
Specialized distributed editing tools
Audio chat programs or VoIP software could be helpful when the screen sharing software does not provide two-way audio capability. Use of headsets keep the programmers' hands free
Cloud development environments
Collaborative pair programming services
Extreme programming
Joint attention
Mob programming
Team programming
Agile software developmentExtreme programmingSoftware review
Webarchive template wayback linksAll accuracy disputesAccuracy disputes from April 2016Articles with short descriptionShort description matches WikidataAll articles with unsourced statementsArticles with unsourced statements from April 2022All articles with minor POV problemsArticles with minor POV problems from May 2021All articles with self-published sourcesArticles with self-published sources from April 2016






# Planning_poker.md




(Top)





1
Process




Toggle Process subsection





1.1
Rationale








1.2
Equipment








1.3
Procedure










2
See also








3
References










1.1
Rationale








1.2
Equipment








1.3
Procedure
















This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Planning poker" – news · newspapers · books · scholar · JSTOR (February 2012) (Learn how and when to remove this message)


Planning poker, also called Scrum poker, is a consensus-based, gamified technique for estimating, mostly used for timeboxing in Agile principles. In planning poker, members of the group make estimates by playing numbered cards face-down to the table, instead of speaking them aloud. The cards are revealed, and the estimates are then discussed. By hiding the figures in this way, the group can avoid the cognitive bias of anchoring, where the first number spoken aloud sets a precedent for subsequent estimates.

Planning poker is a variation of the Wideband delphi method. It is most commonly used in agile software development, in particular in Scrum and Extreme Programming. Agile software development methods recommend the use of Planning Poker for estimating the size of user stories and developing release and iteration plans. [1]

The method was first defined and named by James Grenning in 2002[2] and later popularized by Mike Cohn in the book Agile Estimating and Planning,[3] whose company trade marked the term[4] and a digital online tool.[5]

The reason to use planning poker is to avoid the influence of the other participants. If a number is spoken, it can sound like a suggestion and influence the other participants' sizing. Planning poker should force people to think independently and propose their numbers simultaneously. This is accomplished by requiring that all participants show their cards at the same time.

Planning poker is based on a list of features to be delivered, several copies of a deck of cards, and optionally, an egg timer that can be used to limit time spent in discussion of each item.

The feature list, often a list of user stories, describes some software that needs to be developed.

The cards in the deck have numbers on them. A typical deck has cards showing the Fibonacci sequence including a zero: 0, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89; other decks use similar progressions with a fixed ratio between each value such as 1, 2, 4, 8, etc.

The reason for using the Fibonacci sequence instead of simply doubling each subsequent value is because estimating a task as exactly double the effort as another task is misleadingly precise. A task that is about twice as much effort as a 5, has to be evaluated as either a bit less than double (8) or a bit more than double (13).

Several commercially available decks use the sequence: 0, ½, 1, 2, 3, 5, 8, 13, 20, 40, 100, and optionally a ? (unsure), an infinity symbol (this task cannot be completed), and a coffee cup (I need a break, and I will make the rest of the team coffee). The reason for not exactly following the Fibonacci sequence after 13 is because someone once said to Mike Cohn "You must be very certain to have estimated that task as 21 instead of 20." Using numbers with only a single digit of precision (except for 13) indicates the uncertainty in the estimation. Alternatively standard playing cards of Ace, 2, 3, 5, 8, and king can be used. Where king means: "this item is too big or too complicated to estimate". "Throwing a king" ends the discussion of the item for the current sprint.

When teams are not in the same geographical locations, collaborative software over the internet can be used as replacement for physical cards. Several web applications and mobile applications exist for the purpose.

At the estimation meeting, each estimator is given one deck of the cards. All decks have identical sets of cards in them.

The meeting proceeds as follows:

A Moderator, who will not play, chairs the meeting.
The Product Owner provides a short overview of one user story to be estimated. The team is given an opportunity to ask questions and discuss to clarify assumptions and risks. A summary of the discussion is recorded, e.g. by the Moderator.
Each individual lays a card face down representing their estimate for the story. Units used vary - they can be days duration, ideal days, t-shirt sizes[6] or story points. During the discussion, estimations must not be mentioned at all in relation to feature size to avoid anchoring.
Everyone calls their cards simultaneously by turning them over.
People with high estimates and low estimates are given a soap box to offer their justification for their estimate and then the discussion continues.
Repeat the estimation process until a consensus is reached. The developer who was likely to own the deliverable has a large portion of the "consensus vote", although the Moderator can negotiate the consensus.
To ensure that discussion is structured; the Moderator or the Product Owner may at any point turn over the egg timer and when it runs out all discussion must cease and another round of poker is played. The structure in the conversation is re-introduced by the soapboxes.
The cards are numbered as they are to account for the fact that the longer an estimate is, the more uncertainty it contains. Thus, if a developer wants to play a 6 he is forced to reconsider and either work through that some of the perceived uncertainty does not exist and play a 5, or accept a conservative estimate accounting for the uncertainty and play an 8.

Comparison of scrum software, which generally has support for planning poker, either included or as an optional add-on.
Agile software developmentSoftware project managementSoftware development philosophies
Articles with short descriptionShort description matches WikidataArticles needing additional references from February 2012All articles needing additional referencesUse American English from February 2022All Wikipedia articles written in American EnglishUse dmy dates from January 2020






# Product_backlog.md




(Top)





1
Outline








2
References










Within agile project management, product backlog refers to a prioritized list of functionality which a product should contain. It is sometimes referred to as a to-do list,[1] and is considered an 'artifact' (a form of documentation) within the scrum software development framework.[2] The product backlog is referred to with different names in different project management frameworks, such as product backlog in scrum,[2][3] work item list in disciplined agile,[3][4] and option pool in lean.[3] In the scrum framework, creation and continuous maintenance of the product backlog is part of the responsibility of the product owner.[5]

A sprint backlog[6] consists of selected elements from the product backlog which are planned to be developed within that particular sprint.

In scrum, coherence is defined as a measure of the relationships between backlog items which make them worthy of consideration as a whole.[7]

The agile product backlog in scrum is a prioritized features list, containing short descriptions of all functionality desired in the product. When applying the scrum or other agile development methodology, it is not necessary to start a project with a lengthy, upfront effort to document all requirements as is more common with traditional project management methods following the waterfall model.[citation needed] Instead, a scrum team and its product owner will typically begin by writing down every relevant feature they can think of for the project's agile backlog prioritization, and the initial agile product backlog is almost always more than enough for a first sprint. The scrum product backlog is then allowed to grow further throughout the project life cycle and change as more is learned about the product and its customers.

A typical scrum backlog comprises the following different types of items:[clarification needed]

Features
Bugs
Technical work
Knowledge acquisition
Computing terminologyAgile software development
All articles with unsourced statementsArticles with unsourced statements from December 2021Wikipedia articles needing clarification from December 2021






# Project_management.md




(Top)





1
History








2
Project management types








3
Approaches of project management




Toggle Approaches of project management subsection





3.1
Benefits realization management








3.2
Critical path method








3.3
Critical chain project management








3.4
Earned value management








3.5
Iterative and incremental project management








3.6
Lean project management








3.7
Project lifecycle








3.8
Process-based management








3.9
Project production management








3.10
Product-based planning










4
Process groups




Toggle Process groups subsection





4.1
Initiating








4.2
Planning








4.3
Executing








4.4
Project documentation








4.5
Monitoring and controlling








4.6
Closing








4.7
Project control and project control systems










5
Characteristics of projects




Toggle Characteristics of projects subsection





5.1
Project complexity








5.2
Positive, appropriate (requisite), and negative complexity










6
Project managers








7
Multilevel success framework and criteria - project success vs. project performance








8
Risk management








9
Work breakdown structure and other breakdown structures








10
International standards








11
Program management and project networks








12
Project portfolio management








13
Project management software








14
Virtual project management








15
See also




Toggle See also subsection





15.1
Related fields








15.2
Related subjects








15.3
Lists










16
References








17
External links














3.1
Benefits realization management








3.2
Critical path method








3.3
Critical chain project management








3.4
Earned value management








3.5
Iterative and incremental project management








3.6
Lean project management








3.7
Project lifecycle








3.8
Process-based management








3.9
Project production management








3.10
Product-based planning






























4.1
Initiating








4.2
Planning








4.3
Executing








4.4
Project documentation








4.5
Monitoring and controlling








4.6
Closing








4.7
Project control and project control systems
























5.1
Project complexity








5.2
Positive, appropriate (requisite), and negative complexity
































15.1
Related fields








15.2
Related subjects








15.3
Lists


















Business administration
Management of a business
Accounting
Management accounting
Financial accounting
Audit

Business entity (list)
Corporate group
Corporation sole
Company
Conglomerate
Holding company
Cooperative
Corporation
Joint-stock company
Limited liability company
Partnership
Privately held company
Sole proprietorship
State-owned enterprise

Corporate governance
Annual general meeting
Board of directors
Supervisory board
Advisory board
Audit committee

Corporate law
Commercial law
Constitutional documents
Contract
Corporate crime
Corporate liability
Insolvency law
International trade law
Mergers and acquisitions

Corporate title
Chairman
Chief business officer/Chief brand officer
Chief executive officer/Chief operating officer
Chief financial officer
Chief human resources officer
Chief information officer/Chief marketing officer
Chief product officer/Chief technology officer

Economics
Commodity
Public economics
Labour economics
Development economics
International economics
Mixed economy
Planned economy
Econometrics
Environmental economics
Open economy
Market economy
Knowledge economy
Microeconomics
Macroeconomics
Economic development
Economic statistics

Finance
Financial statement
Insurance
Factoring
Cash conversion cycle
Insider dealing
Capital budgeting
Commercial bank
Derivative
Financial statement analysis
Financial risk
Public finance
Corporate finance
Managerial finance
International finance
Liquidation
Stock market
Financial market
Tax
Financial institution
Capital management
Venture capital

Types of management
Asset
Brand
Business intelligence
Business development
Capacity
Capability
Change
innovation
Commercial
Marketing
Communications
Configuration
Conflict
Content
Customer relationship
Distributed
Earned value
Electronic business
Enterprise resource planning 
management information system
Financial
Human resource 
development
Incident
Knowledge
Legal
Materials
Network
administrator
Office
Operations 
services
Performance
Power
Problem
Process
Product life-cycle
Product
Project
Property
Quality
Records
Resource
Risk 
crisis
Sales
Security
Service
Strategic
Supply chain
Systems
administrator
Talent
Technology

Organization
Architecture
Behavior
Communication
Culture
Conflict
Development
Engineering
Hierarchy
Patterns
Space
Structure

Trade
Business analysis
Business ethics
Business plan
Business judgment rule
Consumer behaviour
Business operations
International business
Business model
International trade
Trade route
Business process
Business statistics

 Business and economics portalvte
Management accounting
Financial accounting
Audit
Corporate group
Corporation sole
Company
Conglomerate
Holding company
Cooperative
Corporation
Joint-stock company
Limited liability company
Partnership
Privately held company
Sole proprietorship
State-owned enterprise
Annual general meeting
Board of directors
Supervisory board
Advisory board
Audit committee
Commercial law
Constitutional documents
Contract
Corporate crime
Corporate liability
Insolvency law
International trade law
Mergers and acquisitions
Chairman
Chief business officer/Chief brand officer
Chief executive officer/Chief operating officer
Chief financial officer
Chief human resources officer
Chief information officer/Chief marketing officer
Chief product officer/Chief technology officer
Commodity
Public economics
Labour economics
Development economics
International economics
Mixed economy
Planned economy
Econometrics
Environmental economics
Open economy
Market economy
Knowledge economy
Microeconomics
Macroeconomics
Economic development
Economic statistics
Financial statement
Insurance
Factoring
Cash conversion cycle
Insider dealing
Capital budgeting
Commercial bank
Derivative
Financial statement analysis
Financial risk
Public finance
Corporate finance
Managerial finance
International finance
Liquidation
Stock market
Financial market
Tax
Financial institution
Capital management
Venture capital
Asset
Brand
Business intelligence
Business development
Capacity
Capability
Change
innovation
Commercial
Marketing
Communications
Configuration
Conflict
Content
Customer relationship
Distributed
Earned value
Electronic business
Enterprise resource planning 
management information system
Financial
Human resource 
development
Incident
Knowledge
Legal
Materials
Network
administrator
Office
Operations 
services
Performance
Power
Problem
Process
Product life-cycle
Product
Project
Property
Quality
Records
Resource
Risk 
crisis
Sales
Security
Service
Strategic
Supply chain
Systems
administrator
Talent
Technology
innovation
Marketing
management information system
development
administrator
services
crisis
administrator
Architecture
Behavior
Communication
Culture
Conflict
Development
Engineering
Hierarchy
Patterns
Space
Structure
Business analysis
Business ethics
Business plan
Business judgment rule
Consumer behaviour
Business operations
International business
Business model
International trade
Trade route
Business process
Business statistics
Trade route
 Business and economics portal
vte
Project management is the process of supervising the work of a team to achieve all project goals within the given constraints.[1] This information is usually described in project documentation, created at the beginning of the development process. The primary constraints are scope, time, and budget.[2] The secondary challenge is to optimize the allocation of necessary inputs and apply them to meet pre-defined objectives.

The objective of project management is to produce a complete project which complies with the client's objectives. In many cases, the objective of project management is also to shape or reform the client's brief to feasibly address the client's objectives. Once the client's objectives are established, they should influence all decisions made by other people involved in the project– for example, project managers, designers, contractors, and subcontractors. Ill-defined or too tightly prescribed project management objectives are detrimental to decision-making.

A project is a temporary and unique endeavor designed to produce a product, service, or result with a defined beginning and end (usually time-constrained, and often constrained by funding or staffing) undertaken to meet unique goals and objectives, typically to bring about beneficial change or added value.[3][4] The temporary nature of projects stands in contrast with business as usual (or operations),[5] which are repetitive, permanent, or semi-permanent functional activities to produce products or services. In practice, the management of such distinct production approaches requires the development of distinct technical skills and management strategies.[6]

Until 1900, civil engineering projects were generally managed by creative architects, engineers, and master builders themselves, for example, Vitruvius (first century BC), Christopher Wren (1632–1723), Thomas Telford (1757–1834), and Isambard Kingdom Brunel (1806–1859).[7] In the 1950s, organizations started to apply project-management tools and techniques more systematically to complex engineering projects.[8]

As a discipline, project management developed from several fields of application including civil construction, engineering, and heavy defense activity.[9] Two forefathers of project management are Henry Gantt, called the father of planning and control techniques,[10] who is famous for his use of the Gantt chart as a project management tool (alternatively Harmonogram first proposed by Karol Adamiecki);[11] and Henri Fayol for his creation of the five management functions that form the foundation of the body of knowledge associated with project and program management.[12] Both Gantt and Fayol were students of Frederick Winslow Taylor's theories of scientific management. His work is the forerunner to modern project management tools including work breakdown structure (WBS) and resource allocation.

The 1950s marked the beginning of the modern project management era, where core engineering fields came together to work as one. Project management became recognized as a distinct discipline arising from the management discipline with the engineering model.[13] In the United States, prior to the 1950s, projects were managed on an ad-hoc basis, using mostly Gantt charts and informal techniques and tools. At that time, two mathematical project-scheduling models were developed. The critical path method (CPM) was developed as a joint venture between DuPont Corporation and Remington Rand Corporation for managing plant maintenance projects. The program evaluation and review technique (PERT), was developed by the U.S. Navy Special Projects Office in conjunction with the Lockheed Corporation and Booz Allen Hamilton as part of the Polaris missile submarine program.[14]

PERT and CPM are very similar in their approach but still present some differences. CPM is used for projects that assume deterministic activity times; the times at which each activity will be carried out are known. PERT, on the other hand, allows for stochastic activity times; the times at which each activity will be carried out are uncertain or varied. Because of this core difference, CPM and PERT are used in different contexts. These mathematical techniques quickly spread into many private enterprises.

At the same time, as project-scheduling models were being developed, technology for project cost estimating, cost management and engineering economics was evolving, with pioneering work by Hans Lang and others. In 1956, the American Association of Cost Engineers (now AACE International; the Association for the Advancement of Cost Engineering) was formed by early practitioners of project management and the associated specialties of planning and scheduling, cost estimating, and project control. AACE continued its pioneering work and in 2006, released the first integrated process for portfolio, program, and project management (total cost management framework).

In 1969, the Project Management Institute (PMI) was formed in the USA.[15] PMI publishes the original version of A Guide to the Project Management Body of Knowledge (PMBOK Guide) in 1996 with William Duncan as its primary author, which describes project management practices that are common to "most projects, most of the time."[16]

Project management methods can be applied to any project. It is often tailored to a specific type of project based on project size, nature, industry or sector. For example, the construction industry, which focuses on the delivery of things like buildings, roads, and bridges, has developed its own specialized form of project management that it refers to as construction project management and in which project managers can become trained and certified.[17] The information technology industry has also evolved to develop its own form of project management that is referred to as IT project management and which specializes in the delivery of technical assets and services that are required to pass through various lifecycle phases such as planning, design, development, testing, and deployment. Biotechnology project management focuses on the intricacies of biotechnology research and development.[18] Localization project management includes application of many standard project management practices to translation works even though many consider this type of management to be a very different discipline. For example, project managers have a key role in improving the translation even when they do not speak the language of the translation, because they know the study objectives well to make informed decisions.[19] Similarly, research study management can also apply a project manage approach.[20] There is public project management that covers all public works by the government, which can be carried out by the government agencies or contracted out to contractors. Another classification of project management is based on the hard (physical) or soft (non-physical) type.

Common among all the project management types is that they focus on three important goals: time, quality, and cost. Successful projects are completed on schedule, within budget, and according to previously agreed quality standards i.e. meeting the Iron Triangle or Triple Constraint in order for projects to be considered a success or failure.[21]

For each type of project management, project managers develop and utilize repeatable templates that are specific to the industry they're dealing with. This allows project plans to become very thorough and highly repeatable, with the specific intent to increase quality, lower delivery costs, and lower time to deliver project results.

A 2017 study suggested that the success of any project depends on how well four key aspects are aligned with the contextual dynamics affecting the project, these are referred to as the four P's:[22]

Plan: The planning and forecasting activities.
Process: The overall approach to all activities and project governance.
People: Including dynamics of how they collaborate and communicate.
Power: Lines of authority, decision-makers, organograms, policies for implementation and the like.
There are a number of approaches to organizing and completing project activities, including phased, lean, iterative, and incremental. There are also several extensions to project planning, for example, based on outcomes (product-based) or activities (process-based).

Regardless of the methodology employed, careful consideration must be given to the overall project objectives, timeline, and cost, as well as the roles and responsibilities of all participants and stakeholders.[23]

Benefits realization management (BRM) enhances normal project management techniques through a focus on outcomes (benefits) of a project rather than products or outputs and then measuring the degree to which that is happening to keep a project on track. This can help to reduce the risk of a completed project being a failure by delivering agreed upon requirements (outputs) i.e. project success but failing to deliver the benefits (outcomes) of those requirements i.e. product success. Note that good requirements management will ensure these benefits are captured as requirements of the project and their achievement monitored throughout the project.

In addition, BRM practices aim to ensure the strategic alignment between project outcomes and business strategies. The effectiveness of these practices is supported by recent research evidencing BRM practices influencing project success from a strategic perspective across different countries and industries. These wider effects are called the strategic impact.[24]

An example of delivering a project to requirements might be agreeing to deliver a computer system that will process staff data and manage payroll, holiday, and staff personnel records in shorter times with reduced errors. Under BRM, the agreement might be to achieve a specified reduction in staff hours and errors required to process and maintain staff data after the system installation when compared without the system.

Critical path method (CPM) is an algorithm for determining the schedule for project activities. It is the traditional process used for predictive-based project planning. The CPM method evaluates the sequence of activities, the work effort required, the inter-dependencies, and the resulting float time per line sequence to determine the required project duration. Thus, by definition, the critical path is the pathway of tasks on the network diagram that has no extra time available (or very little extra time)."[25]

Critical chain project management (CCPM) is an application of the theory of constraints (TOC) to planning and managing projects and is designed to deal with the uncertainties inherent in managing projects, while taking into consideration the limited availability of resources (physical, human skills, as well as management & support capacity) needed to execute projects.

The goal is to increase the flow of projects in an organization (throughput). Applying the first three of the five focusing steps of TOC, the system constraint for all projects, as well as the resources, are identified. To exploit the constraint, tasks on the critical chain are given priority over all other activities.

Earned value management (EVM) extends project management with techniques to improve project monitoring.[26] It illustrates project progress towards completion in terms of work and value (cost). Earned Schedule is an extension to the theory and practice of EVM.

In critical studies of project management, it has been noted that phased approaches are not well suited for projects which are large-scale and multi-company,[27] with undefined, ambiguous, or fast-changing requirements,[28] or those with high degrees of risk, dependency, and fast-changing technologies. The cone of uncertainty explains some of this as the planning made on the initial phase of the project suffers from a high degree of uncertainty. This becomes especially true as software development is often the realization of a new or novel product.

These complexities are better handled with a more exploratory or iterative and incremental approach.[29] Several models of iterative and incremental project management have evolved, including agile project management, dynamic systems development method, extreme project management, and Innovation Engineering®.[30]

Lean project management uses the principles from lean manufacturing to focus on delivering value with less waste and reduced time.


There are five phases to a project lifecycle; known as process groups. Each process group represents a series of inter-related processes to manage the work through a series of distinct steps to be completed. This type of project approach is often referred to as "traditional"[31] or "waterfall".[32] The five process groups are:
Initiating
Planning
Executing
Monitoring and Controlling
Closing
Some industries may use variations of these project stages and rename them to better suit the organization. For example, when working on a brick-and-mortar design and construction, projects will typically progress through stages like pre-planning, conceptual design, schematic design, design development, construction drawings (or contract documents), and construction administration.

While the phased approach works well for small, well-defined projects, it often results in challenge or failure on larger projects, or those that are more complex or have more ambiguities, issues, and risks[33] - see the parodying 'six phases of a big project'.

The incorporation of process-based management has been driven by the use of maturity models such as the OPM3 and the CMMI (capability maturity model integration; see Image:Capability Maturity Model.jpg

Project production management is the application of operations management to the delivery of capital projects. The Project production management framework is based on a project as a production system view, in which a project transforms inputs (raw materials, information, labor, plant & machinery) into outputs (goods and services).[34]

Product-based planning is a structured approach to project management, based on identifying all of the products (project deliverables) that contribute to achieving the project objectives. As such, it defines a successful project as output-oriented rather than activity- or task-oriented.[35] The most common implementation of this approach is PRINCE2.[36]

Traditionally (depending on what project management methodology is being used), project management includes a number of elements: four to five project management process groups, and a control system. Regardless of the methodology or terminology used, the same basic project management processes or stages of development will be used. Major process groups generally include:[38]

Initiation
Planning
Production or execution
Monitoring and controlling
Closing
In project environments with a significant exploratory element (e.g., research and development), these stages may be supplemented with decision points (go/no go decisions) at which the project's continuation is debated and decided. An example is the Phase–gate model.

The initiating processes determine the nature and scope of the project.[39] If this stage is not performed well, it is unlikely that the project will be successful in meeting the business' needs. The key project controls needed here are an understanding of the business environment and making sure that all necessary controls are incorporated into the project. Any deficiencies should be reported and a recommendation should be made to fix them.

The initiating stage should include a plan that encompasses the following areas. These areas can be recorded in a series of documents called Project Initiation documents.
Project Initiation documents are a series of planned documents used to create an order for the duration of the project. 
These tend to include: 

project proposal (idea behind project, overall goal, duration)
project scope (project direction and track)
product breakdown structure (PBS) (a hierarchy of deliverables/outcomes and components thereof)
work breakdown structure (WBS) (a hierarchy of the work to be done, down to daily tasks)
responsibility assignment matrix (RACI - Responsible, Accountable, Consulted, Informed) (roles and responsibilities aligned to deliverables / outcomes)
tentative project schedule (milestones, important dates, deadlines)
analysis of business needs and requirements against measurable goals
review of the current operations
financial analysis of the costs and benefits, including a budget
stakeholder analysis, including users and support personnel for the project
project charter including costs, tasks, deliverables, and schedules
SWOT analysis: strengths, weaknesses, opportunities, and threats to the business
After the initiation stage, the project is planned to an appropriate level of detail (see an example of a flowchart).[37] The main purpose is to plan time, cost, and resources adequately to estimate the work needed and to effectively manage risk during project execution. As with the Initiation process group, a failure to adequately plan greatly reduces the project's chances of successfully accomplishing its goals.

Project planning generally consists of[40]

determining the project management methodology to follow (e.g. whether the plan will be defined wholly upfront, iteratively, or in rolling waves);
developing the scope statement;
selecting the planning team;
identifying deliverables and creating the product and work breakdown structures;
identifying the activities needed to complete those deliverables and networking the activities in their logical sequence;
estimating the resource requirements for the activities;
estimating time and cost for activities;
developing the schedule;
developing the budget;
risk planning;
developing quality assurance measures;
gaining formal approval to begin work.
Additional processes, such as planning for communications and for scope management, identifying roles and responsibilities, determining what to purchase for the project, and holding a kick-off meeting are also generally advisable.

For new product development projects, conceptual design of the operation of the final product may be performed concurrent with the project planning activities and may help to inform the planning team when identifying deliverables and planning activities.

While executing we must know what are the planned terms that need to be executed.
The execution/implementation phase ensures that the project management plan's deliverables are executed accordingly. This phase involves proper allocation, coordination, and management of human resources and any other resources such as materials and budgets. The output of this phase is the project deliverables.

Documenting everything within a project is key to being successful. To maintain budget, scope, effectiveness and pace a project must have physical documents pertaining to each specific task. With correct documentation, it is easy to see whether or not a project's requirement has been met. To go along with that, documentation provides information regarding what has already been completed for that project. Documentation throughout a project provides a paper trail for anyone who needs to go back and reference the work in the past. 
In most cases, documentation is the most successful way to monitor and control the specific phases of a project. With the correct documentation, a project's success can be tracked and observed as the project goes on. If performed correctly documentation can be the backbone of a project's success

Monitoring and controlling consist of those processes performed to observe project execution so that potential problems can be identified in a timely manner and corrective action can be taken, when necessary, to control the execution of the project. The key benefit is that project performance is observed and measured regularly to identify variances from the project management plan.

Monitoring and controlling include:[41]

Measuring the ongoing project activities ('where we are');
Monitoring the project variables (cost, effort, scope, etc.) against the project management plan and the project performance baseline (where we should be);
Identifying corrective actions to address issues and risks properly (How can we get on track again);
Influencing the factors that could circumvent integrated change control so only approved changes are implemented.
Two main mechanisms support monitoring and controlling in projects. On the one hand, contracts offer a set of rules and incentives often supported by potential penalties and sanctions.[42] On the other hand, scholars in business and management have paid attention to the role of integrators (also called project barons) to achieve a project's objectives.[43][44] In turn, recent research in project management has questioned the type of interplay between contracts and integrators. Some have argued that these two monitoring mechanisms operate as substitutes[45] as one type of organization would decrease the advantages of using the other one.

In multi-phase projects, the monitoring and control process also provides feedback between project phases, to implement corrective or preventive actions to bring the project into compliance with the project management plan.

Project maintenance is an ongoing process, and it includes:[38]

Continuing support of end-users
Correction of errors
Updates to the product over time
In this stage, auditors should pay attention to how effectively and quickly user problems are resolved.

Over the course of any construction project, the work scope may change. Change is a normal and expected part of the construction process. Changes can be the result of necessary design modifications, differing site conditions, material availability, contractor-requested changes, value engineering, and impacts from third parties, to name a few. Beyond executing the change in the field, the change normally needs to be documented to show what was actually constructed. This is referred to as change management. Hence, the owner usually requires a final record to show all changes or, more specifically, any change that modifies the tangible portions of the finished work. The record is made on the contract documents – usually, but not necessarily limited to, the design drawings. The end product of this effort is what the industry terms as-built drawings, or more simply, "as built." The requirement for providing them is a norm in construction contracts. Construction document management is a highly important task undertaken with the aid of an online or desktop software system or maintained through physical documentation. The increasing legality pertaining to the construction industry's maintenance of correct documentation has caused an increase in the need for document management systems.

When changes are introduced to the project, the viability of the project has to be re-assessed. It is important not to lose sight of the initial goals and targets of the projects. When the changes accumulate, the forecasted result may not justify the original proposed investment in the project. Successful project management identifies these components, and tracks and monitors progress, so as to stay within time and budget frames already outlined at the commencement of the project. Exact methods were suggested to identify the most informative monitoring points along the project life-cycle regarding its progress and expected duration.[46]

Closing includes the formal acceptance of the project and the ending thereof. Administrative activities include the archiving of the files and documenting lessons learned.

This phase consists of:[38]

Contract closure: Complete and settle each contract (including the resolution of any open items) and close each contract applicable to the project or project phase.
Project close: Finalize all activities across all of the process groups to formally close the project or a project phase
Also included in this phase is the post implementation review. This is a vital phase of the project for the project team to learn from experiences and apply to future projects. Normally a post implementation review consists of looking at things that went well and analyzing things that went badly on the project to come up with lessons learned.

Project control (also known as Cost Engineering)
should be established as an independent function in project management. It implements verification and controlling functions during the processing of a project to reinforce the defined performance and formal goals.[47] The tasks of project control are also: 

the creation of infrastructure for the supply of the right information and its update
the establishment of a way to communicate disparities in project parameters
the development of project information technology based on an intranet or the determination of a project key performance indicator system (KPI)
divergence analyses and generation of proposals for potential project regulations[48]
the establishment of methods to accomplish an appropriate project structure, project workflow organization, project control, and governance
creation of transparency among the project parameters[49]
Fulfillment and implementation of these tasks can be achieved by applying specific methods and instruments of project control. The following methods of project control can be applied:

investment analysis
cost–benefit analysis
value benefit analysis
expert surveys
simulation calculations
risk-profile analysis
surcharge calculations
milestone trend analysis
cost trend analysis
target/actual comparison[50]
Project control is that element of a project that keeps it on track, on time, and within budget.[41] Project control begins early in the project with planning and ends late in the project with post-implementation review, having a thorough involvement of each step in the process. Projects may be audited or reviewed while the project is in progress. Formal audits are generally risk or compliance-based and management will direct the objectives of the audit. An examination may include a comparison of approved project management processes with how the project is actually being managed.[51] Each project should be assessed for the appropriate level of control needed: too much control is too time-consuming, too little control is very risky. If project control is not implemented correctly, the cost to the business should be clarified in terms of errors and fixes.

Control systems are needed for cost, risk, quality, communication, time, change, procurement, and human resources. In addition, auditors should consider how important the projects are to the financial statements, how reliant the stakeholders are on controls, and how many controls exist. Auditors should review the development process and procedures for how they are implemented. The process of development and the quality of the final product may also be assessed if needed or requested. A business may want the auditing firm to be involved throughout the process to catch problems earlier on so that they can be fixed more easily. An auditor can serve as a controls consultant as part of the development team or as an independent auditor as part of an audit.

Businesses sometimes use formal systems development processes. This help assure systems are developed successfully. A formal process is more effective in creating strong controls, and auditors should review this process to confirm that it is well designed and is followed in practice. A good formal systems development plan outlines:

A strategy to align development with the organization's broader objectives
Standards for new systems
Project management policies for timing and budgeting
Procedures describing the process
Evaluation of quality of change
There are five important characteristics of a project:

(i) It should always have specific start and end dates.

(ii) They are performed and completed by a group of people.

(iii) The output is the delivery of a unique product or service.

(iv) They are temporary in nature.

(v) It is progressively elaborated.

Examples are: designing a new car or writing a book.

Complexity and its nature play an important role in the area of project management. Despite having a number of debates on this subject matter, studies suggest a lack of definition and reasonable understanding of complexity in relation to the management of complex projects.[52][53]

Project complexity is the property of a project which makes it difficult to understand, foresee, and keep under control its overall behavior, even when given reasonably complete information about the project system.[54]

The identification of complex projects is specifically important to multi-project engineering environments.[55]

As it is considered that project complexity and project performance are closely related, it is important to define and measure the complexity of the project for project management to be effective.[56]

Complexity can be:

Structural complexity (also known as detail complexity, or complicatedness), i.e. consisting of many varied interrelated parts.[57] It is typically expressed in terms of size, variety, and interdependence of project components, and described by technological and organizational factors.
Dynamic complexity refers to phenomena, characteristics, and manifestations such as ambiguity, uncertainty, propagation, emergence, and chaos.[54]
Based on the Cynefin framework,[58] complex projects can be classified as:

Simple (or clear, obvious, known) projects, systems, or contexts. These are characterized by known knowns, stability, and clear cause-and-effect relationships. They can be solved with standard operating procedures and best practices.
Complicated: characterized by known unknowns. A complicated system is the sum of its parts. In principle, it can be deconstructed into smaller simpler components. While difficult, complicated problems are theoretically solvable with additional resources, specialized expertise, analytical, reductionist, simplification, decomposition techniques, scenario planning, and following good practices.[59][60]
Complex are characterized by unknown unknowns, and emergence. Patterns could be uncovered, but they are not obvious. A complex system can be described by Euclid's statement that the whole is more than the sum of its parts.
Really complex projects, a.k.a. very complex, or chaotic: characterized by unknowables. No patterns are discernible in really complex projects. Causes and effects are unclear even in retrospect. Paraphrasing Aristotle, a really complex system is different from the sum of its parts.[61]
By applying the discovery in measuring work complexity described in Requisite Organization and Stratified Systems Theory, Elliott Jaques classifies projects and project work (stages, tasks) into seven basic levels of project complexity based on such criteria as time-span of discretion and complexity of a project's output:[62][63]

Level 1 Project – improve the direct output of an activity (quantity, quality, time) within a business process with a targeted completion time up to 3 months.
Level 2 Project – develop and improve compliance to a business process with a targeted completion time of 3 months to 1 year.
Level 3 Project – develop, change, and improve a business process with a targeted completion time of 1 to 2 years.
Level 4 Project – develop, change, and improve a functional system with a targeted completion time of 2 to 5 years.
Level 5 Project – develop, change, and improve a group of functional systems/business functions with a targeted completion time of 5 to 10 years.
Level 6 Project – develop, change, and improve a whole single value chain of a company with targeted completion time from 10 to 20 years.
Level 7 Project – develop, change, and improve multiple value chains of a company with target completion time from 20 to 50 years.[64]
Benefits from measuring Project Complexity are to improve project people feasibility by matching the level of a project's complexity with an effective targeted completion time, with the respective capability level of the project manager and of the project members.[65]

Similarly with the Law of requisite variety and The law of requisite complexity, project complexity is sometimes required in order for the project to reach its objectives, and sometimes it has beneficial outcomes. Based on the effects of complexity, Stefan Morcov proposed its classification as Positive, Appropriate, or Negative.[66][61]

Positive complexity is the complexity that adds value to the project, and whose contribution to project success outweighs the associated negative consequences.
Appropriate (or requisite) complexity is the complexity that is needed for the project to reach its objectives, or whose contribution to project success balances the negative effects, or the cost of mitigation outweighs negative manifestations.
Negative complexity is the complexity that hinders project success.
This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (October 2022) (Learn how and when to remove this message)
A project manager is a professional in the field of project management. Project managers are in charge of the people in a project. People are the key to any successful project. Without the correct people in the right place and at the right time a project cannot be successful. Project managers can have the responsibility of the planning, execution, controlling, and closing of any project typically relating to the construction industry, engineering, architecture, computing, and telecommunications. Many other fields of production engineering, design engineering, and heavy industrial have project managers.

A project manager needs to understand the order of execution of a project to schedule the project correctly as well as the time necessary to accomplish each individual task within the project. A project manager is the person accountable for accomplishing the stated project objectives on behalf of the client. Project Managers tend to have multiple years' experience in their field. A project manager is required to know the project in and out while supervising the workers along with the project. Typically in most construction, engineering, architecture, and industrial projects, a project manager has another manager working alongside of them who is typically responsible for the execution of task on a daily basis. This position in some cases is known as a superintendent. A superintendent and project manager work hand in hand in completing daily project tasks. Key project management responsibilities include creating clear and attainable project objectives, building the project requirements, and managing the triple constraint (now including more constraints and calling it competing constraints) for projects, which is cost, time, quality and scope for the first three but about three additional ones in current project management. A typical project is composed of a team of workers who work under the project manager to complete the assignment within the time and budget targets. A project manager normally reports directly to someone of higher stature on the completion and success of the project.

A project manager is often a client representative and has to determine and implement the exact needs of the client, based on knowledge of the firm they are representing. The ability to adapt to the various internal procedures of the contracting party, and to form close links with the nominated representatives, is essential in ensuring that the key issues of cost, time, quality and above all, client satisfaction, can be realized.

A complete project manager, a term first coined by Robert J. Graham in his simulation, has been expanded upon by Randall L. Englund and Alfonso Bucero. They describe a complete project manager as a person who embraces multiple disciplines, such as leadership, influence, negotiations, politics, change and conflict management, and humor. These are all "soft" people skills that enable project leaders to be more effective and achieve optimized, consistent results.

There is a tendency to confuse the project success with project management success. They are two different things. "Project success" has 2 perspectives: 

the perspective of the process, i.e. delivering efficient outputs; typically called project management performance or project efficiency.
the perspective of the result, i.e. delivering beneficial outcomes; typically called project performance (sometimes just project success).[67][68][69][self-published source?]
Project management success criteria are different from project success criteria. The project management is said to be successful if the given project is completed within the agreed upon time, met the agreed upon scope and within the agreed upon budget. Subsequent to the triple constraints, multiple constraints have been considered to ensure project success. However, the triple or multiple constraints indicate only the efficiency measures of the project, which are indeed the project management success criteria during the project lifecycle.

The priori criteria leave out the more important after-completion results of the project which comprise four levels i.e. the output (product) success, outcome (benefits) success and impact (strategic) success during the product lifecycle. These posterior success criteria indicate the effectiveness measures of the project product, service or result, after the project completion and handover. This overarching multilevel success framework of projects, programs and portfolios has been developed by Paul Bannerman in 2008.[70] In other words, a project is said to be successful, when it succeeds in achieving the expected business case which needs to be clearly identified and defined during the project inception and selection before starting the development phase. This multilevel success framework conforms to the theory of project as a transformation depicted as the input-process / activity-output-outcome-impact in order to generate whatever value intended. Emanuel Camilleri in 2011 classifies all the critical success and failure factors into groups and matches each of them with the multilevel success criteria in order to deliver business value.[71]

An example of a performance indicator used in relation to project management is the "backlog of commissioned projects" or "project backlog".[72]

The United States Department of Defense states that "Cost, Schedule, Performance, and Risk" are the four elements through which Department of Defense acquisition professionals make trade-offs and track program status.[73] There are also international standards. Risk management applies proactive identification (see tools) of future problems and understanding of their consequences allowing predictive decisions about projects. ERM system plays a role in overall risk management.[74]

The work breakdown structure (WBS) is a tree structure that shows a subdivision of the activities required to achieve an objective – for example a portfolio, program, project, and contract. The WBS may be hardware-, product-, service-, or process-oriented (see an example in a NASA reporting structure (2001)).[75] Beside WBS for project scope management, there are organizational breakdown structure (chart), cost breakdown structure and risk breakdown structure.

A WBS can be developed by starting with the end objective and successively subdividing it into manageable components in terms of size, duration, and responsibility (e.g., systems, subsystems, components, tasks, sub-tasks, and work packages), which include all steps necessary to achieve the objective.[33]

The work breakdown structure provides a common framework for the natural development of the overall planning and control of a contract and is the basis for dividing work into definable increments from which the statement of work can be developed and technical, schedule, cost, and labor hour reporting can be established.[75]
The work breakdown structure can be displayed in two forms, as a table with subdivision of tasks or as an organizational chart whose lowest nodes are referred to as "work packages".

It is an essential element in assessing the quality of a plan, and an initial element used during the planning of the project. For example, a WBS is used when the project is scheduled, so that the use of work packages can be recorded and tracked.

Similarly to work breakdown structure (WBS), other decomposition techniques and tools are: organization breakdown structure (OBS), product breakdown structure (PBS), cost breakdown structure (CBS), risk breakdown structure (RBS), and resource breakdown structure (ResBS).[76][61]

There are several project management standards, including:

The ISO standards ISO 9000, a family of standards for quality management systems, and the ISO 10006:2003, for Quality management systems and guidelines for quality management in projects.
ISO 21500:2012 – Guidance on project management. This is the first International Standard related to project management published by ISO. Other standards in the 21500 family include 21503:2017 Guidance on programme management; 21504:2015 Guidance on portfolio management; 21505:2017 Guidance on governance; 21506:2018 Vocabulary; 21508:2018 Earned value management in project and programme management; and 21511:2018 Work breakdown structures for project and programme management.
ISO 21502:2020 Project, programme and portfolio management — Guidance on project management
ISO 21503:2022 Project, programme and portfolio management — Guidance on programme management
ISO 21504:2015 Project, programme and portfolio management – Guidance on portfolio management
ISO 21505:2017 Project, programme and portfolio management - Guidance on governance
ISO 31000:2009 – Risk management.
ISO/IEC/IEEE 16326:2009 – Systems and Software Engineering—Life Cycle Processes—Project Management[77]
Individual Competence Baseline (ICB) from the International Project Management Association (IPMA).[78]
Capability Maturity Model (CMM) from the Software Engineering Institute.
GAPPS, Global Alliance for Project Performance Standards – an open source standard describing COMPETENCIES for project and program managers.
HERMES method, Swiss general project management method, selected for use in Luxembourg and international organizations.
The logical framework approach (LFA), which is popular in international development organizations.
PMBOK Guide from the Project Management Institute (PMI).
PRINCE2 from AXELOS.
PM2: The Project Management methodology developed by the [European Commission].[79]
Procedures for Project Formulation and Management (PPFM) by the Indian Ministry of Defence [80]
Team Software Process (TSP) from the Software Engineering Institute.
Total Cost Management Framework, AACE International's Methodology for Integrated Portfolio, Program and Project Management.
V-Model, an original systems development method.
Some projects, either identical or different, can be managed as program management. 
Programs are collections of projects that support a common objective and set of goals. While individual projects have clearly defined and specific scope and timeline, a program's objectives and duration are defined with a lower level of granularity.

Besides programs and portfolios, additional structures that combine their different characteristics are: project networks, mega-projects, or mega-programs.

A project network is a temporary project formed of several different distinct evolving phases, crossing organizational lines. 
Mega-projects and mega-programs are defined as exceptional in terms of size, cost, public and political attention, and competencies required.[61]

An increasing number of organizations are using what is referred to as project portfolio management (PPM) as a means of selecting the right projects and then using project management techniques[81] as the means for delivering the outcomes in the form of benefits to the performing public, private or not-for-profit organization.

Portfolios are collections of similar projects. Portfolio management supports efficiencies of scale, increasing success rates, and reducing project risks, by applying similar standardized techniques to all projects in the portfolio, by a group of project management professionals sharing common tools and knowledge. 
Organizations often create project management offices as an organizational structure to support project portfolio management in a structured way.[61] 
Thus, PPM is usually performed by a dedicated team of managers organized within an enterprise project management office (PMO), usually based within the organization, and headed by a PMO director or chief project officer. In cases where strategic initiatives of an organization form the bulk of the PPM, the head of the PPM is sometimes titled as the chief initiative officer.

Project management software is software used to help plan, organize, and manage resource pools, develop resource estimates and implement plans. Depending on the sophistication of the software, functionality may include estimation and planning, scheduling, cost control and budget management, resource allocation, collaboration software, communication, decision-making, workflow, risk, quality, documentation, and/or administration systems.[82][83]

Virtual program management (VPM) is management of a project done by a virtual team, though it rarely may refer to a project implementing a virtual environment[84] It is noted that managing a virtual project is fundamentally different from managing traditional projects,[85] combining concerns of remote work and global collaboration (culture, time zones, language).[86]

Agile construction
Architectural engineering
Construction management
Cost engineering
Facilitation (business)
Industrial engineering
Project Production Management
Project management software
Project portfolio management
Project management office
Project workforce management
Software project management
Systems engineering
Agile management is the application of the principles of Agile software development and Lean Management to various management processes, particularly product development.
Decision-making
Game theory
Earned value management
Human factors
Kanban (development)
Kickoff meeting is the first meeting with the project team and with or without the client of the project.
Operations research
Outline of project management
Postmortem documentation is a process used to identify the causes of a project failure, and how to prevent them in the future.
Process architecture
Program management
Project accounting
Project governance
Project management office
Project management simulation
Small-scale project management
Software development process
Social project management
Systems development life cycle (SDLC)
Comparison of project management software
Glossary of project management
List of collaborative software
List of project management topics
Timeline of project management
Project managementManagement by typeIEEE standardsISO/IEC standardsProduct developmentProduct management
CS1 maint: date and yearCS1 maint: unfit URLCS1 maint: multiple names: authors listCS1 maint: numeric names: authors listCS1 maint: othersArticles with short descriptionShort description is different from WikidataUse American English from November 2021All Wikipedia articles written in American EnglishUse mdy dates from November 2021Articles needing additional references from October 2022All articles needing additional referencesAll articles with self-published sourcesArticles with self-published sources from November 2021Commons category link is on WikidataArticles with GND identifiersArticles with J9U identifiersArticles with LCCN identifiersArticles with LNB identifiersArticles with NDL identifiersArticles with NKC identifiers






# Project_management_triangle.md




(Top)





1
Overview








2
STR Model








3
Project management triangle topics




Toggle Project management triangle topics subsection





3.1
Time






3.1.1
Define Activities








3.1.2
Activity sequencing








3.1.3
Activity resource estimating








3.1.4
Activity duration estimating








3.1.5
Schedule development








3.1.6
Schedule control










3.2
Cost






3.2.1
Cost Process Areas






3.2.1.1
Project Management Cost Estimating Tools[8]












3.3
Scope










4
Evolution of the Project Constraint Model








5
Evolution of Project Success Criteria








6
Limitations








7
See also








8
References








9
External links














3.1
Time






3.1.1
Define Activities








3.1.2
Activity sequencing








3.1.3
Activity resource estimating








3.1.4
Activity duration estimating








3.1.5
Schedule development








3.1.6
Schedule control










3.2
Cost






3.2.1
Cost Process Areas






3.2.1.1
Project Management Cost Estimating Tools[8]












3.3
Scope










3.1.1
Define Activities








3.1.2
Activity sequencing








3.1.3
Activity resource estimating








3.1.4
Activity duration estimating








3.1.5
Schedule development








3.1.6
Schedule control






















3.2.1
Cost Process Areas






3.2.1.1
Project Management Cost Estimating Tools[8]












3.2.1.1
Project Management Cost Estimating Tools[8]






















This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these template messages)

This article possibly contains original research. Please improve it by verifying the claims made and adding inline citations. Statements consisting only of original research should be removed. (October 2008) (Learn how and when to remove this message)
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Project management triangle" – news · newspapers · books · scholar · JSTOR (December 2008) (Learn how and when to remove this message)

 (Learn how and when to remove this message)
This article possibly contains original research. Please improve it by verifying the claims made and adding inline citations. Statements consisting only of original research should be removed. (October 2008) (Learn how and when to remove this message)
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Project management triangle" – news · newspapers · books · scholar · JSTOR (December 2008) (Learn how and when to remove this message)
The project management triangle (called also the triple constraint, iron triangle and project triangle) is a model of the constraints of project management. While its origins are unclear, it has been used since at least the 1950s.[1] It contends that:

The quality of work is constrained by the project's budget, deadlines and scope (features).
The project manager can trade between constraints.
Changes in one constraint necessitate changes in others to compensate or quality will suffer.
For example, a project can be completed faster by increasing budget or cutting scope. Similarly, increasing scope may require equivalent increases in budget and schedule. Cutting budget without adjusting schedule or scope will lead to lower quality.

"Good, fast, cheap. Choose two." as stated in the Common Law of Business Balance (often expressed as "You get what you pay for.") which is attributed to John Ruskin but without any evidence and similar statements are often used to encapsulate the triangle's constraints concisely.[2][3] Martin Barnes (1968) proposed a project cost model based on cost, time and resources (CTR) in his PhD thesis and in 1969, he designed a course entitled "Time and Cost in Contract Control" in which he drew a triangle with each apex representing cost, time and quality (CTQ).[4] Later, he expanded quality with performance, becoming CTP. It is understood that the area of the triangle represents the scope of a project which is fixed and known for a fixed cost and time. In fact the scope can be a function of cost, time and performance, requiring a trade off among the factors.

In practice, however, trading between constraints is not always possible. For example, throwing money (and people) at a fully staffed project can slow it down.[5] Moreover, in poorly run projects it is often impossible to improve budget, schedule or scope without adversely affecting quality.

The time constraint refers to the amount of time available to complete a project. The cost constraint refers to the budgeted amount available for the project. The scope constraint refers to what must be done to produce the project's end result. These three constraints are often competing constraints: increased scope typically means increased time and increased cost, a tight time constraint could mean increased costs and reduced scope, and a tight budget could mean increased time and reduced scope.

The discipline of project management is about providing the tools and techniques that enable the project team (not just the project manager) to organize their work to meet these constraints.

Another approach to project management is to consider the three constraints as finance, time and human resources. If you need to finish a job in a shorter time, you can throw more people at the problem, which in turn will raise the cost of the project, unless by doing this task quicker we will reduce costs elsewhere in the project by an equal amount.

As a project management graphic aid, a triangle can show time, resources, and technical objective as the sides of a triangle, instead of the corners.[6] John Storck, a former instructor of the American Management Association's "Basic Project Management" course, used a pair of triangles called triangle outer and triangle inner to represent the concept that the intent of a project is to complete on or before the allowed time, on or under budget, and to meet or exceed the required scope. The distance between the inner and outer triangles illustrated the hedge or contingency for each of the three elements. Bias could be shown by the distance. His example of a project with a strong time bias was the Alaska pipeline which essentially had to be done on time no matter the cost. After years of development, oil flowed out the end of the pipe within four minutes of schedule. In this illustration, the time side of triangle inner was effectively on top of the triangle outer line. This was true of the technical objective line also. The cost line of triangle inner, however, was outside since the project ran significantly over budget.

James P. Lewis [7] suggests that project scope represents the area of the triangle, and can be chosen as a variable to achieve project success. He calls this relationship PCTS (Performance, Cost, Time, Scope), and suggests that a project can pick any three.

The real value of the project triangle is to show the complexity that is present in any project. The plane area of the triangle represents the near infinite variations of priorities that could exist between the three competing values. By acknowledging the limitless variety, possible within the triangle, using this graphic aid can facilitate better project decisions and planning and ensure alignment among team members and the project owners.

The STR model is a mathematical model which views the "triangle model" as a graphic abstraction of the relationship:

Scope refers to complexity (which can also mean quality or performance). Resources includes humans (workers), financial, and physical. Note that these values are not considered unbounded. For instance, if one baker can make a loaf of bread in an hour in an oven, that does not mean that ten bakers could make ten loaves in one hour in the same oven, due to the oven's limited capacity.

For analytical purposes, the time required to produce a deliverable is estimated using several techniques. One method is to identify tasks needed to produce the deliverables documented in a work breakdown structure or WBS. The work effort for each task is estimated and those estimates are rolled up into the final deliverable estimate.

The tasks are also prioritized, dependencies between tasks are identified, and this information is documented in a project schedule. The dependencies between the tasks can affect the length of the overall project (dependency constrained), as can the availability of resources (resource constrained). Time is different from all other resources and cost categories.

Using actual cost of previous, similar projects as the basis for estimating the cost of current project.

According to the Project Management Body of Knowledge (PMBOK) the Project Time Management processes include:

Plan Schedule Management
Define Activities
Sequence Activities
Estimate Activity Resources
Estimate Activity Durations
Develop Schedule
Control Schedule
Inputs: Management Plan, Scope Baseline, Enterprise environmental factors, Organizational process assets
Tools: Decomposition, Rolling Wave Planning, Expert Judgment
Outputs: Activity list, Activity attributes, Milestone list
Inputs: Project Scope Statement, Activity List, Activity Attributes, Milestones List, Approved change requests
Tools: Precedence Diagramming Method (PDM), Arrow Diagramming Method (ADM), Schedule Network templates, dependency degeneration, applying leads and lags
Outputs: Project Schedule Network diagrams, Activity List Updates, Activity Attributes updates, Request Changes
Inputs: Enterprise Environmental factoring, Organizational process assets, Activity list, Activity attributes, Resources Availability, Project Management Plan
Tools: Expert Judgment Collections, Alternative Analysis, Publishing estimating data, Project management software implementation, Bottom up estimating
Outputs: Activity resource requirements, Activity attributes, Resource breakdown structure, resource calendars, request change updates.
Inputs: Enterprise environmental factors, organization process assets, Project scope statement, activity list, activity attributes, activity resource requirements, resource calendars, project management plan, risk register, activity cost estimates
Tools: Expert judgment collection, analogous estimating, parametric estimating, Bottom up Estimation, Two-Point estimation, Three-point estimation, reserve analysis
Outputs: Activity duration estimates, activity attribute updates and estimates
Inputs: Organizational process assets, Project scope Statement, Activity list, Activity attributes, project Schedule Network diagrams, Activity resource requirements, Resource calendars, Activity duration estimates, project management plan, risk register
Tools: Schedule Network Analysis, Critical path method, schedule compression, what if scenario analysis, resources leveling, critical chain method, project management software, applying calendars, adjusting leads and lags, schedule model
Outputs: Project schedule, Schedule model data, schedule baseline, resource requirements update, activity attributes, project calendar updates, request changes, project management plan updates, schedule management plan updates
Inputs: Schedule management plan, schedule baseline, performance reports, approved change requests
Tools: Progressive elaboration reporting, schedule change control system, performance measurement, project management software, variance, analysis, schedule comparison bar charts
Outputs: Schedule model data updates, schedule baseline. performance measurement, requested changes, recommended corrective actions, organizational process assets, activity list updates, activity attribute updates, project management plan updates
Due to the complex nature of the 'Time' process group the project management credential PMI Scheduling Professional (PMI-SP) was created.

To develop an approximation of a project cost depends on several variables including: resources, work packages such as labor rates and mitigating or controlling influencing factors that create cost variances. Tools used in cost are, risk management, cost contingency, cost escalation, and indirect costs. But beyond this basic accounting approach to fixed and variable costs, the economic cost that must be considered includes worker skill and productivity which is calculated using various project cost estimate tools. This is important when companies hire temporary or contract employees or outsource work.

Cost Estimating is an approximation of the cost of all resources needed to complete activities.
Cost budgeting aggregating the estimated costs of resources, work packages and activities to establish a cost baseline.
Cost Control – factors that create cost fluctuation and variance can be influenced and controlled using various cost management tools.
Analogous Estimating: Using the cost of similar project to determine the cost of the current project
Determining Resource Cost rates: The cost of goods and labor by unit gathered through estimates or estimation.
Bottom Up estimating: Using the lowest level of work package detail and summarizing the cost associated with it. Then rolling it up to a higher level aimed and calculating the entire cost of the project.
Parametric Estimating: Measuring the statistical relationship between historical data and other variable or flow.
Vendor bid analysis: taking the average of several bids given by vendors for the project.
Reserve Analysis: Aggregate the cost of each activity on the network path then add a contingency or reserve to the end result of the analysis by a factor determined by the project manager.
Cost of Quality Analysis: Estimating the cost at the highest quality for each activity.
Project management software can be used to calculate the cost variances for a project.

Requirements specified to achieve the end result. The overall definition of what the project is supposed to accomplish, and a specific description of what the end result should be or accomplish. A major component of scope is the quality of the final product. The amount of time put into individual tasks determines the overall quality of the project. Some tasks may require a given amount of time to complete adequately, but given more time could be completed exceptionally. Over the course of a large project, quality can have a significant impact on time and cost (or vice versa).

Together, these three constraints have given rise to the phrase "On Time, On Spec, On Budget." In this case, the term "scope" is substituted with "spec(ification)."

Traditionally the Project Constraint Model recognised three key constraints; "Cost", "Time" and "Scope". These constraints construct a triangle with geometric proportions illustrating the strong interdependent relationship between these factors. If there is a requirement to shift any one of these factors then at least one of the other factors must also be manipulated.[9]

With mainstream acceptance of the Triangle Model, "Cost" and "Time" appear to be represented consistently. "Scope" however is often used interchangeably given the context of the triangle's illustration or the perception of the respective project. Scope / Goal / Product / Deliverable / Quality / Performance / Output are all relatively similar and generic variation examples of this, while the above suggestion of 'People Resources' offers a more specialised interpretation.

This widespread use of variations implies a level of ambiguity carried by the nuance of the third constraint term and of course a level of value in the flexibility of the Triangle Model. This ambiguity allows blurred focus between a project's output and project's process, with the example terms above having potentially different impetus in the two contexts. Both "Cost" and "Time" / "Delivery" represent the top level project's inputs.

The ‘Project Diamond’ model [10] engenders this blurred focus through the inclusion of "Scope" and "Quality" separately as the ‘third’ constraint. While there is merit in the addition of "Quality" as a key constraining factor, acknowledging the increasing maturity of project management, this model still lacks clarity between output and process. The Diamond Model does not capture the analogy of the strong interrelation between points of the triangles however.

PMBOK 4.0 offered an evolved model based on the triple constraint with 6 factors to be monitored and managed.[11] This is illustrated as a 6 pointed Star that maintains the strength of the triangle analogy (two overlaid triangles), while at the same time represents the separation and relationship between project inputs/outputs factors on one triangle and the project processes factors on the other. The star variables are:

Input-Output Triangle
Scope
Cost
Time
Process Triangle
Risk
Quality
Resources
Scope
Cost
Time
Risk
Quality
Resources
When considering the ambiguity of the third constraint and the suggestions of the "Project Diamond"; it is possible to consider instead the Goal or Product of the project as the third constraint, being made up of the sub factors "Scope" and "Quality". In terms of a project's output both "Scope" and "Quality" can be adjusted resulting in an overall manipulation of the Goal/Product. This interpretation includes the four key factors in the original triangle inputs/outputs form. This can even be incorporated into the PMBOK Star illustrating that "Quality" in particular may be monitored separately in terms of project outputs and process. Further to this suggestion, the use of term "Goal" may best represent change initiative outputs, while Product may best represent more tangible outputs.[12]

The triple constraints represent a minimum number of project success criteria which are not adequate by themselves. Thus, a number of studies have been carried out to define and expand the various criteria of project success based on the theory of change which is the basic input-process-output chain.

Bannerman (2008) proposed the multilevel project success framework which comprises five L
Levels of project success i.e. team, project management, deliverable, business and strategic.[13]

The UNDP in 2012 proposed the results framework which has six stages of project success i.e. input, process, output, outcome and impact.[14]

Zidane et al (2016) expanded the results framework into the PESTOL framework to plan and assess project success which can be used to evaluate "value for money" spent on each project in terms of efficiency and effectiveness.[15]

Hence, the triple constraints has been developed into various frameworks to plan and appraise project success as holistically as possible.

The Project Management Triangle is used to analyze projects.[16] It is often misused to define success as delivering the required scope, at a reasonable quality, within the established budget and schedule.[17][18][19][20] The Project Management Triangle is considered insufficient as a model of project success because it omits crucial dimensions of success including impact on stakeholders,[21] learning[22] and user satisfaction.[23] Subsequently, several enhancements of the basic triple constraints have been proposed such as the diamond model, the pyramid model, six or multiple constraints and theory of constraints. Accordingly, the project success criteria have been enhanced as well from three to multiple parameters.

Quality, cost, delivery
Trilemma
Ternary plot
Project managementProject management techniques
All articles with bare URLs for citationsArticles with bare URLs for citations from March 2022Articles with PDF format bare URLs for citationsArticles with short descriptionShort description is different from WikidataArticles that may contain original research from October 2008All articles that may contain original researchArticles needing additional references from December 2008All articles needing additional referencesArticles with multiple maintenance issuesCommons category link is on Wikidata






# Project_team.md




(Top)





1
See also








2
References








3
External links












In a project, a project team or team is defined as "an interdependent collection of individuals who work together towards a common goal and who share responsibility for specific outcomes of their organizations".[1] An additional requirement to the original definition is that "the team is identified as such by those within and outside of the team".[2] As project teams work on specific projects, the first requirement is usually met. In the early stages of a project, the project team may not be recognized as a team, leading to some confusion within the organization. The central characteristic of project teams in modern organizations is the autonomy and flexibility availed in the process or method undertaken to meet their goals.

Most[quantify] project teams require involvement from more than one department, therefore most project teams can be classified as cross-functional teams. The project team usually consists of a variety of members often working under the direction of a project manager or of a senior member of the organization. Projects that may not receive strong support initially often have the backing of a project champion. Individual team-members can either be involved on a part-time or full-time basis. Their time commitment can change throughout the project depending on the project development stage.

Project teams need to have the right combination of skills, abilities and personality types to achieve collaborative tension.[3] Teams can be formulated in a variety of ways. The most common method is at the discretion of a senior member of the organization.

There are many components to becoming a top-performing team, but the key is working on highly cooperative relationship.[citation needed] The job of management is to foster a relaxed and comfortable atmosphere where members can be themselves and are engaged and invested in the project work. All team members are encouraged for relationship building.[citation needed] Each member is responsible to give constructive feedback, recognize, value and utilize unique strengths of each other. The whole team is tuned trust and cooperation.[4][need quotation to verify]

Resource calendar
Resource allocation
Programming team
Project managementTeams
Articles with short descriptionShort description matches WikidataAll articles with unsourced statementsArticles with unsourced statements from August 2019Wikipedia articles needing factual verification from August 2019






# Rapid_application_development.md




(Top)





1
History








2
The James Martin RAD method








3
Advantages








4
Disadvantages








5
See also








6
References








7
Further reading






















Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Rapid application development (RAD), also called rapid application building (RAB), is both a general term for adaptive software development approaches, and the name for James Martin's method of rapid development. In general, RAD approaches to software development put less emphasis on planning and more emphasis on an adaptive process. Prototypes are often used in addition to or sometimes even instead of design specifications.

RAD is especially well suited for (although not limited to) developing software that is driven by user interface requirements. Graphical user interface builders are often called rapid application development tools. Other approaches to rapid development include the adaptive, agile, spiral, and unified models.

Rapid application development was a response to plan-driven waterfall processes, developed in the 1970s and 1980s, such as the Structured Systems Analysis and Design Method (SSADM). One of the problems with these methods is that they were based on a traditional engineering model used to design and build things like bridges and buildings. Software is an inherently different kind of artifact. Software can radically change the entire process used to solve a problem. As a result, knowledge gained from the development process itself can feed back to the requirements and design of the solution.[1] Plan-driven approaches attempt to rigidly define the requirements, the solution, and the plan to implement it, and have a process that discourages changes. RAD approaches, on the other hand, recognize that software development is a knowledge intensive process and provide flexible processes that help take advantage of knowledge gained during the project to improve or adapt the solution.

The first such RAD alternative was developed by Barry Boehm and was known as the spiral model. Boehm and other subsequent RAD approaches emphasized developing prototypes as well as or instead of rigorous design specifications. Prototypes had several advantages over traditional specifications:

Risk reduction. A prototype could test some of the most difficult potential parts of the system early on in the life-cycle. This can provide valuable information as to the feasibility of a design and can prevent the team from pursuing solutions that turn out to be too complex or time-consuming to implement. This benefit of finding problems earlier in the life-cycle rather than later was a key benefit of the RAD approach. The earlier a problem can be found the cheaper it is to address.
Users are better at using and reacting than at creating specifications. In the waterfall model it was common for a user to sign off on a set of requirements but then when presented with an implemented system to suddenly realize that a given design lacked some critical features or was too complex. In general most users give much more useful feedback when they can experience a prototype of the running system rather than abstractly define what that system should be.
Prototypes can be usable and can evolve into the completed product. One approach used in some RAD methods was to build the system as a series of prototypes that evolve from minimal functionality to moderately useful to the final completed system. The advantage of this besides the two advantages above was that the users could get useful business functionality much earlier in the process.[2]
Starting with the ideas of Barry Boehm and others, James Martin developed the rapid application development approach during the 1980s at IBM and finally formalized it by publishing a book in 1991, Rapid Application Development. This has resulted in some confusion over the term RAD even among IT professionals. It is important to distinguish between RAD as a general alternative to the waterfall model and RAD as the specific method created by Martin. The Martin method was tailored toward knowledge intensive and UI intensive business systems.

These ideas were further developed and improved upon by RAD pioneers like James Kerr and Richard Hunter, who together wrote the seminal book on the subject, Inside RAD,[3] which followed the journey of a RAD project manager as he drove and refined the RAD Methodology in real-time on an actual RAD project. These practitioners, and those like them, helped RAD gain popularity as an alternative to traditional systems project life cycle approaches.

The RAD approach also matured during the period of peak interest in business re-engineering. The idea of business process re-engineering was to radically rethink core business processes such as sales and customer support with the new capabilities of Information Technology in mind. RAD was often an essential part of larger business re engineering programs. The rapid prototyping approach of RAD was a key tool to help users and analysts "think out of the box" about innovative ways that technology might radically reinvent a core business process.[4][5]

Much of James Martin's comfort with RAD stemmed from Dupont's Information Engineering division and its leader Scott Schultz and their respective relationships with John Underwood who headed up a bespoke RAD development company that pioneered many successful RAD projects in Australia and Hong Kong.

Successful projects that included ANZ Bank, Lend Lease, BHP, Coca-Cola Amatil, Alcan, Hong Kong Jockey Club and numerous others.

Success that led to both Scott Shultz and James Martin both spending time in Australia with John Underwood to understand the methods and details of why Australia was disproportionately successful in implementing significant mission critical RAD projects.

The James Martin approach to RAD divides the process into four distinct phases: 

Requirements planning phase – combines elements of the system planning and systems analysis phases of the systems development life cycle (SDLC). Users, managers, and IT staff members discuss and agree on business needs, project scope, constraints, and system requirements. It ends when the team agrees on the key issues and obtains management authorization to continue.
User design phase – during this phase, users interact with systems analysts and develop models and prototypes that represent all system processes, inputs, and outputs. The RAD groups or subgroups typically use a combination of joint application design (JAD) techniques and CASE tools to translate user needs into working models. User design is a continuous interactive process that allows users to understand, modify, and eventually approve a working model of the system that meets their needs.
Construction phase – focuses on program and application development task similar to the SDLC. In RAD, however, users continue to participate and can still suggest changes or improvements as actual screens or reports are developed. Its tasks are programming and application development, coding, unit-integration and system testing.
Cutover phase – resembles the final tasks in the SDLC implementation phase, including data conversion, testing, changeover to the new system, and user training. Compared with traditional methods, the entire process is compressed. As a result, the new system is built, delivered, and placed in operation much sooner.[6]
In modern Information Technology environments, many systems are now built using some degree of Rapid Application Development[7] (not necessarily the James Martin approach). In addition to Martin's method, agile methods and the Rational Unified Process are often used for RAD development.

The purported advantages of RAD include:

Better quality. By having users interact with evolving prototypes the business functionality from a RAD project can often be much higher than that achieved via a waterfall model. The software can be more usable and has a better chance to focus on business problems that are critical to end users rather than technical problems of interest to developers. However, this excludes other categories of what are usually known as Non-functional requirements (AKA constraints or quality attributes) including security and portability.
Risk control. Although much of the literature on RAD focuses on speed and user involvement a critical feature of RAD done correctly is risk mitigation. It's worth remembering that Boehm initially characterized the spiral model as a risk based approach. A RAD approach can focus in early on the key risk factors and adjust to them based on empirical evidence collected in the early part of the process. E.g., the complexity of prototyping some of the most complex parts of the system.
More projects completed on time and within budget. By focusing on the development of incremental units the chances for catastrophic failures that have dogged large waterfall projects is reduced. In the Waterfall model it was common to come to a realization after six months or more of analysis and development that required a radical rethinking of the entire system. With RAD this kind of information can be discovered and acted upon earlier in the process.[2][8]
The purported disadvantages of RAD include:

The risk of a new approach. For most IT shops RAD was a new approach that required experienced professionals to rethink the way they worked. Humans are virtually always averse to change and any project undertaken with new tools or methods will be more likely to fail the first time simply due to the requirement for the team to learn.
Lack of emphasis on Non-functional requirements, which are often not visible to the end user in normal operation.
Requires time of scarce resources. One thing virtually all approaches to RAD have in common is that there is much more interaction throughout the entire life-cycle between users and developers. In the waterfall model, users would define requirements and then mostly go away as developers created the system. In RAD users are involved from the beginning and through virtually the entire project. This requires that the business is willing to invest the time of application domain experts. The paradox is that the better the expert, the more they are familiar with their domain, the more they are required to actually run the business and it may be difficult to convince their supervisors to invest their time. Without such commitments RAD projects will not succeed.
Less control. One of the advantages of RAD is that it provides a flexible adaptable process. The ideal is to be able to adapt quickly to both problems and opportunities. There is an inevitable trade-off between flexibility and control, more of one means less of the other. If a project (e.g. life-critical software) values control more than agility RAD is not appropriate.
Poor design. The focus on prototypes can be taken too far in some cases resulting in a "hack and test" methodology where developers are constantly making minor changes to individual components and ignoring system architecture issues that could result in a better overall design. This can especially be an issue for methodologies such as Martin's that focus so heavily on the user interface of the system.[9]
Lack of scalability. RAD typically focuses on small to medium-sized project teams. The other issues cited above (less design and control) present special challenges when using a RAD approach for very large scale systems.[10][11][12]
Practical concepts to implement RAD:

Graphical user interface builder, where main software tools for RAD are represented
Fourth-generation programming language, e.g. FileMaker, 4th Dimension, dBase and Visual FoxPro
Other similar concepts:

Flow-based programming
Lean software development
Platform as a service
Low-code development platforms
No-code development platform
Software project managementSoftware development processProgramming tools
Articles with short descriptionShort description matches WikidataUse dmy dates from June 2020






# Rational_unified_process.md




(Top)





1
History








2
Rational unified process topics




Toggle Rational unified process topics subsection





2.1
RUP building blocks








2.2
Four project life-cycle phases






2.2.1
Inception phase








2.2.2
Elaboration phase








2.2.3
Construction phase








2.2.4
Transition phase










2.3
The IBM Rational Method Composer product








2.4
Certification








2.5
Six best practices










3
See also








4
References








5
Further reading








6
External links












2.1
RUP building blocks








2.2
Four project life-cycle phases






2.2.1
Inception phase








2.2.2
Elaboration phase








2.2.3
Construction phase








2.2.4
Transition phase










2.3
The IBM Rational Method Composer product








2.4
Certification








2.5
Six best practices












2.2.1
Inception phase








2.2.2
Elaboration phase








2.2.3
Construction phase








2.2.4
Transition phase




























Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
The rational unified process (RUP) is an iterative software development process framework created by the Rational Software Corporation, a division of IBM since 2003.[1] RUP is not a single concrete prescriptive process, but rather an adaptable process framework, intended to be tailored by the development organizations and software project teams that will select the elements of the process that are appropriate for their needs. RUP is a specific implementation of the Unified Process.

Rational Software originally developed the rational unified process as a software process product. The product includes a hyperlinked knowledge-base with sample artifacts and detailed descriptions for many different types of activities. RUP is included in the IBM Rational Method Composer (RMC) product which allows customization of the process.

Philippe Kruchten, an experienced Rational technical representative was tasked with heading up the original RUP team.

These initial versions combined the Rational Software organisation's extensive field experience building object-oriented systems (referred to by Rational field staff as the Rational Approach) with Objectory's guidance on practices such as use cases, and incorporated extensive content from Jim Rumbaugh's Object Modeling Technology (OMT) approach to modeling, Grady Booch's Booch method, and the newly released UML 0.8.[2][3]

To help make this growing knowledge base more accessible, Philippe Kruchten was tasked with the assembly of an explicit process framework for modern software engineering. This effort employed the HTML-based process delivery mechanism developed by Objectory. The resulting "Rational Unified Process" (RUP) completed a strategic tripod for Rational:

a tailorable process that guided development
tools that automated the application of that process
services that accelerated adoption of both the process and the tools.
This guidance was augmented in subsequent versions with knowledge based on the experience of companies that Rational had acquired.

In 1997, a requirements and test discipline were added to the approach, much of the additional material sourced from the Requirements College method developed by Dean Leffingwell et al. at Requisite, Inc., and the SQA Process method developed at SQA Inc., both companies having been acquired by Rational Software.

In 1998 Rational Software added two new disciplines:

business modeling, much of this content had already been in the Objectory Process
a Configuration and Change Management discipline, sourced through the acquisition of Pure Atria Corporation.
These additions lead to an overarching set of principles that were defined by Rational and articulated within RUP as the six best practices for modern software engineering:

Develop iteratively, with risk as the primary iteration driver[4]
Manage requirements
Employ a component-based architecture
Model software visually
Continuously verify quality
Control changes
These best practices were tightly aligned with Rational's product line, and both drove the ongoing development of Rational's products, as well as being used by Rational's field teams to help customers improve the quality and predictability of their software development efforts.

Additional techniques including performance testing, UI Design, data engineering were included, and an update to reflect changes in UML 1.1.

In 1999, a project management discipline was introduced, as well as techniques to support real-time software development and updates to reflect UML 1.3. Besides, the first book to describe the process, The Unified Software Development Process (ISBN 0-201-57169-2) by Ivar Jacobson, Grady Booch and James Rumbaugh., was published in the same year.

Between 2000 and 2003, a number of changes introduced guidance from ongoing Rational field experience with iterative development, in addition to tool support for enacting RUP instances and for customization of the RUP framework. These changes included:

the introduction of concepts and techniques from approaches such as eXtreme Programming (XP), that would later come to be known collectively as agile methods. This included techniques such as pair programming, test-first design, and papers that explained how RUP enabled XP to scale for use on larger projects.
a complete overhaul of the testing discipline to better reflect how testing work was conducted in different iterative development contexts.
the introduction of supporting guidance - known as "tool mentors" - for enacting the RUP practices in various tools. These essentially provided step-by-step method support to Rational tool users.
automating the customization of RUP in a way that would allow customers to select parts from the RUP process framework, customize their selection with their own additions, and still incorporate improvements in subsequent releases from Rational.
IBM acquired Rational Software in February 2003.

In 2006, IBM created a subset of RUP tailored for the delivery of Agile projects - released as an OpenSource method called OpenUP through the Eclipse web-site.[5]

RUP is based on a set of building blocks and content elements, describing what is to be produced, the necessary skills required and the step-by-step explanation describing how specific development goals are to be achieved. The main building blocks, or content elements, are the following:

Roles (who) – A role defines a set of related skills, competencies and responsibilities.
Work products (what) – A work product represents something resulting from a task, including all the documents and models produced while working through the process.
Tasks (how) – A task describes a unit of work assigned to a Role that provides a meaningful result.
Within each iteration, the tasks are categorized into nine disciplines:

Six "engineering disciplines"
Business modelling
Requirements
Analysis and design
Implementation
Test
Deployment
Three supporting disciplines
Configuration and change management
Project management
Environment
Business modelling
Requirements
Analysis and design
Implementation
Test
Deployment
Configuration and change management
Project management
Environment
The RUP has determined a project life-cycle consisting of four phases. These phases allow the process to be presented at a high level in a similar way to how a 'waterfall'-styled project might be presented, although in essence the key to the process lies in the iterations of development that lie within all of the phases. Also, each phase has one key objective and milestone at the end that denotes the objective being accomplished. The visualization of RUP phases and disciplines over time is referred to as the RUP hump chart.

The primary objective is to scope the system adequately as a basis for validating initial costing and budgets.
In this phase the business case which includes business context, success factors (expected revenue, market recognition, etc.), and financial forecast is established. To complement the business case, a basic use case model, project plan, initial risk assessment and project description (the core project requirements, constraints and key features) are generated.
After these are completed, the project is checked against the following criteria:

Stakeholder concurrence on scope definition and cost/schedule estimates.
Requirements understanding as evidenced by the fidelity of the primary use cases.
Credibility of the cost/schedule estimates, priorities, risks, and development process.
Depth and breadth of any architectural prototype that was developed.
Establishing a baseline by which to compare actual expenditures versus planned expenditures.
If the project does not pass this milestone, called the life cycle objective milestone, it either can be cancelled or repeated after being redesigned to better meet the criteria.

The primary objective is to mitigate the key risk items identified by analysis up to the end of this phase.
The elaboration phase is where the project starts to take shape. In this phase the problem domain analysis is made and the architecture of the project gets its basic form.

The outcome of the elaboration phase is:

A use-case model in which the use-cases and the actors have been identified and most of the use-case descriptions are developed. The use-case model should be 80% complete.
A description of the software architecture in a software system development process.
An executable architecture that realizes architecturally significant use cases.
Business case and risk list which are revised.
A development plan for the overall project.
Prototypes that demonstrably mitigate each identified technical risk.
A preliminary user manual (optional)
This phase must pass the lifecycle architecture milestone criteria answering the following questions:

Is the vision of the product stable?
Is the architecture stable?
Does the executable demonstration indicate that major risk elements are addressed and resolved?
Is the construction phase plan sufficiently detailed and accurate?
Do all stakeholders agree that the current vision can be achieved using current plan in the context of the current architecture?
Is the actual vs. planned resource expenditure acceptable?
If the project cannot pass this milestone, there is still time for it to be canceled or redesigned. However, after leaving this phase, the project transitions into a high-risk operation where changes are much more difficult and detrimental when made.

The key domain analysis for the elaboration is the system architecture.

The primary objective is to build the software system.
In this phase, the main focus is on the development of components and other features of the system. This is the phase when the bulk of the coding takes place. In larger projects, several construction iterations may be developed in an effort to divide the use cases into manageable segments to produce demonstrable prototypes.

The primary objective is to 'transit' the system from development into production, making it available to and understood by the end user.
The activities of this phase include training the end users and maintainers and beta testing the system to validate it against the end users' expectations. The system also goes through an evaluation phase, any developer which is not producing the required work is replaced or removed. The product is also checked against the quality level set in the Inception phase.

If all objectives are met, the product release milestone is reached and the development cycle is finished.

The IBM Rational Method Composer product is a tool for authoring, configuring, viewing, and publishing processes. See IBM Rational Method Composer and an open source version Eclipse process framework (EPF) project for more details.

In January 2007 the new RUP certification examination for IBM Certified Solution Designer - Rational Unified Process 7.0 was released which replaces the previous version of the course called IBM Rational Certified Specialist - Rational Unified Process.[6] The new examination will not only test knowledge related to the RUP content but also to the process structure elements.[7]

To pass the new RUP certification examination, a person must take IBM's Test 839: Rational Unified Process v7.0. You are given 75 minutes to take the 52 question exam. The passing score is 62%.[8]

Six best software engineering practices are defined for software projects to minimize faults and increase productivity. These are:[9][10]

Macroscope (methodology suite)
Agile modeling (AM)
Agile unified process (AUP)
Disciplined agile delivery (DAD)
Dynamic systems development method (DSDM)
Computer programming
Feature-driven development (FDD)
Project life cycle
Quality control and quality assurance
Scaled agile framework — a descendant of RUP that incorporates agile software development methods such as extreme programming (XP)
Software architecture
Software component
Software development process
Software engineering
Software testing
Test-driven development (TDD)
Formal methodsRational Software softwareSoftware project management
All articles with dead external linksArticles with dead external links from July 2022Articles with permanently dead external linksWebarchive template wayback linksArticles with short descriptionShort description matches WikidataArticles with GND identifiers






# Refinement_(computing).md




(Top)





1
Program refinement








2
Data refinement








3
Refinement calculus








4
Refinement types








5
See also








6
References


















This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Refinement" computing – news · newspapers · books · scholar · JSTOR (September 2010) (Learn how and when to remove this message)
Data transformation
Concepts
Metadata
Data element
Data mapping
Data migration
Data transformation
Model transformation
Macro
Preprocessor

Transformation languages
ATL
AWK
MOFM2T
QVT
XML languages

Techniques and transforms
Identity transform
Data refinement

Applications
Data conversion
Data migration
Data integration
Extract, transform, load (ETL)
Web template system

Related
Data wrangling
Transformation languages
vte
Metadata
Data element
Data mapping
Data migration
Data transformation
Model transformation
Macro
Preprocessor
ATL
AWK
MOFM2T
QVT
XML languages
Identity transform
Data refinement
Data conversion
Data migration
Data integration
Extract, transform, load (ETL)
Web template system
Data wrangling
Transformation languages
vte
Refinement is a generic term of computer science that encompasses various approaches for producing correct computer programs and simplifying existing programs to enable their formal verification.

In formal methods, program refinement is the verifiable transformation of an abstract (high-level) formal specification into a concrete (low-level) executable program.[citation needed] Stepwise refinement allows this process to be done in stages. Logically, refinement normally involves implication, but there can be additional complications.

The progressive just-in-time preparation of the product backlog (requirements list) in agile software development approaches, such as Scrum, is also commonly described as refinement.[1]

Data refinement is used to convert an abstract data model (in terms of sets for example) into implementable data structures (such as arrays).[citation needed] Operation refinement converts a specification of an operation on a system into an implementable program (e.g., a procedure). The postcondition can be strengthened and/or the precondition weakened in this process. This reduces any nondeterminism in the specification, typically to a completely deterministic implementation.

For example, x ∈ {1,2,3} (where x is the value of the variable x after an operation) could be refined to x ∈ {1,2}, then x ∈ {1}, and implemented as x := 1. Implementations of x := 2 and x := 3 would be equally acceptable in this case, using a different route for the refinement. However, we must be careful not to refine to x ∈ {} (equivalent to false) since this is unimplementable; it is impossible to select a member from the empty set.

The term reification is also sometimes used (coined by Cliff Jones). Retrenchment is an alternative technique when formal refinement is not possible. The opposite of refinement is abstraction.

Refinement calculus is a formal system (inspired from Hoare logic) that promotes program refinement. The FermaT Transformation System is an industrial-strength implementation of refinement. The B-Method is also a formal method that extends refinement calculus with a component language: it has been used in industrial developments.

In type theory, a refinement type[2][3][4] is a type endowed with a predicate which is assumed to hold for any element of the refined type. Refinement types can express preconditions when used as function arguments or postconditions when used as return types: for instance, the type of a function which accepts natural numbers and returns natural numbers greater than 5 may be written as 



f
:

N

→
{
n
:

N



|


n
>
5
}


{\displaystyle f:\mathbb {N} \rightarrow \{n:\mathbb {N} \,|\,n>5\}}

. Refinement types are thus related to behavioral subtyping.

Reification (computer science)
Formal methods terminologyComputer programmingSoftware engineering stubs
Articles needing additional references from September 2010All articles needing additional referencesAll articles with unsourced statementsArticles with unsourced statements from September 2010All stub articles






# Retrospective.md




(Top)





1
Medicine








2
Arts and popular culture








3
Awards








4
Law








5
Software development








6
Standards








7
See also








8
References








9
External links
























This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Retrospective" – news · newspapers · books · scholar · JSTOR (December 2009) (Learn how and when to remove this message)
A retrospective (from Latin retrospectare, "look back"), generally, is a look back at events that took place, or works that were produced, in the past. As a noun, retrospective has specific meanings in medicine, software development, popular culture and the arts. It is applied as an adjective, synonymous with the term retroactive, to laws, standards, and awards.

A medical retrospective is an examination of a patient's medical history and lifestyle.

A retrospective exhibition presents works from an extended period of an artist's activity. Similarly, a retrospective compilation album is assembled from a recording artist's past material, usually their greatest hits. A television or newsstand special about an actor, politician, or other celebrity will present a retrospective of the subject's career highlights. A leading (usually elderly) academic may be honored with a Festschrift, an honorary book of articles or a lecture series relating topically to a retrospective of the honoree's career. Celebrity roasts good-naturedly mock the career of the guest of honor, often in a retrospective format.

A retrospective or retroactive award is one which is created and then awarded to persons who would have received it before. Alternatively, a slight change to the criteria of an existing award may result in retrospective awards being presented to persons who would have won the award under present rules. Comparatively, few awards are presented retrospectively.

The term is used in situations where the law (statutory, civil, or regulatory) is changed or reinterpreted, affecting acts committed before the alteration. When such changes make a previously committed lawful act now unlawful in a retroactive manner, this is known as an ex post facto law or retroactive law. Because such laws punish the accused for acts that were not unlawful when committed, they are rare, and not permissible in most legal systems. More commonly, changes retroactively worsen the legal consequences (or status) of actions that were committed, or relationships that existed, by bringing it into a more severe category than it was in when it was committed; by changing the punishment or recompense prescribed, as by adding new penalties, extending sentences, or increasing fines and damages payable; or it may alter the rules of evidence in order to make exoneration more difficult than it would have been.

Conversely, a form of retrospective law commonly called an amnesty law may decriminalize certain acts. A pardon has a similar effect, in a specific case instead of a class of cases. An in mitius change may alleviate possible consequences for unlawful acts (for example, by replacing the death sentence with lifelong imprisonment) retroactively. Finally, when a previous law is repealed or otherwise nullified, it is no longer applicable to situations to which it had been, even if such situations arose before the law was voided; this principle is known as nullum crimen, nulla poena sine praevia lege poenali.

This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (April 2017) (Learn how and when to remove this message)
The term is also used in software engineering, where a retrospective is a meeting held by a project team at the end of a project or process (often after an iteration) to discuss what was successful about the project or time period covered by that retrospective, what could be improved, and how to incorporate the successes and improvements in future iterations or projects. Retrospective can be done in many different ways.

In agile development, retrospectives play a very important role in iterative and incremental development. At the end of every iteration, a retrospective is held to look for ways to improve the process for the next iteration.

In the context of scientific and technical standards, retrospectivity applies current norms to material that pre-dates new rules. An example of a retrospective or retroactive standard is the International Code of Zoological Nomenclature (ICZN Code), a convention which governs the formal scientific naming of animals, of which the 4th edition is effective since 2000. All previous editions of the ICZN Code, or previous other rules and conventions, are disregarded today,[1] and the scientific names published in former times are to be evaluated only under the present edition of the ICZN Code.

After action report
After-action review
Debriefing
Lessons learned
Morbidity and mortality conference
Performance appraisal
Film genresVisual arts exhibitions
Articles with short descriptionShort description is different from WikidataArticles needing additional references from December 2009All articles needing additional referencesArticles containing Latin-language textArticles needing additional references from April 2017






# Risk_management.md




(Top)





1
Introduction




Toggle Introduction subsection





1.1
Risks vs. opportunities








1.2
Method








1.3
Principles








1.4
Mild versus wild risk










2
Process




Toggle Process subsection





2.1
Establishing the context








2.2
Identification








2.3
Assessment










3
Risk options




Toggle Risk options subsection





3.1
Potential risk treatments






3.1.1
Risk avoidance








3.1.2
Risk reduction








3.1.3
Risk sharing








3.1.4
Risk retention










3.2
Risk management plan








3.3
Implementation








3.4
Review and evaluation of the plan










4
Areas




Toggle Areas subsection





4.1
Enterprise








4.2
Finance








4.3
Information technology








4.4
Contractual risk management








4.5
Customs








4.6
Memory institutions (museums, libraries and archives)








4.7
Enterprise security








4.8
Medical devices








4.9
Project management








4.10
Megaprojects (infrastructure)








4.11
Natural disasters








4.12
Wilderness








4.13
Information technology








4.14
Operations








4.15
Petroleum and natural gas








4.16
Pharmaceutical sector








4.17
Supply chain










5
Risk communication








6
See also








7
References








8
External links










1.1
Risks vs. opportunities








1.2
Method








1.3
Principles








1.4
Mild versus wild risk


















2.1
Establishing the context








2.2
Identification








2.3
Assessment
















3.1
Potential risk treatments






3.1.1
Risk avoidance








3.1.2
Risk reduction








3.1.3
Risk sharing








3.1.4
Risk retention










3.2
Risk management plan








3.3
Implementation








3.4
Review and evaluation of the plan










3.1.1
Risk avoidance








3.1.2
Risk reduction








3.1.3
Risk sharing








3.1.4
Risk retention
























4.1
Enterprise








4.2
Finance








4.3
Information technology








4.4
Contractual risk management








4.5
Customs








4.6
Memory institutions (museums, libraries and archives)








4.7
Enterprise security








4.8
Medical devices








4.9
Project management








4.10
Megaprojects (infrastructure)








4.11
Natural disasters








4.12
Wilderness








4.13
Information technology








4.14
Operations








4.15
Petroleum and natural gas








4.16
Pharmaceutical sector








4.17
Supply chain
















































This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Risk management" – news · newspapers · books · scholar · JSTOR (January 2014) (Learn how and when to remove this message)
Risk management is the identification, evaluation, and prioritization of risks (defined in ISO 31000 as the effect of uncertainty on objectives) followed by coordinated and economical application of resources to minimize, monitor, and control the probability or impact of unfortunate events[1] or to maximize the realization of opportunities.

Risks can come from various sources including uncertainty in international markets, political instability, threats from project failures (at any phase in design, development, production, or sustaining of life-cycles), legal liabilities, credit risk, accidents, natural causes and disasters, deliberate attack from an adversary, or events of uncertain or unpredictable root-cause. 

There are two types of events i.e. negative events can be classified as risks while positive events are classified as opportunities. Risk management standards have been developed by various institutions, including the Project Management Institute, the National Institute of Standards and Technology, actuarial societies, and ISO standards (quality management standards to help work more efficiently and reduce product failures).[2][3][4] Methods, definitions and goals vary widely according to whether the risk management method is in the context of project management, security, engineering, industrial processes, financial portfolios, actuarial assessments, or public health and safety. Certain risk management standards have been criticized for having no measurable improvement on risk, whereas the confidence in estimates and decisions seems to increase.[1]

Strategies to manage threats (uncertainties with negative consequences) typically include avoiding the threat, reducing the negative effect or probability of the threat, transferring all or part of the threat to another party, and even retaining some or all of the potential or actual consequences of a particular threat. The opposite of these strategies can be used to respond to opportunities (uncertain future states with benefits).

As a professional role, a risk manager[5] will "oversee the organization's comprehensive insurance and risk management program, assessing and identifying risks that could impede the reputation, safety, security, or financial success of the organization", and then develop plans to minimize and / or mitigate any negative (financial) outcomes. Risk Analysts [6] support the technical side of the organization's risk management approach: once risk data has been compiled and evaluated, analysts share their findings with their managers, who use those insights to decide among possible solutions. 
See also Chief Risk Officer, internal audit, and Financial risk management § Corporate finance.

Risk management appears in scientific and management literature since the 1920s. It became a formal science in the 1950s, when articles and books with "risk management" in the title also appear in library searches.[7] Most of research was initially related to finance and insurance.

A widely used vocabulary for risk management is defined by ISO Guide 73:2009, "Risk management. Vocabulary."[2]

In ideal risk management, a prioritization process is followed whereby the risks with the greatest loss (or impact) and the greatest probability of occurring are handled first. Risks with lower probability of occurrence and lower loss are handled in descending order. In practice the process of assessing overall risk can be difficult, and balancing resources used to mitigate between risks with a high probability of occurrence but lower loss, versus a risk with high loss but lower probability of occurrence can often be mishandled.

Intangible risk management identifies a new type of a risk that has a 100% probability of occurring but is ignored by the organization due to a lack of identification ability. For example, when deficient knowledge is applied to a situation, a knowledge risk materializes. Relationship risk appears when ineffective collaboration occurs. Process-engagement risk may be an issue when ineffective operational procedures are applied. These risks directly reduce the productivity of knowledge workers, decrease cost-effectiveness, profitability, service, quality, reputation, brand value, and earnings quality. Intangible risk management allows risk management to create immediate value from the identification and reduction of risks that reduce productivity.

Opportunity cost represents a unique challenge for risk managers. It can be difficult to determine when to put resources toward risk management and when to use those resources elsewhere. Again, ideal risk management minimizes spending (or manpower or other resources) and also minimizes the negative effects of risks.

Risk is defined as the possibility that an event will occur that adversely affects the achievement of an objective. Uncertainty, therefore, is a key aspect of risk. Systems like the Committee of Sponsoring Organizations of the Treadway Commission Enterprise Risk Management (COSO ERM), can assist managers in mitigating risk factors. Each company may have different internal control components, which leads to different outcomes. For example, the framework for ERM components includes Internal Environment, Objective Setting, Event Identification, Risk Assessment, Risk Response, Control Activities, Information and Communication, and Monitoring.

Opportunities first appear in academic research or management books in the 1990s. The first PMBoK Project Management Body of Knowledge draft of 1987 doesn't mention opportunities at all.

Modern project management school does recognize the importance of opportunities. Opportunities have been included in project management literature since the 1990s, e.g. in PMBoK, and became a significant part of project risk management in the years 2000s,[8] when articles titled "opportunity management" also begin to appear in library searches. Opportunity management thus became an important part of risk management.

Modern risk management theory deals with any type of external events, positive and negative. Positive risks are called opportunities. Similarly to risks, opportunities have specific mitigation strategies: exploit, share, enhance, ignore.

In practice, risks are considered "usually negative". Risk-related research and practice focus significantly more on threats than on opportunities. This can lead to negative phenomena such as target fixation[9]

For the most part, these methods consist of the following elements, performed, more or less, in the following order:

Identify the threats
Assess the vulnerability of critical assets to specific threats
Determine the risk (i.e. the expected likelihood and consequences of specific types of attacks on specific assets)
Identify ways to reduce those risks
Prioritize risk reduction measures
The Risk management knowledge area, as defined by the Project Management Body of Knowledge PMBoK, consists of the following processes:

Plan Risk Management – defining how to conduct risk management activities.
Identify Risks – identifying individual project risks as well as sources.
Perform Qualitative Risk Analysis – prioritizing individual project risks by assessing probability and impact.
Perform Quantitative Risk Analysis – numerical analysis of the effects.
Plan Risk Responses – developing options, selecting strategies and actions.
Implement Risk Responses – implementing agreed-upon risk response plans. In the 4th Ed. of PMBoK, this process was included as an activity in the Monitor and Control process, but was later separated as a distinct process in PMBoK 6th Ed.[10]
Monitor Risks – monitoring the implementation. This process was known as Monitor and Control in the previous PMBoK 4th Ed., when it also included the "Implement Risk Responses" process.
The International Organization for Standardization (ISO) identifies the following principles of risk management:[11]

Risk management should:

Create value – resources expended to mitigate risk should be less than the consequence of inaction
Be an integral part of organizational processes
Be part of decision-making process
Explicitly address uncertainty and assumptions
Be a systematic and structured process
Be based on the best available information
Be tailorable
Take human factors into account
Be transparent and inclusive
Be dynamic, iterative and responsive to change
Be capable of continual improvement and enhancement
Be continually or periodically re-assessed
Benoit Mandelbrot distinguished between "mild" and "wild" risk and argued that risk assessment and management must be fundamentally different for the two types of risk.[12] Mild risk follows normal or near-normal probability distributions, is subject to regression to the mean and the law of large numbers, and is therefore relatively predictable. Wild risk follows fat-tailed distributions, e.g., Pareto or power-law distributions, is subject to regression to the tail (infinite mean or variance, rendering the law of large numbers invalid or ineffective), and is therefore difficult or impossible to predict. A common error in risk assessment and management is to underestimate the wildness of risk, assuming risk to be mild when in fact it is wild, which must be avoided if risk assessment and management are to be valid and reliable, according to Mandelbrot.

According to the standard ISO 31000 – "Risk management – Principles and guidelines on implementation,"[3] the process of risk management consists of several steps as follows:

This involves:

observing the context
the social scope of risk management
the identity and objectives of stakeholders
the basis upon which risks will be evaluated, constraints.
defining a framework for the activity and an agenda for identification
developing an analysis of risks involved in the process
mitigation or solution of risks using available technological, human and organizational resources
the social scope of risk management
the identity and objectives of stakeholders
the basis upon which risks will be evaluated, constraints.
After establishing the context, the next step in the process of managing risk is to identify potential risks. Risks are about events that, when triggered, cause problems or benefits. Hence, risk identification can start with the source of problems and those of competitors (benefit), or with the problem's consequences.

Source analysis[13] – Risk sources may be internal or external to the system that is the target of risk management (use mitigation instead of management since by its own definition risk deals with factors of decision-making that cannot be managed).
Some examples of risk sources are: stakeholders of a project, employees of a company or the weather over an airport.

Problem analysis[citation needed] – Risks are related to identified threats. For example: the threat of losing money, the threat of abuse of confidential information or the threat of human errors, accidents and casualties. The threats may exist with various entities, most important with shareholders, customers and legislative bodies such as the government.
When either source or problem is known, the events that a source may trigger or the events that can lead to a problem can be investigated. For example: stakeholders withdrawing during a project may endanger funding of the project; confidential information may be stolen by employees even within a closed network; lightning striking an aircraft during takeoff may make all people on board immediate casualties.

The chosen method of identifying risks may depend on culture, industry practice and compliance. The identification methods are formed by templates or the development of templates for identifying source, problem or event. Common risk identification methods are:

Objectives-based risk identification [citation needed] – Organizations and project teams have objectives. Any event that may prevent an objective from being achieved is identified as risk.
Scenario-based risk identification – In scenario analysis different scenarios are created. The scenarios may be the alternative ways to achieve an objective, or an analysis of the interaction of forces in, for example, a market or battle. Any event that triggers an undesired scenario alternative is identified as risk – see Futures Studies for methodology used by Futurists.
Taxonomy-based risk identification – The taxonomy in taxonomy-based risk identification is a breakdown of possible risk sources. Based on the taxonomy and knowledge of best practices, a questionnaire is compiled. The answers to the questions reveal risks.[14]
Common-risk checking[15] – In several industries, lists with known risks are available. Each risk in the list can be checked for application to a particular situation.[16]
Risk charting[17] – This method combines the above approaches by listing resources at risk, threats to those resources, modifying factors which may increase or decrease the risk and consequences it is wished to avoid. Creating a matrix under these headings enables a variety of approaches. One can begin with resources and consider the threats they are exposed to and the consequences of each. Alternatively one can start with the threats and examine which resources they would affect, or one can begin with the consequences and determine which combination of threats and resources would be involved to bring them about.
Once risks have been identified, they must then be assessed as to their potential severity of impact (generally a negative impact, such as damage or loss) and to the probability of occurrence. These quantities can be either simple to measure, in the case of the value of a lost building, or impossible to know for sure in the case of an unlikely event, the probability of occurrence of which is unknown. Therefore, in the assessment process it is critical to make the best educated decisions in order to properly prioritize the implementation of the risk management plan.

Even a short-term positive improvement can have long-term negative impacts. Take the "turnpike" example. A highway is widened to allow more traffic. More traffic capacity leads to greater development in the areas surrounding the improved traffic capacity. Over time, traffic thereby increases to fill available capacity. Turnpikes thereby need to be expanded in a seemingly endless cycles. There are many other engineering examples where expanded capacity (to do any function) is soon filled by increased demand. Since expansion comes at a cost, the resulting growth could become unsustainable without forecasting and management.

The fundamental difficulty in risk assessment is determining the rate of occurrence since statistical information is not available on all kinds of past incidents and is particularly scanty in the case of catastrophic events, simply because of their infrequency. Furthermore, evaluating the severity of the consequences (impact) is often quite difficult for intangible assets. Asset valuation is another question that needs to be addressed. Thus, best educated opinions and available statistics are the primary sources of information. Nevertheless, risk assessment should produce such information for senior executives of the organization that the primary risks are easy to understand and that the risk management decisions may be prioritized within overall company goals. Thus, there have been several theories and attempts to quantify risks. Numerous different risk formulae exist, but perhaps the most widely accepted formula for risk quantification is: "Rate (or probability) of occurrence multiplied by the impact of the event equals risk magnitude."[vague]

Risk mitigation measures are usually formulated according to one or more of the following major risk options, which are:

Design a new business process with adequate built-in risk control and containment measures from the start.
Periodically re-assess risks that are accepted in ongoing processes as a normal feature of business operations and modify mitigation measures.
Transfer risks to an external agency (e.g. an insurance company)
Avoid risks altogether (e.g. by closing down a particular high-risk business area)
Later research[18] has shown that the financial benefits of risk management are less dependent on the formula used but are more dependent on the frequency and how risk assessment is performed.

In business it is imperative to be able to present the findings of risk assessments in financial, market, or schedule terms. Robert Courtney Jr. (IBM, 1970) proposed a formula for presenting risks in financial terms. The Courtney formula was accepted as the official risk analysis method for the US governmental agencies. The formula proposes calculation of ALE (annualized loss expectancy) and compares the expected loss value to the security control implementation costs (cost–benefit analysis).

Once risks have been identified and assessed, all techniques to manage the risk fall into one or more of these four major categories:[19]

Avoidance (eliminate, withdraw from or not become involved)
Reduction (optimize – mitigate)
Sharing (transfer – outsource or insure)
Retention (accept and budget)
Ideal use of these risk control strategies may not be possible. Some of them may involve trade-offs that are not acceptable to the organization or person making the risk management decisions. Another source, from the US Department of Defense (see link), Defense Acquisition University, calls these categories ACAT, for Avoid, Control, Accept, or Transfer. This use of the ACAT acronym is reminiscent of another ACAT (for Acquisition Category) used in US Defense industry procurements, in which Risk Management figures prominently in decision making and planning.

Similarly to risks, opportunities have specific mitigation strategies: exploit, share, enhance, ignore.

This includes not performing an activity that could present risk. Refusing to purchase a property or business to avoid legal liability is one such example. Avoiding airplane flights for fear of hijacking. Avoidance may seem like the answer to all risks, but avoiding risks also means losing out on the potential gain that accepting (retaining) the risk may have allowed. Not entering a business to avoid the risk of loss also avoids the possibility of earning profits. Increasing risk regulation in hospitals has led to avoidance of treating higher risk conditions, in favor of patients presenting with lower risk.[20]

Risk reduction or "optimization" involves reducing the severity of the loss or the likelihood of the loss from occurring. For example, sprinklers are designed to put out a fire to reduce the risk of loss by fire. This method may cause a greater loss by water damage and therefore may not be suitable. Halon fire suppression systems may mitigate that risk, but the cost may be prohibitive as a strategy.

Acknowledging that risks can be positive or negative, optimizing risks means finding a balance between negative risk and the benefit of the operation or activity; and between risk reduction and effort applied. By effectively applying Health, Safety and Environment (HSE) management standards, organizations can achieve tolerable levels of residual risk.[21]

Modern software development methodologies reduce risk by developing and delivering software incrementally. Early methodologies suffered from the fact that they only delivered software in the final phase of development; any problems encountered in earlier phases meant costly rework and often jeopardized the whole project. By developing in iterations, software projects can limit effort wasted to a single iteration.

Outsourcing could be an example of risk sharing strategy if the outsourcer can demonstrate higher capability at managing or reducing risks.[22] For example, a company may outsource only its software development, the manufacturing of hard goods, or customer support needs to another company, while handling the business management itself. This way, the company can concentrate more on business development without having to worry as much about the manufacturing process, managing the development team, or finding a physical location for a center. Also, implanting controls can also be an option in reducing risk. Controls that either detect causes of unwanted events prior to the consequences occurring during use of the product, or detection of the root causes of unwanted failures that the team can then avoid. Controls may focus on management or decision-making processes. All these may help to make better decisions concerning risk.[23]

Briefly defined as "sharing with another party the burden of loss or the benefit of gain, from a risk, and the measures to reduce a risk."

The term 'risk transfer' is often used in place of risk-sharing in the mistaken belief that you can transfer a risk to a third party through insurance or outsourcing. In practice, if the insurance company or contractor go bankrupt or end up in court, the original risk is likely to still revert to the first party. As such, in the terminology of practitioners and scholars alike, the purchase of an insurance contract is often described as a "transfer of risk." However, technically speaking, the buyer of the contract generally retains legal responsibility for the losses "transferred", meaning that insurance may be described more accurately as a post-event compensatory mechanism. For example, a personal injuries insurance policy does not transfer the risk of a car accident to the insurance company. The risk still lies with the policyholder namely the person who has been in the accident. The insurance policy simply provides that if an accident (the event) occurs involving the policyholder then some compensation may be payable to the policyholder that is commensurate with the suffering/damage.

Methods of managing risk fall into multiple categories. Risk-retention pools are technically retaining the risk for the group, but spreading it over the whole group involves transfer among individual members of the group. This is different from traditional insurance, in that no premium is exchanged between members of the group upfront, but instead, losses are assessed to all members of the group.

Risk retention involves accepting the loss, or benefit of gain, from a risk when the incident occurs. True self-insurance falls in this category. Risk retention is a viable strategy for small risks where the cost of insuring against the risk would be greater over time than the total losses sustained. All risks that are not avoided or transferred are retained by default. This includes risks that are so large or catastrophic that either they cannot be insured against or the premiums would be infeasible. War is an example since most property and risks are not insured against war, so the loss attributed to war is retained by the insured. Also any amounts of potential loss (risk) over the amount insured is retained risk. This may also be acceptable if the chance of a very large loss is small or if the cost to insure for greater coverage amounts is so great that it would hinder the goals of the organization too much.

Select appropriate controls or countermeasures to mitigate each risk. Risk mitigation needs to be approved by the appropriate level of management. For instance, a risk concerning the image of the organization should have top management decision behind it whereas IT management would have the authority to decide on computer virus risks.

The risk management plan should propose applicable and effective security controls for managing the risks. For example, an observed high risk of computer viruses could be mitigated by acquiring and implementing antivirus software. A good risk management plan should contain a schedule for control implementation and responsible persons for those actions. There are four basic steps of risk management plan, which are threat assessment, vulnerability assessment, impact assessment and risk mitigation strategy development. [24]

According to ISO/IEC 27001, the stage immediately after completion of the risk assessment phase consists of preparing a Risk Treatment Plan, which should document the decisions about how each of the identified risks should be handled. Mitigation of risks often means selection of security controls, which should be documented in a Statement of Applicability, which identifies which particular control objectives and controls from the 
standard have been selected, and why.

Implementation follows all of the planned methods for mitigating the effect of the risks. Purchase insurance policies for the risks that it has been decided to transferred to an insurer, avoid all risks that can be avoided without sacrificing the entity's goals, reduce others, and retain the rest.

Initial risk management plans will never be perfect. Practice, experience, and actual loss results will necessitate changes in the plan and contribute information to allow possible different decisions to be made in dealing with the risks being faced.

Risk analysis results and management plans should be updated periodically. There are two primary reasons for this: 

to evaluate whether the previously selected security controls are still applicable and effective
to evaluate the possible risk level changes in the business environment. For example, information risks are a good example of rapidly changing business environment.
Business administration
Management of a business
Accounting
Management accounting
Financial accounting
Audit

Business entity (list)
Corporate group
Corporation sole
Company
Conglomerate
Holding company
Cooperative
Corporation
Joint-stock company
Limited liability company
Partnership
Privately held company
Sole proprietorship
State-owned enterprise

Corporate governance
Annual general meeting
Board of directors
Supervisory board
Advisory board
Audit committee

Corporate law
Commercial law
Constitutional documents
Contract
Corporate crime
Corporate liability
Insolvency law
International trade law
Mergers and acquisitions

Corporate title
Chairman
Chief business officer/Chief brand officer
Chief executive officer/Chief operating officer
Chief financial officer
Chief human resources officer
Chief information officer/Chief marketing officer
Chief product officer/Chief technology officer

Economics
Commodity
Public economics
Labour economics
Development economics
International economics
Mixed economy
Planned economy
Econometrics
Environmental economics
Open economy
Market economy
Knowledge economy
Microeconomics
Macroeconomics
Economic development
Economic statistics

Finance
Financial statement
Insurance
Factoring
Cash conversion cycle
Insider dealing
Capital budgeting
Commercial bank
Derivative
Financial statement analysis
Financial risk
Public finance
Corporate finance
Managerial finance
International finance
Liquidation
Stock market
Financial market
Tax
Financial institution
Capital management
Venture capital

Types of management
Asset
Brand
Business intelligence
Business development
Capacity
Capability
Change
innovation
Commercial
Marketing
Communications
Configuration
Conflict
Content
Customer relationship
Distributed
Earned value
Electronic business
Enterprise resource planning 
management information system
Financial
Human resource 
development
Incident
Knowledge
Legal
Materials
Network
administrator
Office
Operations 
services
Performance
Power
Problem
Process
Product life-cycle
Product
Project
Property
Quality
Records
Resource
Risk 
crisis
Sales
Security
Service
Strategic
Supply chain
Systems
administrator
Talent
Technology

Organization
Architecture
Behavior
Communication
Culture
Conflict
Development
Engineering
Hierarchy
Patterns
Space
Structure

Trade
Business analysis
Business ethics
Business plan
Business judgment rule
Consumer behaviour
Business operations
International business
Business model
International trade
Trade route
Business process
Business statistics

 Business and economics portalvte
Management accounting
Financial accounting
Audit
Corporate group
Corporation sole
Company
Conglomerate
Holding company
Cooperative
Corporation
Joint-stock company
Limited liability company
Partnership
Privately held company
Sole proprietorship
State-owned enterprise
Annual general meeting
Board of directors
Supervisory board
Advisory board
Audit committee
Commercial law
Constitutional documents
Contract
Corporate crime
Corporate liability
Insolvency law
International trade law
Mergers and acquisitions
Chairman
Chief business officer/Chief brand officer
Chief executive officer/Chief operating officer
Chief financial officer
Chief human resources officer
Chief information officer/Chief marketing officer
Chief product officer/Chief technology officer
Commodity
Public economics
Labour economics
Development economics
International economics
Mixed economy
Planned economy
Econometrics
Environmental economics
Open economy
Market economy
Knowledge economy
Microeconomics
Macroeconomics
Economic development
Economic statistics
Financial statement
Insurance
Factoring
Cash conversion cycle
Insider dealing
Capital budgeting
Commercial bank
Derivative
Financial statement analysis
Financial risk
Public finance
Corporate finance
Managerial finance
International finance
Liquidation
Stock market
Financial market
Tax
Financial institution
Capital management
Venture capital
Asset
Brand
Business intelligence
Business development
Capacity
Capability
Change
innovation
Commercial
Marketing
Communications
Configuration
Conflict
Content
Customer relationship
Distributed
Earned value
Electronic business
Enterprise resource planning 
management information system
Financial
Human resource 
development
Incident
Knowledge
Legal
Materials
Network
administrator
Office
Operations 
services
Performance
Power
Problem
Process
Product life-cycle
Product
Project
Property
Quality
Records
Resource
Risk 
crisis
Sales
Security
Service
Strategic
Supply chain
Systems
administrator
Talent
Technology
innovation
Marketing
management information system
development
administrator
services
crisis
administrator
Architecture
Behavior
Communication
Culture
Conflict
Development
Engineering
Hierarchy
Patterns
Space
Structure
Business analysis
Business ethics
Business plan
Business judgment rule
Consumer behaviour
Business operations
International business
Business model
International trade
Trade route
Business process
Business statistics
Trade route
 Business and economics portal
vte
Enterprise risk management (ERM) defines risk as those possible events or circumstances that can have negative influences on the enterprise in question, 
where the impact can be on the very existence, the resources (human and capital), the products and services, or the customers of the enterprise, as well as external impacts on society, markets, or the environment. 
There are various defined frameworks here, where every probable risk can have a pre-formulated plan to deal with its possible consequences (to ensure contingency if the risk becomes a liability).
Managers thus analyze and monitor both the internal and external environment facing the enterprise, addressing business risk generally, and any impact on the enterprise achieving its strategic goals.
ERM thus overlaps various other disciplines - operational risk management, financial risk management etc. - but is differentiated by its strategic and long-term focus. [25]ERM systems usually focus on safeguarding reputation, acknowledging its significant role in comprehensive risk management strategies.[26]

As applied to finance, risk management concerns the techniques and practices for measuring, monitoring and controlling the market- and credit risk (and operational risk) on a firm's balance sheet, on a bank's credit- or trading book, or re a fund manager's portfolio value; for an overview see Finance § Risk management.

A traditional measure in banking is value at risk (VaR) – the possible loss due to adverse credit and market events. Banks seek to hedge these risks, and will hold risk capital on the net position. The Basel III framework governs the parallel regulatory capital requirements, including for operational risk.
Fund managers employ various strategies to protect their fund value; these given their mandate and benchmark.
Non-financial firms focus on business risk more generally, overlapping enterprise risk management: i.e. those events and occurrences which could negatively impact cash flow or profitability, and hence result in a loss of business value or a decline in share price.
In information technology, risk management includes "Incident Handling", an action plan for dealing with intrusions, cyber-theft, denial of service, fire, floods, and other security-related events. According to the SANS Institute, it is a six step process: Preparation, Identification, Containment, Eradication, Recovery, and Lessons Learned.[27]

The concept of "contractual risk management" emphasises the use of risk management techniques in contract deployment, i.e. managing the risks which are accepted through entry into a contract. Norwegian academic Petri Keskitalo defines "contractual risk management" as "a practical, proactive and systematical contracting method that uses contract planning and governance to manage risks connected to business activities".[28] In an article by Samuel Greengard published in 2010, two US legal cases are mentioned which emphasise the importance of having a strategy for dealing with risk:[29]

UDC v. CH2M Hill, which deals with the risk to a professional advisor who signs an indemnification provision including acceptance of a duty to defend, who may thereby pick up the legal costs of defending a client subject to a claim from a third party,[30]
Witt v. La Gorce Country Club, which deals with the effectiveness of a limitation of liability clause, which may, in certain jurisdictions, be found to be ineffective.[31]
Greengard recommends using industry-standard contract language as much as possible to reduce risk as much as possible and rely on clauses which have been in use and subject to established court interpretation over a number of years.[29]

Customs risk management is concerned with the risks which arise within the context of international trade and have a bearing on safety and security, including the risk that illicit drugs and counterfeit goods can pass across borders and the risk that shipments and their contents are incorrectly declared.[32] The European Union has adopted a Customs Risk Management Framework (CRMF) applicable across the union and throughout its member states, whose aims include establishing a common level of customs control protection and a balance between the objectives of safe customs control and the facilitation of legitimate trade.[33] Two events which prompted the European Commission to review customs risk management policy in 2012-13 were the September 11 attacks of 2001 and the 2010 transatlantic aircraft bomb plot involving packages being sent from Yemen to the United States, referred to by the Commission as "the October 2010 (Yemen) incident".[34]

ESRM is a security program management approach that links security activities to an enterprise's mission and business goals through risk management methods. The security leader's role in ESRM is to manage risks of harm to enterprise assets in partnership with the business leaders whose assets are exposed to those risks. ESRM involves educating business leaders on the realistic impacts of identified risks, presenting potential strategies to mitigate those impacts, then enacting the option chosen by the business in line with accepted levels of business risk tolerance[35]

For medical devices, risk management is a process for identifying, evaluating and mitigating risks associated with harm to people and damage to property or the environment. Risk management is an integral part of medical device design and development, production processes and evaluation of field experience, and is applicable to all types of medical devices. The evidence of its application is required by most regulatory bodies such as the US FDA. The management of risks for medical devices is described by the International Organization for Standardization (ISO) in ISO 14971:2019, Medical Devices—The application of risk management to medical devices, a product safety standard. The standard provides a process framework and associated requirements for management responsibilities, risk analysis and evaluation, risk controls and lifecycle risk management. Guidance on the application of the standard is available via ISO/TR 24971:2020.

The European version of the risk management standard was updated in 2009 and again in 2012 to refer to the Medical Devices Directive (MDD) and Active Implantable Medical Device Directive (AIMDD) revision in 2007, as well as the In Vitro Medical Device Directive (IVDD). The requirements of EN 14971:2012 are nearly identical to ISO 14971:2007. The differences include three "(informative)" Z Annexes that refer to the new MDD, AIMDD, and IVDD. These annexes indicate content deviations that include the requirement for risks to be reduced as far as possible, and the requirement that risks be mitigated by design and not by labeling on the medical device (i.e., labeling can no longer be used to mitigate risk).

Typical risk analysis and evaluation techniques adopted by the medical device industry include hazard analysis, fault tree analysis (FTA), failure mode and effects analysis (FMEA), hazard and operability study (HAZOP), and risk traceability analysis for ensuring risk controls are implemented and effective (i.e. tracking risks identified to product requirements, design specifications, verification and validation results etc.). FTA analysis requires diagramming software. FMEA analysis can be done using a spreadsheet program. There are also integrated medical device risk management solutions.

Through a draft guidance, the FDA has introduced another method named "Safety Assurance Case" for medical device safety assurance analysis. The safety assurance case is structured argument reasoning about systems appropriate for scientists and engineers, supported by a body of evidence, that provides a compelling, comprehensible and valid case that a system is safe for a given application in a given environment. With the guidance, a safety assurance case is expected for safety critical devices (e.g. infusion devices) as part of the pre-market clearance submission, e.g. 510(k). In 2013, the FDA introduced another draft guidance expecting medical device manufacturers to submit cybersecurity risk analysis information.

Project risk management must be considered at the different phases of acquisition. At the beginning of a project, the advancement of technical developments, or threats presented by a competitor's projects, may cause a risk or threat assessment and subsequent evaluation of alternatives (see Analysis of Alternatives). Once a decision is made, and the project begun, more familiar project management applications can be used:[36][37][38]

Planning how risk will be managed in the particular project. Plans should include risk management tasks, responsibilities, activities and budget.
Assigning a risk officer – a team member other than a project manager who is responsible for foreseeing potential project problems. Typical characteristic of risk officer is a healthy skepticism.
Maintaining live project risk database. Each risk should have the following attributes: opening date, title, short description, probability and importance. Optionally a risk may have an assigned person responsible for its resolution and a date by which the risk must be resolved.
Creating anonymous risk reporting channel. Each team member should have the possibility to report risks that he/she foresees in the project.
Preparing mitigation plans for risks that are chosen to be mitigated. The purpose of the mitigation plan is to describe how this particular risk will be handled – what, when, by whom and how will it be done to avoid it or minimize consequences if it becomes a liability.
Summarizing planned and faced risks, effectiveness of mitigation activities, and effort spent for the risk management.
Megaprojects (sometimes also called "major programs") are large-scale investment projects, typically costing more than $1 billion per project. Megaprojects include major bridges, tunnels, highways, railways, airports, seaports, power plants, dams, wastewater projects, coastal flood protection schemes, oil and natural gas extraction projects, public buildings, information technology systems, aerospace projects, and defense systems. Megaprojects have been shown to be particularly risky in terms of finance, safety, and social and environmental impacts. Risk management is therefore particularly pertinent for megaprojects and special methods and special education have been developed for such risk management.[39]

It is important to assess risk in regard to natural disasters like floods, earthquakes, and so on. Outcomes of natural disaster risk assessment are valuable when considering future repair costs, business interruption losses and other downtime, effects on the environment, insurance costs, and the proposed costs of reducing the risk.[40][41] The Sendai Framework for Disaster Risk Reduction is a 2015 international accord that has set goals and targets for disaster risk reduction in response to natural disasters.[42] There are regular International Disaster and Risk Conferences in Davos to deal with integral risk management.

Several tools can be used to assess risk and risk management of natural disasters and other climate events, including geospatial modeling, a key component of land change science. This modeling requires an understanding of geographic distributions of people as well as an ability to calculate the likelihood of a natural disaster occurring.

The management of risks to persons and property in wilderness and remote natural areas has developed with increases in outdoor recreation participation and decreased social tolerance for loss. Organizations providing commercial wilderness experiences can now align with national and international consensus standards for training and equipment such as ANSI/NASBLA 101-2017 (boating),[43] UIAA 152 (ice climbing tools),[44] and European Norm 13089:2015 + A1:2015 (mountaineering equipment).[45][46] The Association for Experiential Education offers accreditation for wilderness adventure programs.[47] The Wilderness Risk Management Conference provides access to best practices, and specialist organizations provide wilderness risk management consulting and training.[48]

The text Outdoor Safety – Risk Management for Outdoor Leaders,[49] published by the New Zealand Mountain Safety Council, provides a view of wilderness risk management from the New Zealand perspective, recognizing the value of national outdoor safety legislation and devoting considerable attention to the roles of judgment and decision-making processes in wilderness risk management.

One popular models for risk assessment is the Risk Assessment and Safety Management (RASM) Model developed by Rick Curtis, author of The Backpacker's Field Manual.[50] The formula for the RASM Model is: Risk = Probability of Accident × Severity of Consequences. The RASM Model weighs negative risk—the potential for loss, against positive risk—the potential for growth.

IT risk is a risk related to information technology. This is a relatively new term due to an increasing awareness that information security is simply one facet of a multitude of risks that are relevant to IT and the real world processes it supports. "Cybersecurity is tied closely to the advancement of technology. It lags only long enough for incentives like black markets to evolve and new exploits to be discovered. There is no end in sight for the advancement of technology, so we can expect the same from cybersecurity."[51]

ISACA's Risk IT framework ties IT risk to enterprise risk management.

Duty of Care Risk Analysis (DoCRA)[52] evaluates risks and their safeguards and considers the interests of all parties potentially affected by those risks.

The Verizon Data Breach Investigations Report (DBIR) features how organizations can leverage the Veris Community Database (VCDB) to estimate risk. Using HALOCK methodology within CIS RAM and data from VCDB, professionals can determine threat likelihood for their industries. 

Operational risk management (ORM) is the oversight of operational risk, including the risk of loss resulting from: inadequate or failed internal processes and systems; human factors; or external events. Given the nature of operations, ORM is typically a "continual" process, and will include ongoing risk assessment, risk decision making, and the implementation of risk controls.

For the offshore oil and gas industry, operational risk management is regulated by the safety case regime in many countries. Hazard identification and risk assessment tools and techniques are described in the international standard ISO 17776:2000, and organisations such as the IADC (International Association of Drilling Contractors) publish guidelines for Health, Safety and Environment (HSE) Case development which are based on the ISO standard. Further, diagrammatic representations of hazardous events are often expected by governmental regulators as part of risk management in safety case submissions; these are known as bow-tie diagrams (see Network theory in risk assessment). The technique is also used by organisations and regulators in mining, aviation, health, defence, industrial and finance.

The principles and tools for quality risk management are increasingly being applied to different aspects of pharmaceutical quality systems. These aspects include development, manufacturing, distribution, inspection, and submission/review processes throughout the lifecycle of drug substances, drug products, biological and biotechnological products (including the use of raw materials, solvents, excipients, packaging and labeling materials in drug products, biological and biotechnological products). Risk management is also applied to the assessment of microbiological contamination in relation to pharmaceutical products and cleanroom manufacturing environments.[53]

Supply chain risk management (SCRM) aims at maintaining supply chain continuity in the event of scenarios or incidents which could interrupt normal business and hence profitability.
Risks to the supply chain range from everyday to exceptional, including unpredictable natural events (such as tsunamis and pandemics) to counterfeit products, and reach across quality, security, to resiliency and product integrity.
Mitigation of these risks can involve various elements of the business including logistics and cybersecurity, as well as the areas of finance and operations.

Risk communication is a complex cross-disciplinary academic field that is part of risk management and related to fields like crisis communication. The goal is to make sure that targeted audiences understand how risks affect them or their communities by appealing to their values.[54][55]

Risk communication is particularly important in disaster preparedness,[56] public health,[57] and preparation for major global catastrophic risk.[56] For example, the impacts of climate change and climate risk effect every part of society, so communicating that risk is an important climate communication practice, in order for societies to plan for climate adaptation.[58] Similarly, in pandemic prevention, understanding of risk helps communities stop the spread of disease and improve responses.[59]

Risk communication deals with possible risks and aims to raise awareness of those risks to encourage or persuade changes in behavior to relieve threats in the long term. On the other hand, crisis communication is aimed at raising awareness of a specific type of threat, the magnitude, outcomes, and specific behaviors to adopt to reduce the threat.[60]

Risk communication in food safety is part of the risk analysis framework. Together with risk assessment and risk management, risk communication aims to reduce foodborne illnesses. Food safety risk communication is an obligatory activity for food safety authorities[61] in countries, which adopted the Agreement on the Application of Sanitary and Phytosanitary Measures.

Business continuity
Catastrophe modeling for risk management
Crossing the river by touching the stones
Disaster risk reduction
Environmental Risk Management Authority (NZ)
Financial risk management
International Institute of Risk & Safety Management
ISO 31000
IT risk management
Loss-control consultant
National Safety Council (USA)
Optimism bias
Pest risk analysis
Precautionary principle
Reference class forecasting
Representative heuristic
Risk appetite
Risk aversion
Risk management tools
Roy's safety-first criterion
Security management
Social risk management
Stranded asset
Supply-chain risk management
Three lines of defence
Gordon–Loeb model
Risk managementActuarial scienceProject managementRisk analysisSystems engineeringCommunication studiesIEEE standardsISO/IEC standards
CS1 maint: numeric names: authors listWebarchive template wayback linksCS1 errors: generic nameCS1 maint: multiple names: authors listArticles with short descriptionShort description is different from WikidataArticles needing additional references from January 2014All articles needing additional referencesAll articles with unsourced statementsArticles with unsourced statements from March 2009All Wikipedia articles needing clarificationWikipedia articles needing clarification from January 2016Articles with excerptsCommons category link from WikidataArticles with GND identifiersArticles with J9U identifiersArticles with LCCN identifiersArticles with NKC identifiers






# Rolling-wave_planning.md




(Top)





1
References








2
External links










Rolling-wave planning is the process of project planning in waves as the project proceeds and later details become clearer; similar to the techniques used in agile software development approaches like Scrum.[1]

Work to be done in the near term is based on high-level assumptions; also, high-level milestones are set. As the project progresses, the risks, assumptions, and milestones originally identified become more defined and reliable. One would use rolling-wave planning in an instance where there is an extremely tight schedule or timeline to adhere to, as more thorough planning would place the schedule into an unacceptable negative schedule variance.

The concepts of rolling-wave planning and progressive elaboration are techniques covered in the Project Management Body of Knowledge.[2]

Schedule (project management)Management stubs
All stub articles






# Scott_Ambler.md




(Top)





1
Biography








2
Work








3
See also








4
Publications








5
References








6
External links


















This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these template messages)

 A major contributor to this article appears to have a close connection with its subject. It may require cleanup to comply with Wikipedia's content policies, particularly neutral point of view. Please discuss further on the talk page. (November 2019) (Learn how and when to remove this message)
This biography of a living person needs additional citations for verification, as its only attribution is to self-published sources; articles should not be based solely on such sources. Please help by adding reliable, independent sources. Immediately remove contentious material about living people that is unsourced or poorly sourced. (July 2021) (Learn how and when to remove this message)

 (Learn how and when to remove this message)
 A major contributor to this article appears to have a close connection with its subject. It may require cleanup to comply with Wikipedia's content policies, particularly neutral point of view. Please discuss further on the talk page. (November 2019) (Learn how and when to remove this message)
This biography of a living person needs additional citations for verification, as its only attribution is to self-published sources; articles should not be based solely on such sources. Please help by adding reliable, independent sources. Immediately remove contentious material about living people that is unsourced or poorly sourced. (July 2021) (Learn how and when to remove this message)
Scott W. Ambler (born 1966) is a Canadian software engineer, consultant and author. He is an author of books about the Disciplined Agile Delivery toolkit, the Unified process, Agile software development, the Unified Modeling Language, and Capability Maturity Model (CMM) development.

He regularly runs surveys[1] which explore software development issues and works with organizations in different countries on their approach to software development.

Ambler received a BSc in computer science and an MA in information science from the University of Toronto. He has been working in the IT industry since the mid-1980s, with object technology since the early 1990s,[2] and in IT methodologies since the mid-1990s. Scott has led the development of several software processes, including Disciplined Agile Delivery (DAD) (with Mark Lines), Agile Modeling (AM), Agile Data (AD), Enterprise Unified Process (EUP), and Agile Unified Process (AUP) methodologies. Scott was a Senior Consulting Partner with SA+A[3] and then became the Chief Scientist at Disciplined Agile[4] which became a part of the Project Management Institute[5] while helping organizations around the world to improve their IT processes.

Ambler was a contributing editor with Dr. Dobb's Journal,[6] and has written columns for Software Development, Object Magazine, and Computing Canada.

He is speaker at a wide variety of practitioner and academic conferences worldwide. Public conferences include Agile 20XX, Agile India 20XX, Software Development, Agile Universe, UML World, JavaOne, OOPSLA, EuroSPI, and CAiSE. Scott also is a keynote speaker at private conferences organized by large, Fortune 500 companies for their managers and IT staff.[7]

He is a Disciplined Agile Fellow of the Project Management Institute and a Fellow of the International Association of Software Architects (IASA). In the past he was an Eclipse Process Framework (EPF) committer and a Jolt Judge at the Jolt Awards.[2]

Ambler has co-developed Disciplined Agile Delivery (DAD) with Mark Lines, the Enterprise Unified Process[8] (an extension of the Rational Unified Process), and Agile Modeling.[9]

Database refactoring
Scott Ambler has published several books[10] and articles.[11] A selection:

Ambler, Scott (1995). The Object Primer: the application developer's guide to object-orientation. SIGS Books. ISBN 1-884842-17-8.
Ambler, Scott (1998). Process Patterns: building large-scale systems using object technology. Cambridge University Press. ISBN 0-521-64568-9.
Ambler, Scott (2002). Agile Modeling: Effective Practices for EXtreme Programming and the Unified Process. J. Wiley. ISBN 0-471-20282-7.
Ambler, Scott; Constantine, Larry (2002). The Unified Process Transition and Production Phases. CMP Books. ISBN 1-57820-092-X.
McGovern, James; Ambler, Scott; Stevens, Mike; Linn, James; Sharan, Vikas; Jo, Elias (2003). The Practical Guide to Enterprise Architecture. Prentice Hall. ISBN 0-13-141275-2.
Ambler, Scott (2003). Agile Database Techniques: effective strategies for the agile software developer. Wiley Publishing. ISBN 0-471-20283-5.
Ambler, Scott (2004). The Object Primer 3rd Edition: Agile Model Driven Development with UML 2. Cambridge University Press. ISBN 0-521-54018-6.
Ambler, Scott; Vizdos, Michael (2005). Enterprise Unified Process: Extending the Rational Unified Process. Prentice Hall PTR. ISBN 0-13-191451-0.
Ambler, Scott; Sadalage, Pramod J. (2006). Refactoring Databases: Evolutionary Database Design. Addison Wesley Professional. ISBN 0-321-29353-3.
Ambler, Scott; Lines, Mark (2012). Disciplined Agile Delivery: A Practitioner's Guide to Agile Software Delivery in the Enterprise. IBM press. ISBN 978-0132810135.
Lines, Mark; Ambler, Scott (2015). Introduction to Disciplined Agile Delivery: A Small Team's Journey from Scrum to Continuous Delivery. Disciplined Agile Consortium. ISBN 978-1497544383.
Ambler, Scott; Lines, Mark (2017). An Executive Guide to Disciplined Agile: Winning the Race to Business Agility. Disciplined Agile Consortium. ISBN 978-1539852964.
Lines, Mark; Ambler, Scott (2018). Introduction to Disciplined Agile Delivery 2nd Edition: A Small Team's Journey from Scrum to Disciplined DevOps. Project Management Institute. ISBN 978-1497544383.
Ambler, Scott; Lines, Mark (2022). Choose Your WoW!: A Disciplined Agile Delivery Handbook for Optimizing Your Way of Working. Project Management Institute. ISBN 978-1628257540.
1966 birthsLiving peopleCanadian software engineersCanadian technology writers
Articles with short descriptionShort description is different from WikidataWikipedia articles with possible conflicts of interest from November 2019Articles lacking reliable references from July 2021All articles lacking reliable referencesArticles with multiple maintenance issuesArticles with ISNI identifiersArticles with VIAF identifiersArticles with WorldCat Entities identifiersArticles with BNF identifiersArticles with BNFdata identifiersArticles with CANTICN identifiersArticles with GND identifiersArticles with J9U identifiersArticles with LCCN identifiersArticles with NDL identifiersArticles with NKC identifiersArticles with NLK identifiersArticles with NSK identifiersArticles with PLWABN identifiersArticles with ACM-DL identifiersArticles with DBLP identifiersArticles with SNAC-ID identifiersArticles with SUDOC identifiers






# Scrum_(software_development).md




(Top)





1
History








2
Scrum team




Toggle Scrum team subsection





2.1
Product owner








2.2
Developers








2.3
Scrum master










3
Workflow




Toggle Workflow subsection





3.1
Sprint








3.2
Sprint planning








3.3
Daily scrum








3.4
Post-sprint events








3.5
Backlog refinement










4
Artifacts




Toggle Artifacts subsection





4.1
Product backlog








4.2
Sprint backlog








4.3
Increment








4.4
Other artifacts






4.4.1
Burndown chart








4.4.2
Release burn-up chart








4.4.3
Velocity












5
Limitations








6
Adaptations




Toggle Adaptations subsection





6.1
Scrumban








6.2
Scrum of scrums








6.3
Large-scale scrum










7
Criticism








8
See also








9
Citations








10
References








11
External links












2.1
Product owner








2.2
Developers








2.3
Scrum master
















3.1
Sprint








3.2
Sprint planning








3.3
Daily scrum








3.4
Post-sprint events








3.5
Backlog refinement




















4.1
Product backlog








4.2
Sprint backlog








4.3
Increment








4.4
Other artifacts






4.4.1
Burndown chart








4.4.2
Release burn-up chart








4.4.3
Velocity


















4.4.1
Burndown chart








4.4.2
Release burn-up chart








4.4.3
Velocity


















6.1
Scrumban








6.2
Scrum of scrums








6.3
Large-scale scrum






















This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these template messages)

This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Scrum" software development – news · newspapers · books · scholar · JSTOR (May 2020) (Learn how and when to remove this message)
Some of this article's listed sources may not be reliable. Please help improve this article by looking for better, more reliable sources. Unreliable citations may be challenged and removed. (May 2020) (Learn how and when to remove this message)

 (Learn how and when to remove this message)
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Scrum" software development – news · newspapers · books · scholar · JSTOR (May 2020) (Learn how and when to remove this message)
Some of this article's listed sources may not be reliable. Please help improve this article by looking for better, more reliable sources. Unreliable citations may be challenged and removed. (May 2020) (Learn how and when to remove this message)


Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Scrum is an agile team collaboration framework commonly used in software development and other industries. 

Scrum prescribes for teams to break work into goals to be completed within time-boxed iterations, called sprints. Each sprint is no longer than one month and commonly lasts two weeks. The scrum team assesses progress in time-boxed, stand-up meetings of up to 15 minutes, called daily scrums. At the end of the sprint, the team holds two further meetings: one sprint review to demonstrate the work for stakeholders and solicit feedback, and one internal sprint retrospective. A person in charge of a scrum team is typically called a scrum master.[2]

Scrum's approach to product development involves bringing decision-making authority to an operational level.[3] Unlike a sequential approach to product development, scrum is an iterative and incremental framework for product development.[4] Scrum allows for continuous feedback and flexibility, requiring teams to self-organize by encouraging physical co-location or close online collaboration, and mandating frequent communication among all team members. The flexible and semi-unplanned approach of scrum is based in part on the notion of requirements volatility, that stakeholders will change their requirements as the project evolves.[5]

The use of the term scrum in software development came from a 1986 Harvard Business Review paper titled "The New New Product Development Game" by Hirotaka Takeuchi and Ikujiro Nonaka. Based on case studies from manufacturing firms in the automotive, photocopier, and printer industries, the authors outlined a new approach to product development for increased speed and flexibility. They called this the rugby approach, as the process involves a single cross-functional team operating across multiple overlapping phases, in which the team "tries to go the distance as a unit, passing the ball back and forth".[6] The authors later developed scrum in their book, The Knowledge Creating Company.[7]

In the early 1990s, Ken Schwaber used what would become scrum at his company, Advanced Development Methods. Jeff Sutherland, John Scumniotales, and Jeff McKenna developed a similar approach at Easel Corporation, referring to the approach with the term scrum.[8] Sutherland and Schwaber later worked together to integrate their ideas into a single framework, formally known as scrum. Schwaber and Sutherland tested scrum and continually improved it, leading to the publication of a research paper in 1995,[9] and the Manifesto for Agile Software Development in 2001.[10] Schwaber also collaborated with Babatunde Ogunnaike at DuPont Research Station and the University of Delaware to develop Scrum. Ogunnaike believed that software development projects could often fail when initial conditions change, if the product management was not rooted in empirical practice.[3]

In 2002, Schwaber with others founded the Scrum Alliance and set up the Certified Scrum accreditation series.[11] Schwaber left the Scrum Alliance in late 2009 and subsequently founded Scrum.org which oversees the parallel Professional Scrum accreditation series.[12] Since 2009, a public document called The Scrum Guide[13] has been published and updated by Schwaber and Sutherland. It has been revised 6 times, with the current version being November 2020.

A scrum team is organized into at least three categories of individuals: the product owner, developers, and the scrum master. The product owner liaises with stakeholders, those who have interest in the project's outcome, to communicate tasks and expectations with developers.[14] Developers in a scrum team organize work by themselves, with the facilitation of a scrum master.[15] Scrum teams, ideally, should abide by the five values of scrum: commitment, courage, focus, openness, and respect.[13]

Each scrum team has one product owner.[16] The product owner focuses on the business side of product development and spends the majority of time liaising with stakeholders and the team. The role is intended to primarily represent the product's stakeholders, the voice of the customer, or the desires of a committee, and bears responsibility for the delivery of business results.[17][18][19][20] Product owners manage the product backlog, which is essentially the project's running to-do list, and are responsible for maximizing the value that a team delivers.[18] They do not dictate the technical solutions of a team but may instead attempt to seek consensus among team members.[21][22]

As the primary liaison of the scrum team towards stakeholders, product owners are responsible for communicating announcements, project definitions and progress, RIDAs (risks, impediments, dependencies, and assumptions), funding and scheduling changes, the product backlog, and project governance, among other responsibilities.[23][better source needed] Product owners can also cancel a sprint if necessary, without the input of team members.[13]

In scrum, the term developer or team member refers to anyone who plays a role in the development and support of the product and can include researchers, architects, designers, programmers, etc.[13][24]

Scrum is facilitated by a scrum master, whose role is to educate and coach teams about scrum theory and practice.[1] Scrum masters have differing roles and responsibilities from traditional team leads or project managers. Some scrum master responsibilities include coaching, objective setting, problem solving, oversight, planning, backlog management, and communication facilitation.[1] On the other hand, traditional project managers often have people management responsibilities, which a scrum master does not. Scrum teams do not involve project managers, so as to maximize self-organisation among developers.[25]

A sprint (also known as an iteration, timebox or design sprint) is a fixed period of time wherein team members work on a specific goal. Each sprint is normally between one week and one month, with two weeks being the most common.[3] Usually, daily meetings are held to discuss the progress of the project undertaken as well as difficulties faced by team members. The outcome of the sprint is a functional deliverable, or a product which has received some development in increments. 

When a sprint is abnormally terminated, the next step is to conduct new sprint planning, where the reason for the termination is reviewed.

Each sprint starts with a sprint planning event in which a sprint goal is defined. Priorities for planned sprints are chosen out of the backlog. Each sprint ends with two events:[8]

A sprint review (progress shown to stakeholders to elicit their feedback)
A sprint retrospective (identify lessons and improvements for the next sprints)
Scrum emphasizes actionable output at the end of each sprint, which brings the developed product closer to market success.

At the beginning of a sprint, the scrum team holds a sprint planning event to:

Agree on the sprint goal, that is, what they intend to deliver by sprint end
Identifying product backlog items that contribute towards this goal
Form a sprint backlog by selecting which identified items should be completed in the sprint
The suggested maximum duration of sprint planning is eight hours for a four-week sprint.[13]

Each day during a sprint, the developers hold a daily scrum (often conducted standing up) with specific guidelines, and which may be facilitated by a scrum master.[3][26] Daily scrum meetings are intended to be less than 15 minutes in length, taking place at the same time and location daily. The purpose of the meeting is to announce progress made towards the sprint goal and issues that may be hindering the goal, without going into any detailed discussion. Once over, individual members can go into a 'breakout session' or an 'after party' for extended discussion and collaboration.[27] Scrum masters are responsible for ensuring that team members use daily scrums effectively, or, if team members are unable to use them, to provide alternatives to achieve similar outcomes.[28][29]

Conducted at the end of a sprint, a sprint review is a meeting that has a team share the work they've completed with stakeholders and liaise with them on feedback, expectations, and upcoming plans. At a sprint review completed deliverables are demonstrated to stakeholders, who should also be made aware of product increments and works in progress. The recommended duration for a sprint review is one hours per week of sprint.[13]

A sprint retrospective is a separate meeting that allows team members to internally analyze strengths and weaknesses of the sprint, future areas of improvement, and continuous process improvement actions.[30]

Backlog refinement is a process by which team members revise and prioritize a backlog for future sprints.[31] It can be done as a separate stage done before the beginning of a new sprint or as a continuous process that team members work on by themselves. Backlog refinement can include the breaking down of large tasks into smaller and clearer ones, the clarification of success criteria, and the revision of changing priorities and returns. It is recommended to invest of up to 10 percent of a team's sprint capacity on backlog refinement.[13]

This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (March 2013) (Learn how and when to remove this message)
Artifacts are a means by which scrum teams manage product development by documenting work done towards the project. The main scrum artifacts used are the product backlog, sprint backlog, and increment.

The product backlog is a breakdown of work to be done and contains an ordered list of product requirements (such as features, bug fixes, non-functional requirements) that the team maintains for a product. The order of a product backlog corresponds to the urgency of the task. Common formats for backlog items include user stories and use cases.[25] The product backlog may also contain the product owner's assessment of business value and the team's assessment of the product's effort or complexity, which can be stated in story points using the rounded Fibonacci scale. These estimates help the product owner to gauge the timeline and may influence the ordering of product backlog items.[32]

The product owner maintains and prioritizes product backlog items based on considerations such as risk, business value, dependencies, size, and timing. High-priority items at the top of the backlog are broken down into more detail for developers to work on, while tasks further down the backlog may be more vague.[3]

The sprint backlog is the subset of items from the product backlog intended for developers to address in a particular sprint.[33] Developers fill this backlog with tasks they deem appropriate to fill the sprint, using past performance to assess their capacity for each sprint. The scrum approach has tasks on the sprint backlog not assigned to developers by any particular individual or leader. Team members self organize by pulling work as needed according to the backlog priority and their own capabilities and capacity.[34]

An increment is a potentially releasable output of a sprint, which meets the sprint goal. It is formed from all the completed sprint backlog items, integrated with the work of all previous sprints. An ideal increment is complete, fully functioning, and in a usable condition.

Often used in scrum, a burndown chart is a publicly displayed chart showing remaining work.[35] Updated every day, it provides quick visualizations for reference. The horizontal axis of the burndown chart shows the days remaining, while the vertical axis shows the amount of work remaining each day. During sprint planning, the ideal burndown chart is plotted. Then, during the sprint, developers update the chart with remaining work so the chart is updated day by day, showing a comparison between actual and predicted.

Updated at the end of each sprint, the release burn-up chart shows progress towards delivering a forecast scope. The horizontal axis of the release burn-up chart shows the sprints in a release, while the vertical axis shows the amount of work completed at the end of each sprint. 

Some project managers believe that a team's total capability effort for a single sprint can be derived by evaluating work completed in the last sprint. The collection of historical "velocity" data is a guideline for assisting the team in understanding their capacity. Nonetheless, the concept of velocity has been controversial among scrum practitioners.

Some have argued that scrum events, such as daily scrum and scrum review, hurt productivity and waste time that could be better spent on actual productive tasks.[36][37] In practice, many scrum practitioners conduct events, like the daily scrum, as an extended discussion, without complying with the time-boxing requirement.[citation needed]

Scrum has also been observed to pose difficulties for a number of types of teams, including those which are part-time or geographically distant; which have members that are highly specialized and would be better off working by themselves or in working cliques; which have many external dependencies that disrupt planned short sprints of work from occurring; and which are unsuitable for incremental and development testing.[38][39]

Scrum is frequently tailored or adapted in different contexts to achieve varying aims.[40] A common approach to adapting scrum is the combination of scrum with other software development methodologies, as scrum does not cover the whole product development lifecycle.[41] Various scrum practitioners have also suggested more detailed techniques for how to apply or adapt scrum to particular problems or organizations. Many refer to these techniques as 'patterns', an analogous use to design patterns in architecture and software.[42][43]

Scrumban is a software production model based on scrum and kanban. To illustrate each stage of work, teams working in the same space often use post-it notes or a large whiteboard.[44] Scrumban is especially suited for product maintenance with frequent and unexpected work items, such as production defects or programming errors. In such cases time-limited scrum sprints may not be as beneficial, although scrum's daily events and other practices can still be applied. At the same time, kanban models allow a team to visualize work stages and limitations.[45]

Scrum of scrums is a technique to operate scrum at scale, for multiple teams coordinating on the same product. Scrum-of-scrums daily scrum meetings involve ambassadors selected from each individual team, who may be either a developer or scrum master. As a tool for coordination, scrum of scrums allows teams to collectively work on team-wide risks, impediments, dependencies, and assumptions (RIDAs), which may be tracked in a backlog of its own.[46][47]

Large-scale scrum is a product development framework that scales scrum with varied rules and guidelines, developed by Bas Vodde and Craig Larman.[48][49] There are two levels to the framework: the first level, designed for up to eight teams; and the second level, known as 'LeSS Huge', which can accommodate development involving hundreds of developers.[50]

This section needs expansion. You can help by adding to it. (June 2024)
A systematic review found "that Distributed Scrum has no impact, positive or negative on overall project success" in distributed software development.[51]

Martin Fowler, one of the authors of the Manifesto for Agile Software Development, has criticised what he calls "faux-agile" practices that are "disregarding agile's values and principles",[52] and "the Agile Industrial Complex imposing methods upon people" contrary to the Agile principle of valuing "individuals and interactions over processes and tools"[10] and allowing the individuals doing the work to decide how the work is done, changing processes to suit their needs.

In September 2016, Ron Jeffries, a signatory to the Agile Manifesto,[10] described what he called "Dark Scrum", saying that "Scrum can be very unsafe for programmers."[53]

Agile software development
Agile testing
Agile learning
Disciplined agile delivery
Comparison of scrum software
High-performance teams
Lean software development
Project management
Unified Process
Agile testing

^ a b c Ken Schwaber; Jeff Sutherland. "The Scrum Guide" (PDF). Scrum.org. Retrieved June 15, 2023.

^ "What Is A Scrum Master? Everything You Need To Know – Forbes Advisor". www.forbes.com. Retrieved November 16, 2023.

^ a b c d e Schwaber, Ken (February 1, 2004). Agile Project Management with Scrum. Microsoft Press. ISBN 978-0-7356-1993-7.

^ "What is Scrum?". What is Scrum? An Agile Framework for Completing Complex Projects – Scrum Alliance. Scrum Alliance. Retrieved February 24, 2016.

^ J. Henry and S. Henry. Quantitative assessment of the software maintenance process and requirements volatility. In Proc. of the ACM Conference on Computer Science, pages 346–351, 1993.

^ Takeuchi, Hirotaka; Nonaka, Ikujiro (January 1, 1986). "The New New Product Development Game". Harvard Business Review. Retrieved June 9, 2010. Moving the Scrum Downfield

^ The Knowledge Creating Company. Oxford University Press. 1995. p. 3. ISBN 978-0-19-976233-0. Retrieved March 12, 2013.

^ a b Sutherland, Jeff (October 2004). "Agile Development: Lessons learned from the first Scrum". Archived from the original (PDF) on June 30, 2014. Retrieved September 26, 2008.

^ Sutherland, Jeffrey Victor; Schwaber, Ken (1995). Business object design and implementation: OOPSLA '95 workshop proceedings. The University of Michigan. p. 118. ISBN 978-3-540-76096-2.

^ a b c "Manifesto for Agile Software Development". Retrieved October 17, 2019.

^ Maximini, Dominik (January 8, 2015). The Scrum Culture: Introducing Agile Methods in Organizations. Management for Professionals. Cham: Springer (published 2015). p. 26. ISBN 978-3-319-11827-7. Retrieved August 25, 2016. Ken Schwaber and Jeff Sutherland presented Scrum for the first time at the OOPSLA conference in Austin, Texas, in 1995. [...] In 2001, the first book about Scrum was published. [...] One year later (2002), Ken founded the Scrum Alliance, aiming at providing worldwide Scrum training and certification.

^ "Home". Scrum.org. Retrieved January 6, 2020.

^ a b c d e f g Sutherland, Jeff; Schwaber, Ken (2013). "Scrum Guides". ScrumGuides.org. Retrieved June 15, 2023.

^ Morris, David (2017). Scrum: an ideal framework for agile projects. In Easy Steps. pp. 178–179. ISBN 978-1-84078-731-3. OCLC 951453155.

^ Cobb, Charles G. (2015). The Project Manager's Guide to Mastering Agile: Principles and Practices for an Adaptive Approach. Hoboken, NJ: John Wiley & Sons. p. 37. ISBN 978-1-118-99104-6.

^ Cohn, Mike (2010). Succeeding with Agile: Software Development Using Scrum. Upper Saddle River, NJ: Addison-Wesley. ISBN 978-0-321-57936-2.

^ Rubin, Kenneth (2013), Essential Scrum. A Practical Guide to the Most Popular Agile Process, Addison-Wesley, p. 173, ISBN 978-0-13-704329-3

^ a b McGreal, Don; Jocham, Ralph (June 4, 2018). The Professional Product Owner: Leveraging Scrum as a Competitive Advantage. Addison-Wesley Professional. ISBN 978-0-13-468665-3.

^ Pichler, Roman (March 11, 2010). Agile Product Management with Scrum: Creating Products that Customers Love. Addison-Wesley Professional. ISBN 978-0-321-68413-4.

^ Ambler, Scott. "The Product Owner Role: A Stakeholder Proxy for Agile Teams". agilemodeling.com. Retrieved July 22, 2016. [...] in practice there proves to be two critical aspects to this role: first as a stakeholder proxy within the development team and second as a project team representative to the overall stakeholder community as a whole.

^ "The Scrum Guide" (PDF). Scrum.org. p. 6. Retrieved June 15, 2023.

^ "The Role of the Product Owner". Scrum Alliance. Retrieved May 26, 2018.

^ "The Product Owner Role". Scrum Master Test Prep. Retrieved February 3, 2017.

^ Rad, Nader K.; Turley, Frank (2018). Agile Scrum Foundation Courseware, Second Edition. 's-Hertogenbosch, Netherlands: Van Haren. p. 26. ISBN 978-94-018-0279-6.

^ a b Pete Deemer; Gabrielle Benefield; Craig Larman; Bas Vodde (December 17, 2012). "The Scrum Primer: A Lightweight Guide to the Theory and Practice of Scrum (Version 2.0)". InfoQ.

^ "What is a Daily Scrum?". Scrum.org. Retrieved January 6, 2020.

^ Flewelling, Paul (2018). The Agile Developer's Handbook: Get more value from your software development: get the best out of the Agile methodology. Birmingham, UK: Packt Publishing Ltd. p. 91. ISBN 978-1-78728-020-5.

^ McKenna, Dave (2016). The Art of Scrum: How Scrum Masters Bind Dev Teams and Unleash Agility. Aliquippa, PA: CA Press. p. 126. ISBN 978-1-4842-2276-8.

^ Drongelen, Mike van; Dennis, Adam; Garabedian, Richard; Gonzalez, Alberto; Krishnaswamy, Aravind (2017). Lean Mobile App Development: Apply Lean startup methodologies to develop successful iOS and Android apps. Birmingham, UK: Packt Publishing Ltd. p. 43. ISBN 978-1-78646-704-1.

^ Rubin, Kenneth (2012), Essential Scrum. A Practical Guide to the Most Popular Agile Process, Addison-Wesley (published 2013), p. 375, ISBN 978-0-13-704329-3

^ Project Management Institute 2021, Glossary §3 Definitions. sfn error: no target: CITEREFProject\_Management\_Institute2021 (help)

^ Higgins, Tony (March 31, 2009). "Authoring Requirements in an Agile World". BA Times.

^ Russ J. Martinelli; Dragan Z. Milosevic (January 5, 2016). Project Management ToolBox: Tools and Techniques for the Practicing Project Manager. Wiley. p. 304. ISBN 978-1-118-97320-2.

^ Ken Schwaber; Jeff Sutherland. "The Scrum Guide" (PDF). Scrum.org. Retrieved May 25, 2018.

^ Charles G. Cobb (January 27, 2015). The Project Manager's Guide to Mastering Agile: Principles and Practices for an Adaptive Approach. John Wiley & Sons. p. 378. ISBN 978-1-118-99104-6.

^ Jenson, John (March 8, 2019). "Meetings: The productivity killer for developers". TandemSeven – The Experience Innovation Company. Archived from the original on June 5, 2020. Retrieved June 5, 2020.

^ "Not all developers like agile, and here are 5 reasons why". Business Matters. December 4, 2019. Retrieved June 5, 2020.

^ Turk, Dan; France, Robert; Rumpe, Bernhard (2014) [2002]. "Limitations of Agile Software Processes". Proceedings of the Third International Conference on Extreme Programming and Flexible Processes in Software Engineering: 43–46. arXiv:1409.6600.

^ "Issues and Challenges in Scrum Implementation" (PDF). International Journal of Scientific & Engineering Research. 3 (8). August 2012. Retrieved December 10, 2015.

^ Hron, Michal; Obwegeser, Nikolaus (January 1, 2022). "Why and how is Scrum being adapted in practice: A systematic review". Journal of Systems and Software. 183: 111110. doi:10.1016/j.jss.2021.111110. ISSN 0164-1212. S2CID 240950847.

^ Hron, M.; Obwegeser, N. (January 2018). "Scrum in practice: an overview of Scrum adaptations" (PDF). Proceedings of the 2018 51st Hawaii International Conference on System Sciences (HICSS), January 3–6, 2018.

^ Bjørnvig, Gertrud; Coplien, Jim (June 21, 2008). "Scrum as Organizational Patterns". Gertrude & Cope.

^ "Scrum Pattern Community". ScrumPLoP.org. Retrieved July 22, 2016.

^ Ladas, Corey (October 27, 2007). "scrum-ban". Lean Software Engineering. Archived from the original on August 23, 2018. Retrieved September 13, 2012.

^ Kniberg, Henrik; Skarin, Mattias (December 21, 2009). "Kanban and Scrum – Making the most of both" (PDF). InfoQ. Retrieved July 22, 2016.

^ "Risk Management – How to Stop Risks from Screwing Up Your Projects!". Kelly Waters.

^ "Scrum of Scrums". Agile Alliance. December 17, 2015. Archived from the original on February 9, 2014. Retrieved December 17, 2013.

^ "Large-Scale Scrum (LeSS)". 2014.

^ Grgic (2015). "Descaling organisation with LeSS (Blog)".

^ Larman, Craig; Bas Vodde (May–June 2013). "Scaling Agile Development" (PDF). Crosstalk.

^ Santos, Ronnie de Souza; Ralph, Paul; Arshad, Arham; Stol, Klaas-Jan (October 5, 2023). "Distributed Scrum: A Case Meta-Analysis". ACM Computing Surveys. 56 (4): 1–37. doi:10.1145/3626519. S2CID 263672588.

^ Fowler, Martin (August 25, 2018). "The State of Agile Software in 2018". martinfowler.com. Archived from the original on September 14, 2023. Retrieved September 14, 2023.

^ Jeffries, Ron (September 8, 2016). "Dark Scrum". ronjeffries.com. Retrieved May 6, 2024.


Agile software developmentSoftware developmentSoftware development philosophiesSoftware project management
Harv and Sfn no-target errorsArticles with short descriptionShort description is different from WikidataArticles needing additional references from May 2020All articles needing additional referencesArticles lacking reliable references from May 2020All articles lacking reliable referencesArticles with multiple maintenance issuesUse American English from July 2023All Wikipedia articles written in American EnglishUse mdy dates from February 2022Articles lacking reliable references from July 2023Articles needing additional references from March 2013All articles with unsourced statementsArticles with unsourced statements from July 2023Articles to be expanded from June 2024All articles to be expandedArticles using small message boxesCommons category link is on WikidataArticles prone to spam from May 2015Articles with J9U identifiersArticles with LCCN identifiers






# Scrumban.md




(Top)





1
History








2
The Method




Toggle The Method subsection





2.1
Iterations








2.2
On-demand planning








2.3
Prioritization








2.4
Bucket size planning








2.5
The board








2.6
The team








2.7
Pull principle








2.8
Feature freeze








2.9
Triage










3
Tooling








4
See also








5
References












2.1
Iterations








2.2
On-demand planning








2.3
Prioritization








2.4
Bucket size planning








2.5
The board








2.6
The team








2.7
Pull principle








2.8
Feature freeze








2.9
Triage






























This article contains content that is written like an advertisement. Please help improve it by removing promotional content and inappropriate external links, and by adding encyclopedic content written from a neutral point of view. (January 2017) (Learn how and when to remove this message)
This article needs attention from an expert in Software. Please add a reason or a talk parameter to this template to explain the issue with the article. WikiProject Software may be able to help recruit an expert. (August 2023)
Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Scrumban is an Agile aligned approach to product delivery which is a hybrid of Scrum and Kanban. Scrumban was originally designed as a way to transition from Scrum to Kanban.

Scrumban was developed as an attempt to make it easier for existing Scrum teams to begin exploring Lean and Kanban concepts.[1]

In Scrumban, the teamwork is organized in small iterations and monitored with the help of a visual board, similar to Scrum and kanban boards. To illustrate each stage of work, teams working in the same space often use post-it notes or a large whiteboard. In the case of decentralized teams, visual management software such as Assembla, Targetprocess, Eylean Board, JIRA, Mingle or Agilo for Trac are often used.[2] Planning meetings are held to determine what User Stories to complete in the next iteration. The User Stories are then added to the board and the team completes them, working on as few User Stories at a time as practical (work-in-progress, or WIP). To keep iterations short, WIP limits are used, and a planning trigger is set to know when to plan next - when WIP falls below a predetermined level. There are no predefined roles in Scrumban; the team keeps the roles they already have.[3]

Work iterations in Scrumban are kept short. This ensures that a team can easily adapt and change its course of action to a quickly changing environment. The length of the iteration is measured in weeks. The ideal length of an iteration depends on the work process of each team, however it is recommended not to have iterations exceeding two weeks.[4] Velocity (a measure of productivity) is often used by the team to assess issues and trends in its throughput, in order to support continuous improvement.

The planning in Scrumban is based on demand and occurs only when the planning trigger goes off. The planning trigger is associated with the number of tasks left in the "To Do" section of the board - when it goes down to a certain number, the planning event is held. The number of tasks that should trigger a planning event is not predefined. It depends on a team's velocity (how quickly can the remaining tasks be finished) and on the time required to plan the next iteration. The tasks planned for the next iteration are added to the "To Do" section of the board.

It is recommended to prioritize tasks during the planning event. This means the tasks are added to the board with marked priorities. It helps the team members to know which tasks should be completed first and which can be completed later. The prioritization can be done by adding numbers to the tasks or by adding an additional priority column, where the most important tasks are put at the top and the less important tasks below.

Bucket size planning brings the possibility of long-term planning to Scrumban. It is based on the system of three buckets that the work items need to go through before making it on the Scrumban board. The three buckets represent three different stages of the plan and are usually called 1-year, 6-month, and 3-month buckets. The 1-year bucket is dedicated for long-term goals that the company has, like penetrating a new market, releasing a new product, etc. When the company decides to move forward with a plan, it is moved to the 6-month bucket, where the main requirements of this plan are crystallized. When a company is ready to start implementing the plan, the requirements are moved into the 3-month bucket and divided into clear tasks to be completed by the project team. It is from this bucket that the team draws tasks during their on-demand planning meeting and starts working on the tasks.[5]

The basic Scrumban board is composed out of three columns: To Do, Doing, and Done. After the planning meeting, the tasks are added to the To Do column, when a team member is ready to work on a task, he/she moves it to the Doing column and when he/she completes it, he/she moves it to the Done column. The Scrumban board visually represents the progress of the team. The task board columns are adapted and expanded based on the team's work progress. The most common add-ons include priority columns in the To Do section and columns like Design, Manufacturing, and Testing in the Doing section.

WIP limits -- 
To ensure that the team is working effectively, Scrumban methodology states that a team member should be working on no more than one task at a time. To make sure this rule is followed Scrumban uses WIP (work in progress) limit. This limit is visualized on top of the Doing section of the board (also could be on each column of that section) and means that only that number of tasks can be in the corresponding column at one time. A WIP limit usually is equal to the number of people in the team but could be expanded based on the specifics of the team's work.

To Do limits --
In order to have more productive planning meetings, the number of tasks in the To Do section can be limited as well. The same as with WIP limits, it is written at the top of the To Do section or on top of the corresponding columns and limits the number of tasks in the To Do section or specific columns.

Scrumban does not require any specific number of team members or team roles. The roles a team has prior to adopting Scrumban are kept when implementing Scrumban. They are reinforced by team members having to choose the tasks to complete themselves. The team roles in Scrumban are more specialized and less cross-functional than what is expected in scrum teams.

In Scrumban tasks are not assigned to the team members by the team leader or project manager. Each team member chooses which task from the To Do section they are going to complete next. This guarantees a smooth process flow, where all the team members are equally busy at all times.

Feature freeze is used in Scrumban when the project deadline is approaching. It means that only the features that the team already has for development can still be worked on and no additional features can be added.[6]

Triage usually happens right after the feature freeze. With an approaching project deadline, the project manager decides which of the in-development features will be completed and which will stay unfinished. This guarantees that the team can focus on finishing important features before the project deadline and forget the less important ones.[7]

The most basic Scrumban set-up is a physical whiteboard with sticky notes. Electronic solutions, similar to scrum and kanban electronic boards are available as well. They offer full automation of the board, where it only has to be updated by the team members. Electronic boards often also provide automatic reports, the possibility of attachments and discussions on tasks, time tracking, as well as integrations with other commonly used project management software.[8]

Kanban (development)
List of software development philosophies
Scrum (software development)
Agile software developmentIndustrial organization
Articles with short descriptionShort description matches WikidataArticles with a promotional tone from January 2017All articles with a promotional toneArticles needing expert attention with no reason or talk parameterArticles needing expert attention from August 2023All articles needing expert attentionSoftware articles needing expert attention






# Software_craftsmanship.md




(Top)





1
Overview








2
Manifesto








3
History








4
References








5
Further reading








6
External links


















Software craftsmanship is an approach to software development that emphasizes the coding skills of the software developers. It is a response by software developers to the perceived ills of the mainstream software industry, including the prioritization of financial concerns over developer accountability.

Historically, programmers have been encouraged to see themselves as practitioners of the well-defined statistical analysis and mathematical rigor of a scientific approach with computational theory. This has changed to an engineering approach with connotations of precision, predictability, measurement, risk mitigation, and professionalism. Practice of engineering led to calls for licensing, certification and codified bodies of knowledge as mechanisms for spreading engineering knowledge and maturing the field.

The Agile Manifesto, with its emphasis on "individuals and interactions over processes and tools" questioned some of these assumptions. The Software Craftsmanship Manifesto extends and challenges further the assumptions of the Agile Manifesto, drawing a metaphor between modern software development and the apprenticeship model of medieval Europe.

The movement traces its roots to the ideas expressed in written works. The Pragmatic Programmer by Andy Hunt and Dave Thomas and Software Craftsmanship by Pete McBreen explicitly position software development as heir to the guild traditions of medieval Europe. The philosopher Richard Sennett wrote about software as a modern craft in his book The Craftsman. Freeman Dyson, in his essay "Science as a Craft Industry", expands software crafts to include mastery of using software as a driver for economic benefit:

Following initial discussion, conferences were held in both London[1] and Chicago,[2] after which, a manifesto[3] was drafted and put online to gather signatories. This was followed by the development of practices to further develop the movement including the exchange of talent in "Craftsman Swaps" and the assessment of skills in "Craftsmanship Spikes".

From the Software Craftsmanship website

As aspiring Software Craftsmen we are raising the bar of professional software development by practicing it and helping others learn the craft. Through this work we have come to value:

Not only working software, but also well-crafted software
Not only responding to change, but also steadily adding value
Not only individuals and interactions, but also a community of professionals
Not only customer collaboration, but also productive partnerships
That is, in pursuit of the items on the left we have found the items on the right to be indispensable.

The origins of software craftsmanship came from the agile software development movement which aimed to reform software project management in the 1990s.

In 1992, Jack W. Reeves' essay "What Is Software Design?"[4] suggested that software development is both a craft and an engineering discipline. Seven years later, in 1999, The Pragmatic Programmer was published. Its sub-title, "From Journeyman to Master", suggested that programmers go through stages in their professional development akin to the medieval guild traditions of Europe.

In 2001, Pete McBreen's book Software Craftsmanship was published. It suggested that software developers need not see themselves as part of the engineering tradition and that a different metaphor would be more suitable.

In his August keynote at Agile 2008, Robert C. Martin proposed a fifth value for the Agile Manifesto, namely "Craftsmanship over Crap". He later changed his proposal to "Craftsmanship over Execution".[5]

In December 2008, a number of aspiring software craftsmen met in Libertyville, Illinois, with the intent of establishing a set of principles for software craftsmanship. Three months later, a summary of the general conclusions was decided upon. It was presented publicly, for both viewing and signing, in the form of a Manifesto for Software Craftsmanship.[6]

In April 2009, two of the companies in the software craftsmanship movement, 8th Light and Obtiva, experimented with a "Craftsman Swap."[7] The Chicago Tribune covered this event on 15 June 2009.[8] In January 2010, a second Craftsman Swap was held between Obtiva and Relevance.[9]

The 'London Software Craftsmanship Community' (LSCC) was founded in 2010 and is today the largest and most active Software Craftsmanship community in the world, with more than 5000 craftspeople. In 2014, Sandro Mancuso, one of its co-founders, published a book The Software Craftsman: Professionalism, Pragmatism, Pride. It brought the software craftsmanship movement additional visibility, reinforcing the efforts to achieve higher technical excellence and customer satisfaction.

Computer programming
Articles with short descriptionShort description matches WikidataCS1 French-language sources (fr)






# Software_development.md




(Top)





1
Methodologies








2
Steps




Toggle Steps subsection





2.1
Feasibility








2.2
Analysis








2.3
Design








2.4
Programming








2.5
Testing








2.6
Production










3
Workers








4
Models and tools




Toggle Models and tools subsection





4.1
Computer-aided software engineering








4.2
Documentation








4.3
Effort estimation








4.4
Integrated development environment








4.5
Version control








4.6
View model








4.7
Fitness functions










5
Intellectual property








6
References








7
Further reading








8
External links












2.1
Feasibility








2.2
Analysis








2.3
Design








2.4
Programming








2.5
Testing








2.6
Production
























4.1
Computer-aided software engineering








4.2
Documentation








4.3
Effort estimation








4.4
Integrated development environment








4.5
Version control








4.6
View model








4.7
Fitness functions






























Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Software development is the process used to create software. Programming and maintaining the source code is the central step of this process, but it also includes conceiving the project, evaluating its feasibility, analyzing the business requirements, software design, testing, to release. Software engineering, in addition to development, also includes project management, employee management, and other overhead functions.[1] Software development may be sequential, in which each step is complete before the next begins, but iterative development methods where multiple steps can be executed at once and earlier steps can be revisited have also been devised to improve flexibility, efficiency, and scheduling.

Software development involves professionals from various fields, not just software programmers but also individuals specialized in testing, documentation writing, graphic design, user support, marketing, and fundraising. A number of tools and models are commonly used in software development, such as integrated development environment (IDE), version control, computer-aided software engineering, and software documentation.

Each of the available methodologies are best suited to specific kinds of projects, based on various technical, organizational, project, and team considerations.[3]

The simplest methodology is the "code and fix", typically used by a single programmer working on a small project. After briefly considering the purpose of the program, the programmer codes it and runs it to see if it works. When they are done, the product is released. This methodology is useful for prototypes but cannot be used for more elaborate programs.[4]
In the top-down waterfall model, feasibility, analysis, design, development, quality assurance, and implementation occur sequentially in that order. This model requires one step to be complete before the next begins, causing delays, and makes it impossible to revise previous steps if necessary.[5][6][7]
With iterative processes these steps are interleaved with each other for improved flexibility, efficiency, and more realistic scheduling. Instead of completing the project all at once, one might go through most of the steps with one component at a time. Iterative development also lets developers prioritize the most important features, enabling lower priority ones to be dropped later on if necessary.[6][8] Agile is one popular method, originally intended for small or medium sized projects, that focuses on giving developers more control over the features that they work on to reduce the risk of time or cost overruns.[9] Derivatives of agile include extreme programming and Scrum.[9] Open-source software development typically uses agile methodology with concurrent design, coding, and testing, due to reliance on a distributed network of volunteer contributors.[10]
Beyond agile, some companies integrate information technology (IT) operations with software development, which is called DevOps or DevSecOps including computer security.[11] DevOps includes continuous development, testing, integration of new code in the version control system, deployment of the new code, and sometimes delivery of the code to clients.[12] The purpose of this integration is to deliver IT services more quickly and efficiently.[11]
Another focus in many programming methodologies is the idea of trying to catch issues such as security vulnerabilities and bugs as early as possible (shift-left testing) to reduce the cost of tracking and fixing them.[13]

In 2009, it was estimated that 32 percent of software projects were delivered on time and budget, and with the full functionality. An additional 44 percent were delivered, but missing at least one of these features. The remaining 24 percent were cancelled prior to release.[14]

Software development life cycle refers to the systematic process of developing applications.[15]

The sources of ideas for software products are plentiful. These ideas can come from market research including the demographics of potential new customers, existing customers, sales prospects who rejected the product, other internal software development staff, or a creative third party. Ideas for software products are usually first evaluated by marketing personnel for economic feasibility, fit with existing channels of distribution, possible effects on existing product lines, required features, and fit with the company's marketing objectives. In the marketing evaluation phase, the cost and time assumptions become evaluated.[16] The feasibility analysis estimates the project's return on investment, its development cost and timeframe. Based on this analysis, the company can make a business decision to invest in further development.[17] After deciding to develop the software, the company is focused on delivering the product at or below the estimated cost and time, and with a high standard of quality (i.e., lack of bugs) and the desired functionality. Nevertheless, most software projects run late and sometimes compromises are made in features or quality to meet a deadline.[18]

Software analysis begins with a requirements analysis to capture the business needs of the software.[19] Challenges for the identification of needs are that current or potential users may have different and incompatible needs, may not understand their own needs, and change their needs during the process of software development.[20] Ultimately, the result of analysis is a detailed specification for the product that developers can work from. Software analysts often decompose the project into smaller objects, components that can be reused for increased cost-effectiveness, efficiency, and reliability.[19] Decomposing the project may enable a multi-threaded implementation that runs significantly faster on multiprocessor computers.[21]

During the analysis and design phases of software development, structured analysis is often used to break down the customer's requirements into pieces that can be implemented by software programmers.[22] The underlying logic of the program may be represented in data-flow diagrams, data dictionaries, pseudocode, state transition diagrams, and/or entity relationship diagrams.[23] If the project incorporates a piece of legacy software that has not been modeled, this software may be modeled to help ensure it is correctly incorporated with the newer software.[24]

Design involves choices about the implementation of the software, such as which programming languages and database software to use, or how the hardware and network communications will be organized. Design may be iterative with users consulted about their needs in a process of trial and error. Design often involves people expert in aspect such as database design, screen architecture, and the performance of servers and other hardware.[19] Designers often attempt to find patterns in the software's functionality to spin off distinct modules that can be reused with object-oriented programming. An example of this is the model–view–controller, an interface between a graphical user interface and the backend.[25]

The central feature of software development is creating and understanding the software that implements the desired functionality.[26] There are various strategies for writing the code. Cohesive software has various components that are independent from each other.[19] Coupling is the interrelation of different software components, which is viewed as undesirable because it increases the difficulty of maintenance.[27] Often, software programmers do not follow industry best practices, resulting in code that is inefficient, difficult to understand, or lacking documentation on its functionality.[28] These standards are especially likely to break down in the presence of deadlines.[29] As a result, testing, debugging, and revising the code becomes much more difficult. Code refactoring, for example adding more comments to the code, is a solution to improve the understandability of code.[30]

Testing is the process of ensuring that the code executes correctly and without errors. Debugging is performed by each software developer on their own code to confirm that the code does what it is intended to. In particular, it is crucial that the software executes on all inputs, even if the result is incorrect.[31] Code reviews by other developers are often used to scrutinize new code added to the project, and according to some estimates dramatically reduce the number of bugs persisting after testing is complete.[32] Once the code has been submitted, quality assurance—a separate department of non-programmers for most large companies—test the accuracy of the entire software product. Acceptance tests derived from the original software requirements are a popular tool for this.[31] Quality testing also often includes stress and load checking (whether the software is robust to heavy levels of input or usage), integration testing (to ensure that the software is adequately integrated with other software), and compatibility testing (measuring the software's performance across different operating systems or browsers).[31] When tests are written before the code, this is called test-driven development.[33]

Production is the phase in which software is deployed to the end user.[34] During production, the developer may create technical support resources for users[35][34] or a process for fixing bugs and errors that were not caught earlier. There might also be a return to earlier development phases if user needs changed or were misunderstood.[34]

Software development is performed by software developers, usually working on a team. Efficient communications between team members is essential to success. This is more easily achieved if the team is small, used to working together, and located near each other.[36] Communications also help identify problems at an earlier state of development and avoid duplicated effort. Many development projects avoid the risk of losing essential knowledge held by only one employee by ensuring that multiple workers are familiar with each component.[37] Software development involves professionals from various fields, not just software programmers but also individuals specialized in testing, documentation writing, graphic design, user support, marketing, and fundraising. Although workers for proprietary software are paid, most contributors to open-source software are volunteers.[38] Alternately, they may be paid by companies whose business model does not involve selling the software, but something else—such as services and modifications to open source software.[39]

Computer-aided software engineering (CASE) is tools for the partial automation of software development.[40] CASE enables designers to sketch out the logic of a program, whether one to be written, or an already existing one to help integrate it with new code or reverse engineer it (for example, to change the programming language).[41]

Documentation comes in two forms that are usually kept separate—that intended for software developers, and that made available to the end user to help them use the software.[42][43] Most developer documentation is in the form of code comments for each file, class, and method that cover the application programming interface (API)—how the piece of software can be accessed by another—and often implementation details.[44] This documentation is helpful for new developers to understand the project when they begin working on it.[45] In agile development, the documentation is often written at the same time as the code.[46] User documentation is more frequently written by technical writers.[47]

Accurate estimation is crucial at the feasibility stage and in delivering the product on time and within budget. The process of generating estimations is often delegated by the project manager.[48] Because the effort estimation is directly related to the size of the complete application, it is strongly influenced by addition of features in the requirements—the more requirements, the higher the development cost. Aspects not related to functionality, such as the experience of the software developers and code reusability, are also essential to consider in estimation.[49] As of 2019[update], most of the tools for estimating the amount of time and resources for software development were designed for conventional applications and are not applicable to web applications or mobile applications.[50]

An integrated development environment (IDE) supports software development with enhanced features compared to a simple text editor.[51] IDEs often include automated compiling, syntax highlighting of errors,[52] debugging assistance,[53] integration with version control, and semi-automation of tests.[51]

Version control is a popular way of managing changes made to the software. Whenever a new version is checked in, the software saves a backup of all modified files. If multiple programmers are working on the software simultaneously, it manages the merging of their code changes. The software highlights cases where there is a conflict between two sets of changes and allows programmers to fix the conflict.[54]

A view model is a framework that provides the viewpoints on the system and its environment, to be used in the software development process. It is a graphical representation of the underlying semantics of a view.

The purpose of viewpoints and views is to enable human engineers to comprehend very complex systems and to organize the elements of the problem around domains of expertise. In the engineering of physically intensive systems, viewpoints often correspond to capabilities and responsibilities within the engineering organization.[55]

Fitness functions are automated and objective tests to ensure that the new developments don't deviate from the established constraints, checks and compliance controls.[56]

Intellectual property can be an issue when developers integrate open-source code or libraries into a proprietary product, because most open-source licenses used for software require that modifications be released under the same license. As an alternative, developers may choose a proprietary alternative or write their own software module.[57]

Software developmentSoftware project managementComputer occupationsProduct development
Webarchive template wayback linksArticles with short descriptionShort description is different from WikidataUse dmy dates from March 2024EngvarB from December 2021Articles containing potentially dated statements from 2019All articles containing potentially dated statementsCommons category link is on WikidataArticles with BNE identifiersArticles with GND identifiersArticles with J9U identifiersArticles with LCCN identifiersArticles with NDL identifiers






# Software_development_process.md




(Top)





1
History








2
Prototyping








3
Methodologies




Toggle Methodologies subsection





3.1
Agile development








3.2
Continuous integration








3.3
Incremental development








3.4
Rapid application development








3.5
Waterfall development








3.6
Spiral development








3.7
Shape Up








3.8
Advanced methodologies










4
Process meta-models








5
In practice








6
See also








7
References








8
External links














3.1
Agile development








3.2
Continuous integration








3.3
Incremental development








3.4
Rapid application development








3.5
Waterfall development








3.6
Spiral development








3.7
Shape Up








3.8
Advanced methodologies


































This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Software development process" – news · newspapers · books · scholar · JSTOR (December 2010) (Learn how and when to remove this message)


Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
In software engineering, a software development process or software development life cycle is a process of planning and managing software development. It typically involves dividing software development work into smaller, parallel, or sequential steps or sub-processes to improve design and/or product management. The methodology may include the pre-definition of specific deliverables and artifacts that are created and completed by a project team to develop or maintain an application.[1]

Most modern development processes can be vaguely described as agile. Other methodologies include waterfall, prototyping, iterative and incremental development, spiral development, rapid application development, and extreme programming.

A life-cycle "model" is sometimes considered a more general term for a category of methodologies and a software development "process" is a particular instance as adopted by a specific organization.[citation needed] For example, many specific software development processes fit the spiral life-cycle model. The field is often considered a subset of the systems development life cycle.

The software development methodology framework did not emerge until the 1960s. According to Elliott (2004), the systems development life cycle can be considered to be the oldest formalized methodology framework for building information systems. The main idea of the software development life cycle has been "to pursue the development of information systems in a very deliberate, structured and methodical way, requiring each stage of the life cycle––from the inception of the idea to delivery of the final system––to be carried out rigidly and sequentially"[2] within the context of the framework being applied. The main target of this methodology framework in the 1960s was "to develop large scale functional business systems in an age of large scale business conglomerates. Information systems activities revolved around heavy data processing and number crunching routines."[2]

Requirements gathering and analysis:
The first phase of the custom software development process involves understanding the client's requirements and objectives. This stage typically involves engaging in thorough discussions and conducting interviews with stakeholders to identify the desired features, functionalities, and overall scope of the software. The development team works closely with the client to analyze existing systems and workflows, determine technical feasibility, and define project milestones.

Planning and design:
Once the requirements are understood, the custom software development team proceeds to create a comprehensive project plan. This plan outlines the development roadmap, including timelines, resource allocation, and deliverables. The software architecture and design are also established during this phase. User interface (UI) and user experience (UX) design elements are considered to ensure the software's usability, intuitiveness, and visual appeal.

Development:
With the planning and design in place, the development team begins the coding process. This phase involves writing, testing, and debugging the software code. Agile methodologies, such as scrum or kanban, are often employed to promote flexibility, collaboration, and iterative development. Regular communication between the development team and the client ensures transparency and enables quick feedback and adjustments.

Testing and quality assurance:
To ensure the software's reliability, performance, and security, rigorous testing and quality assurance (QA) processes are carried out. Different testing techniques, including unit testing, integration testing, system testing, and user acceptance testing, are employed to identify and rectify any issues or bugs. QA activities aim to validate the software against the predefined requirements, ensuring that it functions as intended.

Deployment and implementation:
Once the software passes the testing phase, it is ready for deployment and implementation. The development team assists the client in setting up the software environment, migrating data if necessary, and configuring the system. User training and documentation are also provided to ensure a smooth transition and enable users to maximize the software's potential.

Maintenance and support:
After the software is deployed, ongoing maintenance and support become crucial to address any issues, enhance performance, and incorporate future enhancements. Regular updates, bug fixes, and security patches are released to keep the software up-to-date and secure. This phase also involves providing technical support to end users and addressing their queries or concerns.
Methodologies, processes, and frameworks range from specific prescriptive steps that can be used directly by an organization in day-to-day work, to flexible frameworks that an organization uses to generate a custom set of steps tailored to the needs of a specific project or group. In some cases, a "sponsor" or "maintenance" organization distributes an official set of documents that describe the process. Specific examples include:

Structured programming since 1969
Cap Gemini SDM, originally from PANDATA, the first English translation was published in 1974. SDM stands for System Development Methodology
Structured systems analysis and design method (SSADM) from 1980 onwards
Information Requirement Analysis/Soft systems methodology
Object-oriented programming (OOP) developed in the early 1960s and became a dominant programming approach during the mid-1990s
Rapid application development (RAD), since 1991
Dynamic systems development method (DSDM), since 1994
Scrum, since 1995
Team software process, since 1998
Rational Unified Process (RUP), maintained by IBM since 1998
Extreme programming, since 1999
Agile Unified Process (AUP) maintained since 2005 by Scott Ambler
Disciplined agile delivery (DAD) Supersedes AUP
Scaled Agile Framework (SAFe)
Large-Scale Scrum (LeSS)
DevOps
Since DSDM in 1994, all of the methodologies on the above list except RUP have been agile methodologies - yet many organizations, especially governments, still use pre-agile processes (often waterfall or similar). Software process and software quality are closely interrelated; some unexpected facets and effects have been observed in practice.[3]

Among these, another software development process has been established in open source. The adoption of these best practices known and established processes within the confines of a company is called inner source.

Software prototyping is about creating prototypes, i.e. incomplete versions of the software program being developed.

The basic principles are:[1]

Prototyping is not a standalone, complete development methodology, but rather an approach to try out particular features in the context of a full methodology (such as incremental, spiral, or rapid application development (RAD)).
Attempts to reduce inherent project risk by breaking a project into smaller segments and providing more ease of change during the development process.
The client is involved throughout the development process, which increases the likelihood of client acceptance of the final implementation.
While some prototypes are developed with the expectation that they will be discarded, it is possible in some cases to evolve from prototype to working system.
A basic understanding of the fundamental business problem is necessary to avoid solving the wrong problems, but this is true for all software methodologies.

"Agile software development" refers to a group of software development frameworks based on iterative development, where requirements and solutions evolve via collaboration between self-organizing cross-functional teams. The term was coined in the year 2001 when the Agile Manifesto was formulated.

Agile software development uses iterative development as a basis but advocates a lighter and more people-centric viewpoint than traditional approaches. Agile processes fundamentally incorporate iteration and the continuous feedback that it provides to successively refine and deliver a software system.

The Agile model also includes the following software development processes:

Dynamic systems development method (DSDM)
Kanban
Scrum
Lean software development
Continuous integration is the practice of merging all developer working copies to a shared mainline several times a day.[4]
Grady Booch first named and proposed CI in his 1991 method,[5] although he did not advocate integrating several times a day. Extreme programming (XP) adopted the concept of CI and did advocate integrating more than once per day – perhaps as many as tens of times per day.

Various methods are acceptable for combining linear and iterative systems development methodologies, with the primary objective of each being to reduce inherent project risk by breaking a project into smaller segments and providing more ease-of-change during the development process.

There are three main variants of incremental development:[1]

A series of mini-waterfalls are performed, where all phases of the waterfall are completed for a small part of a system, before proceeding to the next increment, or
Overall requirements are defined before proceeding to evolutionary, mini-waterfall development of individual increments of a system, or
The initial software concept, requirements analysis, and design of architecture and system core are defined via waterfall, followed by incremental implementation, which culminates in installing the final version, a working system.
Rapid application development (RAD) is a software development methodology, which favors iterative development and the rapid construction of prototypes instead of large amounts of up-front planning. The "planning" of software developed using RAD is interleaved with writing the software itself. The lack of extensive pre-planning generally allows software to be written much faster and makes it easier to change requirements.

The rapid development process starts with the development of preliminary data models and business process models using structured techniques. In the next stage, requirements are verified using prototyping, eventually to refine the data and process models. These stages are repeated iteratively; further development results in "a combined business requirements and technical design statement to be used for constructing new systems".[6]

The term was first used to describe a software development process introduced by James Martin in 1991. According to Whitten (2003), it is a merger of various structured techniques, especially data-driven information technology engineering, with prototyping techniques to accelerate software systems development.[6]

The basic principles of rapid application development are:[1]

Key objective is for fast development and delivery of a high-quality system at a relatively low investment cost.
Attempts to reduce inherent project risk by breaking a project into smaller segments and providing more ease of change during the development process.
Aims to produce high-quality systems quickly, primarily via iterative Prototyping (at any stage of development), active user involvement, and computerized development tools. These tools may include Graphical User Interface (GUI) builders, Computer Aided Software Engineering (CASE) tools, Database Management Systems (DBMS), fourth-generation programming languages, code generators, and object-oriented techniques.
Key emphasis is on fulfilling the business need, while technological or engineering excellence is of lesser importance.
Project control involves prioritizing development and defining delivery deadlines or “timeboxes”. If the project starts to slip, the emphasis is on reducing requirements to fit the timebox, not on increasing the deadline.
Generally includes joint application design (JAD), where users are intensely involved in system design, via consensus building in either structured workshops, or electronically facilitated interaction.
Active user involvement is imperative.
Iteratively produces production software, as opposed to a throwaway prototype.
Produces documentation necessary to facilitate future development and maintenance.
Standard systems analysis and design methods can be fitted into this framework.
The waterfall model is a sequential development approach, in which development is seen as flowing steadily downwards (like a waterfall) through several phases, typically:

Requirements analysis resulting in a software requirements specification
Software design
Implementation
Testing
Integration, if there are multiple subsystems
Deployment (or Installation)
Maintenance
The first formal description of the method is often cited as an article published by Winston W. Royce[7] in 1970, although Royce did not use the term "waterfall" in this article. Royce presented this model as an example of a flawed, non-working model.[8]

The basic principles are:[1]

The Project is divided into sequential phases, with some overlap and splashback acceptable between phases.
Emphasis is on planning, time schedules, target dates, budgets, and implementation of an entire system at one time.
Tight control is maintained over the life of the project via extensive written documentation, formal reviews, and approval/signoff by the user and information technology management occurring at the end of most phases before beginning the next phase. Written documentation is an explicit deliverable of each phase.
The waterfall model is a traditional engineering approach applied to software engineering. A strict waterfall approach discourages revisiting and revising any prior phase once it is complete. [according to whom?] This "inflexibility" in a pure waterfall model has been a source of criticism by supporters of other more "flexible" models. It has been widely blamed for several large-scale government projects running over budget, over time and sometimes failing to deliver on requirements due to the big design up front approach.[according to whom?] Except when contractually required, the waterfall model has been largely superseded by more flexible and versatile methodologies developed specifically for software development.[according to whom?] See Criticism of waterfall model.

In 1988, Barry Boehm published a formal software system development "spiral model," which combines some key aspects of the waterfall model and rapid prototyping methodologies, in an effort to combine advantages of top-down and bottom-up concepts. It provided emphasis on a key area many felt had been neglected by other methodologies: deliberate iterative risk analysis, particularly suited to large-scale complex systems.

The basic principles are:[1]

Focus is on risk assessment and on minimizing project risk by breaking a project into smaller segments and providing more ease-of-change during the development process, as well as providing the opportunity to evaluate risks and weigh consideration of project continuation throughout the life cycle.
"Each cycle involves a progression through the same sequence of steps, for each part of the product and for each of its levels of elaboration, from an overall concept-of-operation document down to the coding of each individual program."[9]
Each trip around the spiral traverses four basic quadrants: (1) determine objectives, alternatives, and constraints of the iteration, and (2) evaluate alternatives; Identify and resolve risks; (3) develop and verify deliverables from the iteration; and (4) plan the next iteration.[10]
Begin each cycle with an identification of stakeholders and their "win conditions", and end each cycle with review and commitment.[11]
Shape Up is a software development approach introduced by Basecamp in 2018. It is a set of principles and techniques that Basecamp developed internally to overcome the problem of projects dragging on with no clear end. Its primary target audience is remote teams. Shape Up has no estimation and velocity tracking, backlogs, or sprints, unlike waterfall, agile, or scrum. Instead, those concepts are replaced with appetite, betting, and cycles. As of 2022, besides Basecamp, notable organizations that have adopted Shape Up include UserVoice and Block.[12][13]

Other high-level software project methodologies include:

Behavior-driven development and business process management.[14]
Chaos model - The main rule always resolves the most important issue first.
Incremental funding methodology - an iterative approach
Lightweight methodology - a general term for methods that only have a few rules and practices
Structured systems analysis and design method - a specific version of waterfall
Slow programming, as part of the larger Slow Movement, emphasizes careful and gradual work without (or minimal) time pressures. Slow programming aims to avoid bugs and overly quick release schedules.
V-Model (software development) - an extension of the waterfall model
Unified Process (UP) is an iterative software development methodology framework, based on Unified Modeling Language (UML). UP organizes the development of software into four phases, each consisting of one or more executable iterations of the software at that stage of development: inception, elaboration, construction, and guidelines.
Some "process models" are abstract descriptions for evaluating, comparing, and improving the specific process adopted by an organization.

ISO/IEC 12207 is the international standard describing the method to select, implement, and monitor the life cycle for software.
The Capability Maturity Model Integration (CMMI) is one of the leading models and is based on best practices. Independent assessments grade organizations on how well they follow their defined processes, not on the quality of those processes or the software produced. CMMI has replaced CMM.
ISO 9000 describes standards for a formally organized process to manufacture a product and the methods of managing and monitoring progress. Although the standard was originally created for the manufacturing sector, ISO 9000 standards have been applied to software development as well. Like CMMI, certification with ISO 9000 does not guarantee the quality of the end result, only that formalized business processes have been followed.
ISO/IEC 15504 Information technology—Process assessment is also known as Software Process Improvement Capability Determination (SPICE), is a "framework for the assessment of software processes". This standard is aimed at setting out a clear model for process comparison. SPICE is used much like CMMI. It models processes to manage, control, guide, and monitor software development. This model is then used to measure what a development organization or project team actually does during software development. This information is analyzed to identify weaknesses and drive improvement. It also identifies strengths that can be continued or integrated into common practice for that organization or team.
ISO/IEC 24744 Software Engineering—Metamodel for Development Methodologies, is a power type-based metamodel for software development methodologies.
Soft systems methodology - a general method for improving management processes.
Method engineering - a general method for improving information system processes.
A variety of such frameworks have evolved over the years, each with its own recognized strengths and weaknesses. One software development methodology framework is not necessarily suitable for use by all projects. Each of the available methodology frameworks is best suited to specific kinds of projects, based on various technical, organizational, project, and team considerations.[1]

Systems development life cycle
Computer-aided software engineering (some of these tools support specific methodologies)
List of software development philosophies
Outline of software engineering
Software Project Management
Software development
Software development effort estimation
Software release life cycle
Top-down and bottom-up design#Computer science
Software development processMethodologySoftware engineering
CS1 German-language sources (de)Articles with short descriptionShort description matches WikidataUse mdy dates from December 2023Articles needing additional references from December 2010All articles needing additional referencesUse American English from April 2022All Wikipedia articles written in American EnglishAll articles with unsourced statementsArticles with unsourced statements from September 2020All articles with specifically marked weasel-worded phrasesArticles with specifically marked weasel-worded phrases from January 2021Commons category link is on Wikidata






# Specification_by_example.md




(Top)





1
Advantages








2
Examples as a single source of truth








3
Key practices




Toggle Key practices subsection





3.1
Example Mapping










4
Applicability








5
History








6
Automation








7
References








8
External links














3.1
Example Mapping


















Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Specification by example (SBE) is a collaborative approach to defining requirements and business-oriented functional tests for software products based on capturing and illustrating requirements using realistic examples instead of abstract statements. It is applied in the context of agile software development methods, in particular behavior-driven development. This approach is particularly successful for managing requirements and functional tests on large-scale projects of significant domain and organisational complexity.[1]

Specification by example is also known as example-driven development, executable requirements, acceptance test–driven development (ATDD[2] or A-TDD[3]), Agile Acceptance Testing,[4] Test-Driven Requirements (TDR).

Highly abstract or novel new concepts can be difficult to understand without concrete examples.[citation needed] Specification by example is intended to construct an accurate understanding, and significantly reduces feedback loops in software development, leading to less rework, higher product quality, faster turnaround time for software changes and better alignment of activities of various roles involved in software development such as testers, analysts and developers.[1]

A key aspect of specification by example is creating a single source of truth about required changes from all perspectives. When business analysts work on their own documents, software developers maintain their own documentation and testers maintain a separate set of functional tests, software delivery effectiveness is significantly reduced by the need to constantly coordinate and synchronise those different versions of truth. With short iterative cycles, such coordination is often required on weekly or biweekly basis. With Specification by example, different roles participate in creating a single source of truth that captures everyone's understanding. Examples are used to provide clarity and precision, so that the same information can be used both as a specification and a business-oriented functional test. Any additional information discovered during development or delivery, such as clarification of functional gaps, missing or incomplete requirements or additional tests, is added to this single source of truth. As there is only one source of truth about the functionality, there is no need for coordination, translation and interpretation of knowledge inside the delivery cycle.

When applied to required changes, a refined set of examples is effectively a specification and a business-oriented test for acceptance of software functionality. After the change is implemented, specification with examples becomes a document explaining existing functionality. As the validation of such documents is automated, when they are validated frequently, such documents are a reliable source of information on business functionality of underlying software. To distinguish between such documents and typical printed documentation, which quickly gets outdated,[4] a complete set of specifications with examples is called Living Documentation.[1]

Teams that apply Specification by example successfully commonly apply the following process patterns:[1]

Deriving scope from goals
Specifying collaboratively - through all-team specification workshops, smaller meetings or teleconference reviews
Illustrating requirements using examples
Refining specifications
Automating tests based on examples
Validating the underlying software frequently using the tests
Evolving a documentation system from specifications with examples to support future development
Software teams that apply specification by example within a Scrum framework typically spend 5%-10% of their time in refining the product backlog, including specifying collaboratively, illustrating requirements using examples and refining examples.[3]

Example Mapping is a simple technique that can steer the conversation and derive Acceptance criteria in a short time. The process breaks stories into Rules and Examples documented in the form of specification by example, and is a widely used technique in the BDD sphere.[5]

Specification by example applies to projects with sufficient organisational and domain complexity to cause problems in understanding or communicating requirements from a business domain perspective. It does not apply to purely technical problems or where the key complexity is not in understanding or communicating knowledge. There are documented usages of this approach in domains including investment banking, financial trading, insurance, airline ticket reservation, online gaming and price comparison.[1] A similar approach is documented also in a nuclear-power plant simulation project.[3]

Tests based on shared examples fit best in the category of tests designed to support a team while delivering software from a business perspective (see Agile Testing Quadrants[6]) - ensuring that the right product is built. They do not replace tests that look at a software system from a purely technical perspective (those that evaluate whether a product is built the right way, such as unit tests, component or technical integration tests) or tests that evaluate a product after it was developed (such as security penetration tests).

The earliest documented usage of realistic examples as a single source of truth, requirements and automated tests, on software projects is the WyCash+ project, described by Ward Cunningham in the paper A Pattern Language of Competitive Development [7][8] in 1996. The name Specification by Example was coined by Martin Fowler in 2004.[9]

Specification by Example is an evolution of the Customer Test[10] practice of Extreme Programming proposed around 1997 and Ubiquitous Language[11] idea from Domain-driven design from 2004, using the idea of black-box tests as requirements described by Weinberg and Gause[12] in 1989.

Successful application of Specification by example on large scale projects requires frequent validation of software functionality against a large set of examples (tests). In practice, this requires tests based on examples to be automated. A common approach is to automate the tests but keep examples in a form readable and accessible to non-technical and technical team members, keeping the examples as a single source of truth. This process is supported by a class of test automation tools which work with tests divided into two aspects - the specification and the automation layer. The specification of a test which is often in a plain text or HTML form and contains the examples and auxiliary descriptions. The automation layer connects the example to a software system under test. Examples of such tools are:

Behat
Concordion
Cucumber
FitNesse
Framework for Integrated Test
Robot Framework
SpecFlow for .NET
Gauge (software)
Software development philosophiesSoftware testingBusiness analysis
CS1 maint: numeric names: authors listAll articles with unsourced statementsArticles with unsourced statements from May 2021






# Stand-up_meeting.md




(Top)





1
Notable examples








2
Software development




Toggle Software development subsection





2.1
Definition








2.2
Description






2.2.1
Timeboxed












3
Three questions








4
See also








5
Citations








6
References








7
External links












2.1
Definition








2.2
Description






2.2.1
Timeboxed














2.2.1
Timeboxed


















A stand-up meeting (stum) is a meeting in which attendees typically participate while standing. The discomfort of standing for long periods is intended to keep the meetings short.

By tradition, the Privy Council of the United Kingdom meets standing.[1]

According to the PMBOK (7th edition) by the Project Management Institute (PMI), daily standup is a "brief, daily collaboration meeting in which the team review progress from the previous day, declares intentions for the current day, and highlights any obstacles encountered or anticipated."[2]

Some software development methodologies envision daily team meetings to make commitments to team members. The daily commitments allow participants to know about potential challenges as well as to coordinate efforts to resolve difficult or time-consuming issues. The stand-up has particular value in agile software development processes,[3][4] such as scrum or Kanban, but can be utilized in context of any software-development methodology.

The meeting should usually take place at the same time and place every working day. All team members are encouraged to attend, but the meetings are not postponed if some of the team members are not present. One of the crucial features is that the meeting is a communication opportunity among team members and not a status update to management or stakeholders.[5] Although it is sometimes referred to as a type of status meeting, the structure of the meeting is meant to promote follow-up conversation, as well as to identify issues before they become too problematic. The practice also promotes closer working relationships in its frequency, need for follow-up conversations and short structure, which in turn result in a higher rate of knowledge transfer – a much more active intention than the typical status meeting. Team members take turns speaking, sometimes passing along a token to indicate the current person allowed to speak.[6] Each member talks about progress since the last stand-up, the anticipated work until the next stand-up and any impediments, taking the opportunity to ask for help or collaborate.[7]

Team members may sometimes ask for short clarifications and make brief statements, such as "Let's talk about this more after the meeting", but the stand-up does not usually consist of full-fledged discussions.[citation needed]

The meetings are usually timeboxed to between 5 and 15 minutes, and take place with participants standing up to remind people to keep the meeting short and to-the-point.[6] The stand-up meeting is sometimes also referred to as the "stand-up" when doing Extreme Programming, "morning rollcall" or "daily scrum" when following the scrum framework.

Scrum has daily meetings (the daily scrum) for the team to reflect and assess progress towards the sprint goal.[8] This meeting is intended to be brief – less than 15 minutes – so any in-depth discussions about impediments are deferred until after the event is complete. As some teams conduct their meetings standing up, they may refer to this event as the "daily standup"

The older Scrum Guide (2017) suggested team members briefly (a maximum of one minute per team member) address three questions as input to this planning:

What did I do yesterday that helped the development team meet the sprint goal?
What will I do today to help the development team meet the sprint goal?
Do I see any impediment that prevents me or the development team from meeting the sprint goal?
(These questions were removed from the 2020 Scrum Guide)

Whereas Kanban-style daily stand-ups focus more on:

What obstacles are impeding my progress?
(looking at the board from right to left) What has progressed?
Lean software development
Five Ws

^ "Privy Council Office FAQs". Privy Council Office. Retrieved 17 May 2016.

^ Project Management Institute 2021, Glossary §3 Definitions.

^ "Agile Testing". Borland.com. Archived from the original on 2012-07-06. Retrieved 2010-01-27.

^ "Agile Stand-up on Agile Testing". Borland.com. Archived from the original on January 12, 2010. Retrieved 2010-01-27.

^ Stray, Viktoria; Sjøberg, Dag; Dybå, Tore (2016-01-11). "The daily stand-up meeting: A grounded theory study". Journal of Systems and Software. 114 (20): 101–124. doi:10.1016/j.jss.2016.01.004. hdl:11250/2478996. S2CID 206539494.

^ a b "It's Not Just Standing Up". Martin Fowler.

^ "Daily Scrum Meetings". Mountain Goat Software.

^ "Scrum Guide". scrum.org.


Agile software developmentMeetings
Articles with short descriptionShort description is different from WikidataAll articles with unsourced statementsArticles with unsourced statements from December 2011CS1 maint: location missing publisher






# Story-driven_modeling.md




(Top)





1
Software development approach








2
Summary








3
See also








4
References














This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these template messages)

This article includes a list of general references, but it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations. (February 2014) (Learn how and when to remove this message)This article is written like a personal reflection, personal essay, or argumentative essay that states a Wikipedia editor's personal feelings or presents an original argument about a topic. Please help improve it by rewriting it in an encyclopedic style. (February 2014) (Learn how and when to remove this message)

 (Learn how and when to remove this message)
This article includes a list of general references, but it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations. (February 2014) (Learn how and when to remove this message)
This article is written like a personal reflection, personal essay, or argumentative essay that states a Wikipedia editor's personal feelings or presents an original argument about a topic. Please help improve it by rewriting it in an encyclopedic style. (February 2014) (Learn how and when to remove this message)
Story-driven modeling[1][2][3] is an object-oriented modeling technique.[4][5] Other forms of object-oriented modeling focus on class diagrams. 
Class diagrams describe the static structure of a program, i.e. the building blocks of a program and how they relate to each other. 
Class diagrams also model data structures, but with an emphasis on rather abstract concepts like types and type features.

Instead of abstract static structures, story-driven modeling focuses on concrete example scenarios[6] and on how the steps of the example scenarios 
may be represented as object diagrams and how these object diagrams evolve during scenario execution.

Story-driven modeling proposes the following software development approach:

Textual scenarios: For the feature you want to implement, develop a textual scenario description for the most common case. Look on only one example at a time. Try to use specific terms and individual names instead of general terms and e.g. role names:
Scenario Go-Dutch barbecue
Start: This Sunday Peter, Putri, and Peng meet at the park for a go-Dutch barbecue. They use the Group Account app to do the accounting.
Step 1: Peter brings the meat for $12. Peter adds this item to the Group Account app.
Step 2: Putri brings salad for $9. Peter adds this item, too. The app shows that by now the average share is $7 and that Peng still have to bring these $7 while Peter gets $5 out and Putri gets $2 out.
Step 3: ...
GUI mock-ups: To illustrate the graphical user interface (GUI) for the desired feature, you may add some wireframe models or GUI mock-ups to your scenario:
Scenario Go-Dutch barbecue
Start: This Sunday Peter, Putri, and Peng meet at the park for a go-Dutch barbecue. They use the Group Account app to do the accounting.
Step 1: Peter brings the meat for $12. Peter adds this item to the Group Account app.
Step 2: Putri brings salad for $9. Peter adds this item, too. The app shows that by now the average share is $7 and that Peng still have to bring these $7 while Peter gets $5 out and Putri gets $2 out: 
Step 3: ...
Storyboarding: Next, you think about how a certain situation, i.e. a certain step of a scenario may be represented within a computer by a runtime object structure. This is done by adding object diagrams to the scenario. In story driven modeling, a scenario with object diagrams is also called a storyboard.
Scenario Go-Dutch barbecue
Start: This Sunday Peter, Putri, and Peng meet at the park for a go-Dutch barbecue. They use the Group Account app to do the accounting.
Step 1: Peter brings the meat for $12. Peter adds this item to the Group Account app.
Step 2: Putri brings salad for $9. Peter adds this item, too. The app shows that by now the average share is $7 and that Peng still have to bring these $7 while Peter gets $5 out and Putri gets $2 out: 
Step 3: ...
Class diagram derivation: Now it is fairly straightforward to derive a class diagram from the object diagrams used in the storyboards.Note, the class diagram serves as a common reference for all object diagrams. This ensures that overall the same types and attributes are used. Using a UML tool, you may generate a first implementation from this class diagram.
Algorithm design: So far you have modeled and implemented that object structures that are deployed in your application. Now you need to add behavior, i.e. algorithms and method bodies. Programming the behavior of an application is a demanding task. To facilitate it, you should first outline the behavior in pseudocode notation. You might do this, e.g. with an object game. For example, to update the saldo attributes of all persons you look at our object structure and from the point of view of the GroupAccount object you do the following:
Update the saldo of all persons:
visit each item
for each item add the value to the total value and add 1 to the number of items
compute the average share of each person by dividing the total value by the number of persons
visit each person
for each person reset the saldo
for each person visit each item bought by this person
for each item add the value to the saldo of the current person
for each person subtract the share from the saldo
Behavior implementation: Once you have refined your algorithm pseudocode down to the level of operations on object structures it is straightforward to derive source code that executes the same operations on your object model implementation.
Testing: Finally, the scenarios may be used to derive automatic JUnit tests. The pseudocode for a test for our example might look like:
Test update the saldo of all persons:
create a group account object
add a person object with name Peter and a person object with name Putri and a person object with name Peng to the group account object
add an item object with buyer Peter, description Meat, and value $12 to the group account object
add an item object with buyer Putri, description Salad, and value $9 to the group account object
call method update the saldo of all persons on the group account object
ensure that the saldo of the Peter object is $5
ensure that the saldo of the Putri object is $2
ensure that the saldo of the Peter object is -$7
ensure that the sum of all saldos is $0
Start: This Sunday Peter, Putri, and Peng meet at the park for a go-Dutch barbecue. They use the Group Account app to do the accounting.
Step 1: Peter brings the meat for $12. Peter adds this item to the Group Account app.
Step 2: Putri brings salad for $9. Peter adds this item, too. The app shows that by now the average share is $7 and that Peng still have to bring these $7 while Peter gets $5 out and Putri gets $2 out.
Step 3: ...
Start: This Sunday Peter, Putri, and Peng meet at the park for a go-Dutch barbecue. They use the Group Account app to do the accounting.
Step 1: Peter brings the meat for $12. Peter adds this item to the Group Account app.
Step 2: Putri brings salad for $9. Peter adds this item, too. The app shows that by now the average share is $7 and that Peng still have to bring these $7 while Peter gets $5 out and Putri gets $2 out: 
Step 3: ...
Start: This Sunday Peter, Putri, and Peng meet at the park for a go-Dutch barbecue. They use the Group Account app to do the accounting.
Step 1: Peter brings the meat for $12. Peter adds this item to the Group Account app.
Step 2: Putri brings salad for $9. Peter adds this item, too. The app shows that by now the average share is $7 and that Peng still have to bring these $7 while Peter gets $5 out and Putri gets $2 out: 
Step 3: ...
visit each item
for each item add the value to the total value and add 1 to the number of items
compute the average share of each person by dividing the total value by the number of persons
visit each person
for each person reset the saldo
for each person visit each item bought by this person
for each item add the value to the saldo of the current person
for each person subtract the share from the saldo
for each item add the value to the total value and add 1 to the number of items
for each person reset the saldo
for each person visit each item bought by this person
for each item add the value to the saldo of the current person
for each person subtract the share from the saldo
for each item add the value to the saldo of the current person
create a group account object
add a person object with name Peter and a person object with name Putri and a person object with name Peng to the group account object
add an item object with buyer Peter, description Meat, and value $12 to the group account object
add an item object with buyer Putri, description Salad, and value $9 to the group account object
call method update the saldo of all persons on the group account object
ensure that the saldo of the Peter object is $5
ensure that the saldo of the Putri object is $2
ensure that the saldo of the Peter object is -$7
ensure that the sum of all saldos is $0
Story driven modeling has proven to work very well for the cooperation with non IT experts.[7] People from other domains usually have difficulties to describe their needs in general terms (i.e. classes) and general rules (pseudocode). Similarly, normal people have problems to understand pseudocode or to judge, whether their needs are properly addressed or not. However, these people know their business very well and with the help of concrete examples and scenarios it is very easy for normal people to spot problematic cases and to judge whether their needs have been addressed properly.

Story Driven Modeling has matured since its beginning in 1997. In 2013 it is used for teaching e.g. in Kassel University, Paderborn University, Tartu University, Antwerp University, Nazarbayev University Astana, Hasso Platner Institute Potsdam, University of Victoria, ...

Agile modeling
Entity-control-boundary
Agile software development
Class-responsibility-collaboration card
Object-oriented analysis and design
Object-oriented modeling
Test-driven development
Unified Modeling Language
Object-oriented programmingSoftware design
CS1: long volume valueArticles lacking in-text citations from February 2014All articles lacking in-text citationsWikipedia articles with style issues from February 2014All articles with style issuesArticles with multiple maintenance issues






# Systems_development_life_cycle.md




(Top)





1
Overview








2
History








3
Models




Toggle Models subsection





3.1
Waterfall






3.1.1
Preliminary analysis








3.1.2
Systems analysis, requirements definition








3.1.3
Systems design








3.1.4
Development








3.1.5
Integration and testing








3.1.6
Acceptance, installation, deployment








3.1.7
Maintenance








3.1.8
Evaluation








3.1.9
Disposal










3.2
Systems analysis and design








3.3
Object-oriented analysis and design








3.4
System lifecycle






3.4.1
Conceptual design








3.4.2
Preliminary system design








3.4.3
Detail design and development








3.4.4
Production and construction








3.4.5
Utilization and support








3.4.6
Phase-out and disposal












4
Phases




Toggle Phases subsection





4.1
System investigation








4.2
Analysis








4.3
Design








4.4
Testing








4.5
Training and transition








4.6
Operations and maintenance








4.7
Evaluation










5
Life cycle




Toggle Life cycle subsection





5.1
Management and control








5.2
Work breakdown structured organization








5.3
Baselines










6
Alternative methodologies








7
Strengths and weaknesses








8
See also








9
References








10
Further reading








11
External links














3.1
Waterfall






3.1.1
Preliminary analysis








3.1.2
Systems analysis, requirements definition








3.1.3
Systems design








3.1.4
Development








3.1.5
Integration and testing








3.1.6
Acceptance, installation, deployment








3.1.7
Maintenance








3.1.8
Evaluation








3.1.9
Disposal










3.2
Systems analysis and design








3.3
Object-oriented analysis and design








3.4
System lifecycle






3.4.1
Conceptual design








3.4.2
Preliminary system design








3.4.3
Detail design and development








3.4.4
Production and construction








3.4.5
Utilization and support








3.4.6
Phase-out and disposal












3.1.1
Preliminary analysis








3.1.2
Systems analysis, requirements definition








3.1.3
Systems design








3.1.4
Development








3.1.5
Integration and testing








3.1.6
Acceptance, installation, deployment








3.1.7
Maintenance








3.1.8
Evaluation








3.1.9
Disposal
































3.4.1
Conceptual design








3.4.2
Preliminary system design








3.4.3
Detail design and development








3.4.4
Production and construction








3.4.5
Utilization and support








3.4.6
Phase-out and disposal






















4.1
System investigation








4.2
Analysis








4.3
Design








4.4
Testing








4.5
Training and transition








4.6
Operations and maintenance








4.7
Evaluation
























5.1
Management and control








5.2
Work breakdown structured organization








5.3
Baselines


























In systems engineering, information systems and software engineering, the systems development life cycle (SDLC), also referred to as the application development life cycle, is a process for planning, creating, testing, and deploying an information system.[1] The SDLC concept applies to a range of hardware and software configurations, as a system can be composed of hardware only, software only, or a combination of both.[2] There are usually six stages in this cycle: requirement analysis, design, development and testing, implementation, documentation, and evaluation.

A systems development life cycle is composed of distinct work phases that are used by systems engineers and systems developers to deliver information systems. Like anything that is manufactured on an assembly line, an SDLC aims to produce high-quality systems that meet or exceed expectations, based on requirements, by delivering systems within scheduled time frames and cost estimates.[3] Computer systems are complex and often link components with varying origins. Various SDLC methodologies have been created, such as waterfall, spiral, agile, rapid prototyping, incremental, and synchronize and stabilize.[4]

SDLC methodologies fit within a flexibility spectrum ranging from agile to iterative to sequential. Agile methodologies, such as XP and Scrum, focus on lightweight processes that allow for rapid changes.[5] Iterative methodologies, such as Rational Unified Process and dynamic systems development method, focus on stabilizing project scope and iteratively expanding or improving products. Sequential or big-design-up-front (BDUF) models, such as waterfall, focus on complete and correct planning to guide larger projects and limit risks to successful and predictable results.[6] Anamorphic development is guided by project scope and adaptive iterations.

In project management a project can include both a project life cycle (PLC) and an SDLC, during which somewhat different activities occur. According to Taylor (2004), "the project life cycle encompasses all the activities of the project, while the systems development life cycle focuses on realizing the product requirements".[7]

SDLC is not a methodology per se, but rather a description of the phases that a methodology should address. The list of phases is not definitive, but typically includes planning, analysis, design, build, test, implement, and maintenance/support. In the Scrum framework,[8] for example, one could say a single user story goes through all the phases of the SDLC within a two-week sprint. By contrast the waterfall methodology, where every business requirement[citation needed] is translated into feature/functional descriptions which are then all implemented typically over a period of months or longer.[citation needed]

According to Elliott (2004), SDLC "originated in the 1960s, to develop large scale functional business systems in an age of large scale business conglomerates. Information systems activities revolved around heavy data processing and number crunching routines".[9]

The structured systems analysis and design method (SSADM) was produced for the UK government Office of Government Commerce in the 1980s. Ever since, according to Elliott (2004), "the traditional life cycle approaches to systems development have been increasingly replaced with alternative approaches and frameworks, which attempted to overcome some of the inherent deficiencies of the traditional SDLC".[9]

This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (January 2024) (Learn how and when to remove this message)
SDLC provides a set of phases/steps/activities for system designers and developers to follow. Each phase builds on the results of the previous one.[10][11][12][13] Not every project requires that the phases be sequential. For smaller, simpler projects, phases may be combined/overlap.[10]

The oldest and best known is the waterfall model, which uses a linear sequence of steps.[11] Waterfall has different varieties. One variety is as follows:[10][11][14][15]

Conduct with a preliminary analysis, consider alternative solutions, estimate costs and benefits, and submit a preliminary plan with recommendations.

Conduct preliminary analysis: Identify the organization's objectives and define the nature and scope of the project. Ensure that the project fits with the objectives.
Consider alternative solutions: Alternatives may come from interviewing employees, clients, suppliers, and consultants, as well as competitive analysis.
Cost-benefit analysis: Analyze the costs and benefits of the project.
Decompose project goals[clarification needed] into defined functions and operations. This involves gathering and interpreting facts, diagnosing problems, and recommending changes. Analyze end-user information needs and resolve inconsistencies and incompleteness:[16]

Collect facts: Obtain end-user requirements by document review, client interviews, observation, and questionnaires.
Scrutinize existing system(s): Identify pros and cons.
Analyze the proposed system: Find solutions to issues and prepare specifications, incorporating appropriate user proposals.
At this step, desired features and operations are detailed, including screen layouts, business rules, process diagrams, pseudocode, and other deliverables.

Write the code.

Assemble the modules in a testing environment. Check for errors, bugs, and interoperability.

Put the system into production. This may involve training users, deploying hardware, and loading information from the prior system.

Monitor the system to assess its ongoing fitness. Make modest changes and fixes as needed. To maintain the quality of the system. Continual monitoring and updates ensure the system remains effective and high-quality.[17]

The system and the process are reviewed. Relevant questions include whether the newly implemented system meets requirements and achieves project goals, whether the system is usable, reliable/available, properly scaled and fault-tolerant. Process checks include review of timelines and expenses, as well as user acceptance.

At end of life, plans are developed for discontinuing the system and transitioning to its replacement. Related information and infrastructure must be repurposed, archived, discarded, or destroyed, while appropriately protecting security.[18]

In the following diagram, these stages are divided into ten steps, from definition to creation and modification of IT work products:

Systems analysis and design (SAD) can be considered a meta-development activity, which serves to set the stage and bound the problem. SAD can help balance competing high-level requirements. SAD interacts with distributed enterprise architecture, enterprise I.T. Architecture, and business architecture, and relies heavily on concepts such as partitioning, interfaces, personae and roles, and deployment/operational modeling to arrive at a high-level system description. This high-level description is then broken down into the components and modules which can be analyzed, designed, and constructed separately and integrated to accomplish the business goal. SDLC and SAD are cornerstones of full life cycle product and system planning.

Object-oriented analysis and design (OOAD) is the process of analyzing a problem domain to develop a conceptual model that can then be used to guide development. During the analysis phase, a programmer develops written requirements and a formal vision document via interviews with stakeholders.

The conceptual model that results from OOAD typically consists of use cases, and class and interaction diagrams. It may also include a user interface mock-up.

An output artifact does not need to be completely defined to serve as input of object-oriented design; analysis and design may occur in parallel. In practice the results of one activity can feed the other in an iterative process.

Some typical input artifacts for OOAD:

Conceptual model: A conceptual model is the result of object-oriented analysis. It captures concepts in the problem domain. The conceptual model is explicitly independent of implementation details.
Use cases: A use case is a description of sequences of events that, taken together, complete a required task. Each use case provides scenarios that convey how the system should interact with actors (users). Actors may be end users or other systems. Use cases may further elaborated using diagrams. Such diagrams identify the actor and the processes they perform.
System Sequence Diagram: A System Sequence diagrams (SSD) is a picture that shows, for a particular use case, the events that actors generate, their order, including inter-system events.
User interface document: Document that shows and describes the user interface.
Data model: A data model describes how data elements relate to each other. The data model is created before the design phase. Object-oriented designs map directly from the data model. Relational designs are more involved.
The system lifecycle is a view of a system or proposed system that addresses all phases of its existence to include system conception, design and development, production and/or construction, distribution, operation, maintenance and support, retirement, phase-out, and disposal.[19]

The conceptual design stage is the stage where an identified need is examined, requirements for potential solutions are defined, potential solutions are evaluated, and a system specification is developed. The system specification represents the technical requirements that will provide overall guidance for system design. Because this document determines all future development, the stage cannot be completed until a conceptual design review has determined that the system specification properly addresses the motivating need.

Key steps within the conceptual design stage include:

Need identification
Feasibility analysis
System requirements analysis
System specification
Conceptual design review
During this stage of the system lifecycle, subsystems that perform the desired system functions are designed and specified in compliance with the system specification. Interfaces between subsystems are defined, as well as overall test and evaluation requirements.[20] At the completion of this stage, a development specification is produced that is sufficient to perform detailed design and development.

Key steps within the preliminary design stage include:

Functional analysis
Requirements allocation
Detailed trade-off studies
Synthesis of system options
Preliminary design of engineering models
Development specification
Preliminary design review
For example, as the system analyst of Viti Bank, you have been tasked to examine the current information system. Viti Bank is a fast-growing bank in Fiji. Customers in remote rural areas are finding difficulty to access the bank services. It takes them days or even weeks to travel to a location to access the bank services. With the vision of meeting the customers' needs, the bank has requested your services to examine the current system and to come up with solutions or recommendations of how the current system can be provided to meet its needs.

This stage includes the development of detailed designs that brings initial design work into a completed form of specifications. This work includes the specification of interfaces between the system and its intended environment, and a comprehensive evaluation of the systems logistical, maintenance and support requirements. The detail design and development is responsible for producing the product, process and material specifications and may result in substantial changes to the development specification.

Key steps within the detail design and development stage include:

Detailed design
Detailed synthesis
Development of engineering and prototype models
Revision of development specification
Product, process, and material specification
Critical design review
During the production and/or construction stage the product is built or assembled in accordance with the requirements specified in the product, process and material specifications, and is deployed and tested within the operational target environment. System assessments are conducted in order to correct deficiencies and adapt the system for continued improvement.

Key steps within the product construction stage include:

Production and/or construction of system components
Acceptance testing
System distribution and operation
Operational testing and evaluation
System assessment
Once fully deployed, the system is used for its intended operational role and maintained within its operational environment.

Key steps within the utilization and support stage include:

System operation in the user environment
Change management
System modifications for improvement
System assessment
Effectiveness and efficiency of the system must be continuously evaluated to determine when the product has met its maximum effective lifecycle.[21] Considerations include: Continued existence of operational need, matching between operational requirements and system performance, feasibility of system phase-out versus maintenance, and availability of alternative systems.

This section includes a list of references, related reading, or external links, but its sources remain unclear because it lacks inline citations. Please help improve this section by introducing more precise citations. (January 2023) (Learn how and when to remove this message)
During this step, current priorities that would be affected and how they should be handled are considered. A feasibility study determines whether creating a new or improved system is appropriate. This helps to estimate costs, benefits, resource requirements, and specific user needs.

The feasibility study should address operational, financial, technical, human factors, and legal/political concerns.

The goal of analysis is to determine where the problem is. This step involves decomposing the system into pieces, analyzing project goals, breaking down what needs to be created, and engaging users to define requirements.

In systems design, functions and operations are described in detail, including screen layouts, business rules, process diagrams, and other documentation. Modular design reduces complexity and allows the outputs to describe the system as a collection of subsystems.

The design stage takes as its input the requirements already defined. For each requirement, a set of design elements is produced.

Design documents typically include functional hierarchy diagrams, screen layouts, business rules, process diagrams, pseudo-code, and a complete data model with a data dictionary. These elements describe the system in sufficient detail that developers and engineers can develop and deliver the system with minimal additional input.

The code is tested at various levels in software testing. Unit, system, and user acceptance tests are typically performed. Many approaches to testing have been adopted.

The following types of testing may be relevant:

Path testing
Data set testing
Unit testing
System testing
Integration testing
Black-box testing
White-box testing
Regression testing
Automation testing
User acceptance testing
Software performance testing
Once a system has been stabilized through testing, SDLC ensures that proper training is prepared and performed before transitioning the system to support staff and end users. Training usually covers operational training for support staff as well as end-user training.

After training, systems engineers and developers transition the system to its production environment.

Maintenance includes changes, fixes, and enhancements.

The final phase of the SDLC is to measure the effectiveness of the system and evaluate potential enhancements.

SDLC phase objectives are described in this section with key deliverables, a description of recommended tasks, and a summary of related control objectives for effective management. It is critical for the project manager to establish and monitor control objectives while executing projects. Control objectives are clear statements of the desired result or purpose and should be defined and monitored throughout a project. Control objectives can be grouped into major categories (domains), and relate to the SDLC phases as shown in the figure.[22]

To manage and control a substantial SDLC initiative, a work breakdown structure (WBS) captures and schedules the work. The WBS and all programmatic material should be kept in the "project description" section of the project notebook.[clarification needed] The project manager chooses a WBS format that best describes the project.

The diagram shows that coverage spans numerous phases of the SDLC but the associated MCD[clarification needed] shows mappings to SDLC phases. For example, Analysis and Design is primarily performed as part of the Acquisition and Implementation Domain, and System Build and Prototype is primarily performed as part of delivery and support.[22]

The upper section of the WBS provides an overview of the project scope and timeline. It should also summarize the major phases and milestones. The middle section is based on the SDLC phases. WBS elements consist of milestones and tasks to be completed rather than activities to be undertaken and have a deadline. Each task has a measurable output (e.g., analysis document). A WBS task may rely on one or more activities (e.g. coding). Parts of the project needing support from contractors should have a statement of work (SOW). The development of a SOW does not occur during a specific phase of SDLC but is developed to include the work from the SDLC process that may be conducted by contractors.[22]

Baselines[clarification needed] are established after four of the five phases of the SDLC, and are critical to the iterative nature of the model.[23] Baselines become milestones.

functional baseline: established after the conceptual design phase.
allocated baseline: established after the preliminary design phase.
product baseline: established after the detail design and development phase.
updated product baseline: established after the production construction phase.
Alternative software development methods to systems development life cycle are:

Software prototyping
Joint applications development (JAD)
Rapid application development (RAD)
Extreme programming (XP);
Open-source development
End-user development
Object-oriented programming



SDLC

RAD

Open source

Objects

JAD

Prototyping

End User


Control

Formal

MIS

Weak

Standards

Joint

User

User


Time frame

Long

Short

Medium

Any

Medium

Short

Short
–



Users

Many

Few

Few

Varies

Few

One or two

One


MIS staff

Many

Few

Hundreds

Split

Few

One or two

None


Transaction/DSS

Transaction

Both

Both

Both

DSS

DSS

DSS


Interface

Minimal

Minimal

Weak

Windows

Crucial

Crucial

Crucial


Documentation and training

Vital

Limited

Internal

In Objects

Limited

Weak

None


Integrity and security

Vital

Vital

Unknown

In Objects

Limited

Weak

Weak


Reusability

Limited

Some

Maybe

Vital

Limited

Weak

None

–

Fundamentally, SDLC trades flexibility for control by imposing structure. It is more commonly used for large scale projects with many developers.


Strengths

Weaknesses


Control

Increased development time


Monitor large projects

Increased development cost


Detailed steps

Systems must be defined up front


Evaluate costs and completion targets

Rigidity


Documentation

Hard to estimate costs, project overruns


Well defined user input

User input is sometimes limited


Ease of maintenance

Little parallelism


Development and design standards

Automation of documentation and standards is limited


Tolerates changes in MIS of staffing

Does not tolerate changes in requirements




Projects canned early on the result in little or no value

Application lifecycle management
Decision cycle
IPO model
Software development methodologies
Systems engineeringComputing terminologySoftware development processSoftware engineering
Webarchive template wayback linksArticles with short descriptionShort description is different from WikidataUse American English from March 2019All Wikipedia articles written in American EnglishAll articles with unsourced statementsArticles with unsourced statements from August 2021Articles needing additional references from January 2024All articles needing additional referencesWikipedia articles needing clarification from January 2023Articles lacking in-text citations from January 2023All articles lacking in-text citationsCommons category link is on Wikidata






# Technical_debt.md




(Top)





1
Causes








2
Service or repay the technical debt








3
Consequences








4
See also








5
References








6
External links


















This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these template messages)

This article may need to be rewritten to comply with Wikipedia's quality standards. You can help. The talk page may contain suggestions. (July 2024)
This article may be in need of reorganization to comply with Wikipedia's layout guidelines. Please help by editing the article to make improvements to the overall structure. (July 2024) (Learn how and when to remove this message)

 (Learn how and when to remove this message)
This article may need to be rewritten to comply with Wikipedia's quality standards. You can help. The talk page may contain suggestions. (July 2024)
This article may be in need of reorganization to comply with Wikipedia's layout guidelines. Please help by editing the article to make improvements to the overall structure. (July 2024) (Learn how and when to remove this message)
In software development and other information technology fields, technical debt (also known as design debt[1] or code debt) is the implied cost of future reworking required when choosing an easy but limited solution instead of a better approach that could take more time.[2]

Analogous with monetary debt,[3] if technical debt is not repaid, it can accumulate "interest", making it harder to implement changes. Unaddressed technical debt increases software entropy and cost of further rework. Similarly to monetary debt, technical debt is not necessarily a bad thing, and sometimes (e.g. as a proof-of-concept) is required to move projects forward. On the other hand, some experts claim that the "technical debt" metaphor tends to minimize the ramifications, which results in insufficient prioritization of the necessary work to correct it.[4][5]

As a change is started on a codebase, there is often the need to make other coordinated changes in other parts of the codebase or documentation. Changes required that are not completed are considered debt, and until paid, will incur interest on top of interest, making it cumbersome to build a project. Although the term is primarily used in software development, it can also be applied to other professions.

In a Dagstuhl seminar held in 2016, technical debt was defined by academic and industrial experts of the topic as follows: "In software-intensive systems, technical debt is a collection of design or implementation constructs that are expedient in the short term, but set up a technical context that can make future changes more costly or impossible. Technical debt presents an actual or contingent liability whose impact is limited to internal system qualities, primarily maintainability and evolvability."[6]

This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (October 2022) (Learn how and when to remove this message)
Common causes of technical debt include:

Ongoing development, long series of project enhancements over time renders old solutions sub-optimal.
Insufficient up-front definition, where requirements are still being defined during development, development starts before any design takes place. This is done to save time but often has to be reworked later.[7]
Business pressures, where the business considers getting something released sooner before the necessary changes are completed, hence builds up technical debt involving those uncompleted changes.[8]: 4 [9]: 22 
Lack of process or understanding, where businesses are blind to the concept of technical debt, and make decisions without considering the implications.
Tightly coupled components, where functions are not modular, the software is not flexible enough to adapt to changes in business needs.
Lack of a test suite, which encourages quick and risky band-aid bug fixes.
Lack of software documentation, where code is created without supporting documentation. The work to create documentation represents debt.[8]
Lack of collaboration, where knowledge isn't shared around the organization and business efficiency suffers, or junior developers are not properly mentored.
Parallel development on multiple branches accrues technical debt because of the work required to merge the changes into a single source base. The more changes done in isolation, the more debt.
Deferred refactoring; As the requirements for a project evolve, it may become clear that parts of the code have become inefficient or difficult to edit and must be refactored in order to support future requirements. The longer refactoring is delayed, and the more code is added, the bigger the debt.[9]: 29 
Lack of alignment to standards, where industry standard features, frameworks, and technologies are ignored. Eventually integration with standards will come and doing so sooner will cost less (similar to "delayed refactoring").[8]: 7 
Lack of knowledge, when the developer doesn't know how to write elegant code.[9]
Lack of ownership, when outsourced software efforts result in in-house engineering being required to refactor or rewrite outsourced code.
Poor technological leadership, where poorly thought out commands are handed down the chain of command.
Last minute specification changes. These have potential to percolate throughout a project, but there is insufficient time or budget to document and test the changes.[7]
Kenny Rubin uses the following status categories:[10]

Happened-upon technical debt—debt that the development team was unaware existed until it was exposed during the normal course of performing work on the product. For example, the team is adding a new feature to the product and in doing so it realizes that a work-around had been built into the code years before by someone who has long since departed.
Known technical debt—debt that is known to the development team and has been made visible using one of many approaches.
Targeted technical debt—debt that is known and has been targeted for servicing by the development team.
"Interest payments" are caused by both the necessary local maintenance and the absence of maintenance by other users of the project. Ongoing development in the upstream project can increase the cost of "paying off the debt" in the future.[clarification needed] One pays off the debt by simply completing the uncompleted work.[citation needed]

The buildup of technical debt is a major cause for projects to miss deadlines.[citation needed] It is difficult to estimate exactly how much work is necessary to pay off the debt. For each change that is initiated, an uncertain amount of uncompleted work is committed to the project. The deadline is missed when the project realizes that there is more uncompleted work (debt) than there is time to complete it in. To have predictable release schedules, a development team should limit the amount of work in progress in order to keep the amount of uncompleted work (or debt) small at all times.[citation needed]

If enough work is completed on a project to not present a barrier to submission, then a project will be released which still carries a substantial amount of technical debt. If this software reaches production, then the risks of implementing any future refactors which might address the technical debt increase dramatically. Modifying production code carries the risk of outages, actual financial losses and possibly legal repercussions if contracts involve service-level agreements (SLA). For this reason we can view the carrying of technical debt to production almost as if it were an increase in interest rate and the only time this decreases is when deployments are turned down and retired.

"As an evolving program is continually changed, its complexity, reflecting deteriorating structure, increases unless work is done to maintain or reduce it."[11] 
While Manny Lehman's Law already indicated that evolving programs continually add to their complexity and deteriorating structure unless work is done to maintain them, Ward Cunningham first drew the comparison between technical complexity and debt in a 1992 experience report:

"Shipping first time code is like going into debt. A little debt speeds development so long as it is paid back promptly with a rewrite... The danger occurs when the debt is not repaid. Every minute spent on not-quite-right code counts as interest on that debt. Entire engineering organizations can be brought to a stand-still under the debt load of an unconsolidated implementation, object-oriented or otherwise."[12] 
In his 2004 text, Refactoring to Patterns, Joshua Kerievsky presents a comparable argument concerning the costs associated with architectural negligence, which he describes as "design debt".[13]

Activities that might be postponed include documentation, writing tests, attending to TODO comments and tackling compiler and static code analysis warnings. Other instances of technical debt include knowledge that isn't shared around the organization and code that is too confusing to be modified easily.[citation needed]

Writing about PHP development in 2014, Junade Ali said:

The cost of never paying down this technical debt is clear; eventually the cost to deliver functionality will become so slow that it is easy for a well-designed competitive software product to overtake the badly-designed software in terms of features. In my experience, badly designed software can also lead to a more stressed engineering workforce, in turn leading higher staff churn (which in turn affects costs and productivity when delivering features). Additionally, due to the complexity in a given codebase, the ability to accurately estimate work will also disappear. In cases where development agencies charge on a feature-to-feature basis, the profit margin for delivering code will eventually deteriorate.
Grady Booch compares how evolving cities is similar to evolving software-intensive systems and how lack of refactoring can lead to technical debt.

"The concept of technical debt is central to understanding the forces that weigh upon systems, for it often explains where, how, and why a system is stressed. In cities, repairs on infrastructure are often delayed and incremental changes are made rather than bold ones. So it is again in software-intensive systems. Users suffer the consequences of capricious complexity, delayed improvements, and insufficient incremental change; the developers who evolve such systems suffer the slings and arrows of never being able to write quality code because they are always trying to catch up."[1] 
In open source software, postponing sending local changes to the upstream project is a form of technical debt.[citation needed]

Code smell (symptoms of inferior code quality that can contribute to technical debt)
Big ball of mud
Bus factor
Escalation of commitment
Manumation
Overengineering
Shotgun surgery
Software entropy
Software rot
Spaghetti code
SQALE
Sunk cost
TODO, FIXME, XXX
MetaphorsSoftware architectureSoftware engineering terminologySoftware maintenance
Articles with short descriptionShort description is different from WikidataWikipedia articles needing rewrite from July 2024All articles needing rewriteWikipedia articles needing reorganization from July 2024Articles with multiple maintenance issuesArticles needing additional references from October 2022All articles needing additional referencesWikipedia articles needing clarification from October 2013All articles with unsourced statementsArticles with unsourced statements from May 2018Articles with unsourced statements from April 2013






# Test-driven_development.md




(Top)





1
History








2
Coding cycle








3
Test-driven work








4
Development style




Toggle Development style subsection





4.1
Code visibility








4.2
Fakes, mocks and integration tests








4.3
Keep the unit small










5
Best practices




Toggle Best practices subsection





5.1
Test structure








5.2
Individual best practices








5.3
Practices to avoid, or "anti-patterns"










6
Comparison and demarcation




Toggle Comparison and demarcation subsection





6.1
TDD and ATDD








6.2
TDD and BDD










7
Software for TDD




Toggle Software for TDD subsection





7.1
xUnit frameworks








7.2
TAP results










8
TDD for complex systems




Toggle TDD for complex systems subsection





8.1
Designing for testability








8.2
Managing tests for large teams










9
Advantages and Disadvantages of Test Driven Development




Toggle Advantages and Disadvantages of Test Driven Development subsection





9.1
Advantages








9.2
Disadvantages








9.3
Benefits








9.4
Psychological benefits to programmer








9.5
Limitations










10
Conference








11
See also








12
References








13
External links
















4.1
Code visibility








4.2
Fakes, mocks and integration tests








4.3
Keep the unit small
















5.1
Test structure








5.2
Individual best practices








5.3
Practices to avoid, or "anti-patterns"
















6.1
TDD and ATDD








6.2
TDD and BDD














7.1
xUnit frameworks








7.2
TAP results














8.1
Designing for testability








8.2
Managing tests for large teams














9.1
Advantages








9.2
Disadvantages








9.3
Benefits








9.4
Psychological benefits to programmer








9.5
Limitations
























Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Test-driven development (TDD) is a way of writing code that involves writing an automated unit-level test case that fails, then writing just enough code to make the test pass, then refactoring both the test code and the production code, then repeating with another new test case.

Alternative approaches to writing automated tests is to write all of the production code before starting on the test code or to write all of the test code before starting on the production code. With TDD, both are written together, therefore shortening debugging time necessities[1].

TDD is related to the test-first programming concepts of extreme programming, begun in 1999,[2] but more recently has created more general interest in its own right.[3]

Programmers also apply the concept to improving and debugging legacy code developed with older techniques.[4]

Software engineer Kent Beck, who is credited with having developed or "rediscovered"[5] the technique, stated in 2003 that TDD encourages simple designs and inspires confidence.[6]

The original description of TDD was in an ancient book about programming. It said you take the input tape, manually type in the output tape you expect, then program until the actual output tape matches the expected output. After I'd written the first xUnit framework in Smalltalk I remembered reading this and tried it out. That was the origin of TDD for me. When describing TDD to older programmers, I often hear, "Of course. How else could you program?" Therefore I refer to my role as "rediscovering" TDD.
The TDD steps vary somewhat by author in count and description, but are generally as follows. These are based on the book Test-Driven Development by Example,[6] and Kent Beck's Canon TDD article.

moving code to where it most logically belongs
removing duplicate code
making names self-documenting
splitting methods into smaller pieces
re-arranging inheritance hierarchies
Each tests should be small and commits made often. If new code fails some tests, the programmer can undo or revert rather than debug excessively. 

When using external libraries, it is important not to write tests that are so small as to effectively test merely the library itself,[3] unless there is some reason to believe that the library is buggy or not feature-rich enough to serve all the needs of the software under development.

TDD has been adopted outside of software development, in both product and service teams, as test-driven work.[7] For testing to be successful, it needs to be practiced at the micro and macro levels. Every method in a class, every input data value, log message, and error code, amongst other data points, need to be tested.[8] Similar to TDD, non-software teams develop quality control (QC) checks (usually manual tests rather than automated tests) for each aspect of the work prior to commencing. These QC checks are then used to inform the design and validate the associated outcomes. The six steps of the TDD sequence are applied with minor semantic changes:

"Add a check" replaces "Add a test"
"Run all checks" replaces "Run all tests"
"Do the work" replaces "Write some code"
"Run all checks" replaces "Run tests"
"Clean up the work" replaces "Refactor code"
"Repeat"
There are various aspects to using test-driven development, for example the principles of "keep it simple, stupid" (KISS) and "You aren't gonna need it" (YAGNI). By focusing on writing only the code necessary to pass tests, designs can often be cleaner and clearer than is achieved by other methods.[6] In Test-Driven Development by Example, Kent Beck also suggests the principle "Fake it till you make it".

To achieve some advanced design concept such as a design pattern, tests are written that generate that design. The code may remain simpler than the target pattern, but still pass all required tests. This can be unsettling at first but it allows the developer to focus only on what is important.

Writing the tests first: The tests should be written before the functionality that is to be tested. This has been claimed to have many benefits. It helps ensure that the application is written for testability, as the developers must consider how to test the application from the outset rather than adding it later. It also ensures that tests for every feature gets written. Additionally, writing the tests first leads to a deeper and earlier understanding of the product requirements, ensures the effectiveness of the test code, and maintains a continual focus on software quality.[9] When writing feature-first code, there is a tendency by developers and organizations to push the developer on to the next feature, even neglecting testing entirely. The first TDD test might not even compile at first, because the classes and methods it requires may not yet exist. Nevertheless, that first test functions as the beginning of an executable specification.[10]

Each test case fails initially: This ensures that the test really works and can catch an error. Once this is shown, the underlying functionality can be implemented. This has led to the "test-driven development mantra", which is "red/green/refactor", where red means fail and green means pass. Test-driven development constantly repeats the steps of adding test cases that fail, passing them, and refactoring. Receiving the expected test results at each stage reinforces the developer's mental model of the code, boosts confidence and increases productivity.

Test code needs access to the code it is testing, but testing should not compromise normal design goals such as information hiding, encapsulation and the separation of concerns. Therefore, unit test code is usually located in the same project or module as the code being tested.

In object oriented design this still does not provide access to private data and methods. Therefore, extra work may be necessary for unit tests. In Java and other languages, a developer can use reflection to access private fields and methods.[11] Alternatively, an inner class can be used to hold the unit tests so they have visibility of the enclosing class's members and attributes. In the .NET Framework and some other programming languages, partial classes may be used to expose private methods and data for the tests to access.

It is important that such testing hacks do not remain in the production code. In C and other languages, compiler directives such as #if DEBUG ... #endif can be placed around such additional classes and indeed all other test-related code to prevent them being compiled into the released code. This means the released code is not exactly the same as what was unit tested. The regular running of fewer but more comprehensive, end-to-end, integration tests on the final release build can ensure (among other things) that no production code exists that subtly relies on aspects of the test harness.

There is some debate among practitioners of TDD, documented in their blogs and other writings, as to whether it is wise to test private methods and data anyway. Some argue that private members are a mere implementation detail that may change, and should be allowed to do so without breaking numbers of tests. Thus it should be sufficient to test any class through its public interface or through its subclass interface, which some languages call the "protected" interface.[12] Others say that crucial aspects of functionality may be implemented in private methods and testing them directly offers advantage of smaller and more direct unit tests.[13][14]

Unit tests are so named because they each test one unit of code. A complex module may have a thousand unit tests and a simple module may have only ten. The unit tests used for TDD should never cross process boundaries in a program, let alone network connections. Doing so introduces delays that make tests run slowly and discourage developers from running the whole suite. Introducing dependencies on external modules or data also turns unit tests into integration tests. If one module misbehaves in a chain of interrelated modules, it is not so immediately clear where to look for the cause of the failure.

When code under development relies on a database, a web service, or any other external process or service, enforcing a unit-testable separation is also an opportunity and a driving force to design more modular, more testable and more reusable code.[15] Two steps are necessary:

Whenever external access is needed in the final design, an interface should be defined that describes the access available. See the dependency inversion principle for a discussion of the benefits of doing this regardless of TDD.
The interface should be implemented in two ways, one of which really accesses the external process, and the other of which is a fake or mock. Fake objects need do little more than add a message such as "Person object saved" to a trace log, against which a test assertion can be run to verify correct behaviour. Mock objects differ in that they themselves contain test assertions that can make the test fail, for example, if the person's name and other data are not as expected.
Fake and mock object methods that return data, ostensibly from a data store or user, can help the test process by always returning the same, realistic data that tests can rely upon. They can also be set into predefined fault modes so that error-handling routines can be developed and reliably tested. In a fault mode, a method may return an invalid, incomplete or null response, or may throw an exception. Fake services other than data stores may also be useful in TDD: A fake encryption service may not, in fact, encrypt the data passed; a fake random number service may always return 1. Fake or mock implementations are examples of dependency injection.

A test double is a test-specific capability that substitutes for a system capability, typically a class or function, that the UUT depends on. There are two times at which test doubles can be introduced into a system: link and execution. Link time substitution is when the test double is compiled into the load module, which is executed to validate testing. This approach is typically used when running in an environment other than the target environment that requires doubles for the hardware level code for compilation. The alternative to linker substitution is run-time substitution in which the real functionality is replaced during the execution of a test case. This substitution is typically done through the reassignment of known function pointers or object replacement.

Test doubles are of a number of different types and varying complexities:

Dummy – A dummy is the simplest form of a test double. It facilitates linker time substitution by providing a default return value where required.
Stub – A stub adds simplistic logic to a dummy, providing different outputs.
Spy – A spy captures and makes available parameter and state information, publishing accessors to test code for private information allowing for more advanced state validation.
Mock – A mock is specified by an individual test case to validate test-specific behavior, checking parameter values and call sequencing.
Simulator – A simulator is a comprehensive component providing a higher-fidelity approximation of the target capability (the thing being doubled). A simulator typically requires significant additional development effort.[9]
A corollary of such dependency injection is that the actual database or other external-access code is never tested by the TDD process itself. To avoid errors that may arise from this, other tests are needed that instantiate the test-driven code with the "real" implementations of the interfaces discussed above. These are integration tests and are quite separate from the TDD unit tests. There are fewer of them, and they must be run less often than the unit tests. They can nonetheless be implemented using the same testing framework.

Integration tests that alter any persistent store or database should always be designed carefully with consideration of the initial and final state of the files or database, even if any test fails. This is often achieved using some combination of the following techniques:

The TearDown method, which is integral to many test frameworks.
try...catch...finally exception handling structures where available.
Database transactions where a transaction atomically includes perhaps a write, a read and a matching delete operation.
Taking a "snapshot" of the database before running any tests and rolling back to the snapshot after each test run. This may be automated using a framework such as Ant or NAnt or a continuous integration system such as CruiseControl.
Initialising the database to a clean state before tests, rather than cleaning up after them. This may be relevant where cleaning up may make it difficult to diagnose test failures by deleting the final state of the database before detailed diagnosis can be performed.
For TDD, a unit is most commonly defined as a class, or a group of related functions often called a module. Keeping units relatively small is claimed to provide critical benefits, including:

Reduced debugging effort – When test failures are detected, having smaller units aids in tracking down errors.
Self-documenting tests – Small test cases are easier to read and to understand.[9]
Advanced practices of test-driven development can lead to acceptance test–driven development (ATDD) and specification by example where the criteria specified by the customer are automated into acceptance tests, which then drive the traditional unit test-driven development (UTDD) process.[16] This process ensures the customer has an automated mechanism to decide whether the software meets their requirements. With ATDD, the development team now has a specific target to satisfy – the acceptance tests – which keeps them continuously focused on what the customer really wants from each user story.

Effective layout of a test case ensures all required actions are completed, improves the readability of the test case, and smooths the flow of execution. Consistent structure helps in building a self-documenting test case. A commonly applied structure for test cases has (1) setup, (2) execution, (3) validation, and (4) cleanup.

Setup: Put the Unit Under Test (UUT) or the overall test system in the state needed to run the test.
Execution: Trigger/drive the UUT to perform the target behavior and capture all output, such as return values and output parameters. This step is usually very simple.
Validation: Ensure the results of the test are correct. These results may include explicit outputs captured during execution or state changes in the UUT.
Cleanup: Restore the UUT or the overall test system to the pre-test state. This restoration permits another test to execute immediately after this one. In some cases, in order to preserve the information for possible test failure analysis, the cleanup should be starting the test just before the test's setup run. [9]
Some best practices that an individual could follow would be to separate common set-up and tear-down logic into test support services utilized by the appropriate test cases, to keep each test oracle focused on only the results necessary to validate its test, and to design time-related tests to allow tolerance for execution in non-real time operating systems. The common practice of allowing a 5-10 percent margin for late execution reduces the potential number of false negatives in test execution. It is also suggested to treat test code with the same respect as production code. Test code must work correctly for both positive and negative cases, last a long time, and be readable and maintainable. Teams can get together and review tests and test practices to share effective techniques and catch bad habits.[17]

Having test cases depend on system state manipulated from previously executed test cases (i.e., you should always start a unit test from a known and pre-configured state).
Dependencies between test cases. A test suite where test cases are dependent upon each other is brittle and complex. Execution order should not be presumed. Basic refactoring of the initial test cases or structure of the UUT causes a spiral of increasingly pervasive impacts in associated tests.
Interdependent tests. Interdependent tests can cause cascading false negatives. A failure in an early test case breaks a later test case even if no actual fault exists in the UUT, increasing defect analysis and debug efforts.
Testing precise execution, behavior, timing or performance.
Building "all-knowing oracles". An oracle that inspects more than necessary is more expensive and brittle over time. This very common error is dangerous because it causes a subtle but pervasive time sink across the complex project.[17][clarification needed]
Testing implementation details.
Slow running tests.
Test-driven development is related to, but different from acceptance test–driven development (ATDD).[18] TDD is primarily a developer's tool to help create well-written unit of code (function, class, or module) that correctly performs a set of operations. ATDD is a communication tool between the customer, developer, and tester to ensure that the requirements are well-defined. TDD requires test automation. ATDD does not, although automation helps with regression testing. Tests used in TDD can often be derived from ATDD tests, since the code units implement some portion of a requirement. ATDD tests should be readable by the customer. TDD tests do not need to be.

BDD (behavior-driven development) combines practices from TDD and from ATDD.[19]
It includes the practice of writing tests first, but focuses on tests which describe behavior, rather than tests which test a unit of implementation. Tools such as JBehave, Cucumber, Mspec and Specflow provide syntaxes which allow product owners, developers and test engineers to define together the behaviors which can then be translated into automated tests.

There are many testing frameworks and tools that are useful in TDD.

Developers may use computer-assisted testing frameworks, commonly collectively named xUnit (which are derived from SUnit, created in 1998), to create and automatically run the test cases. xUnit frameworks provide assertion-style test validation capabilities and result reporting. These capabilities are critical for automation as they move the burden of execution validation from an independent post-processing activity to one that is included in the test execution. The execution framework provided by these test frameworks allows for the automatic execution of all system test cases or various subsets along with other features.[20]

Testing frameworks may accept unit test output in the language-agnostic Test Anything Protocol created in 1987.

Exercising TDD on large, challenging systems requires a modular architecture, well-defined components with published interfaces, and disciplined system layering with maximization of platform independence. These proven practices yield increased testability and facilitate the application of build and test automation.[9]

Complex systems require an architecture that meets a range of requirements. A key subset of these requirements includes support for the complete and effective testing of the system. Effective modular design yields components that share traits essential for effective TDD.

High Cohesion ensures each unit provides a set of related capabilities and makes the tests of those capabilities easier to maintain.
Low Coupling allows each unit to be effectively tested in isolation.
Published Interfaces restrict Component access and serve as contact points for tests, facilitating test creation and ensuring the highest fidelity between test and production unit configuration.
A key technique for building effective modular architecture is Scenario Modeling where a set of sequence charts is constructed, each one focusing on a single system-level execution scenario. The Scenario Model provides an excellent vehicle for creating the strategy of interactions between components in response to a specific stimulus. Each of these Scenario Models serves as a rich set of requirements for the services or functions that a component must provide, and it also dictates the order in which these components and services interact together. Scenario modeling can greatly facilitate the construction of TDD tests for a complex system.[9]

In a larger system, the impact of poor component quality is magnified by the complexity of interactions. This magnification makes the benefits of TDD accrue even faster in the context of larger projects. However, the complexity of the total population of tests can become a problem in itself, eroding potential gains. It sounds simple, but a key initial step is to recognize that test code is also important software and should be produced and maintained with the same rigor as the production code.

Creating and managing the architecture of test software within a complex system is just as important as the core product architecture. Test drivers interact with the UUT, test doubles and the unit test framework.[9]

Test Driven Development (TDD) is a software development approach where tests are written before the actual code. It offers several advantages:

Comprehensive Test Coverage: TDD ensures that all new code is covered by at least one test, leading to more robust software.
Enhanced Confidence in Code: Developers gain greater confidence in the code's reliability and functionality.
Well-Documented Code: The process naturally results in well-documented code, as each test clarifies the purpose of the code it tests.
Requirement Clarity: TDD encourages a clear understanding of requirements before coding begins.
Facilitates Continuous Integration: It integrates well with continuous integration processes, allowing for frequent code updates and testing.
Boosts Productivity: Many developers find that TDD increases their productivity.
Reinforces Code Mental Model: TDD helps in building a strong mental model of the code's structure and behavior.
Emphasis on Design and Functionality: It encourages a focus on the design, interface, and overall functionality of the program.
Reduces Need for Debugging: By catching issues early in the development process, TDD reduces the need for extensive debugging later.
System Stability: Applications developed with TDD tend to be more stable and less prone to bugs.[21]
However, TDD is not without its drawbacks:

Increased Code Volume: Implementing TDD can result in a larger codebase as tests add to the total amount of code written.
False Security from Tests: A large number of passing tests can sometimes give a misleading sense of security regarding the code's robustness[22].
Maintenance Overheads: Maintaining a large suite of tests can add overhead to the development process.
Time-Consuming Test Processes: Writing and maintaining tests can be time-consuming.
Testing Environment Set-Up: TDD requires setting up and maintaining a suitable testing environment.
Learning Curve: It takes time and effort to become proficient in TDD practices.
Overcomplication: An overemphasis on TDD can lead to code that is more complex than necessary.
Neglect of Overall Design: Focusing too narrowly on passing tests can sometimes lead to neglect of the bigger picture in software design.
Increased Costs: The additional time and resources required for TDD can result in higher development costs.
A 2005 study found that using TDD meant writing more tests and, in turn, programmers who wrote more tests tended to be more productive.[23] Hypotheses relating to code quality and a more direct correlation between TDD and productivity were inconclusive.[24]

Programmers using pure TDD on new ("greenfield") projects reported they only rarely felt the need to invoke a debugger. Used in conjunction with a version control system, when tests fail unexpectedly, reverting the code to the last version that passed all tests may often be more productive than debugging.[25]

Test-driven development offers more than just simple validation of correctness, but can also drive the design of a program.[26] By focusing on the test cases first, one must imagine how the functionality is used by clients (in the first case, the test cases). So, the programmer is concerned with the interface before the implementation. This benefit is complementary to design by contract as it approaches code through test cases rather than through mathematical assertions or preconceptions.

Test-driven development offers the ability to take small steps when required. It allows a programmer to focus on the task at hand as the first goal is to make the test pass. Exceptional cases and error handling are not considered initially, and tests to create these extraneous circumstances are implemented separately. Test-driven development ensures in this way that all written code is covered by at least one test. This gives the programming team, and subsequent users, a greater level of confidence in the code.

While it is true that more code is required with TDD than without TDD because of the unit test code, the total code implementation time could be shorter based on a model by Müller and Padberg.[27] Large numbers of tests help to limit the number of defects in the code. The early and frequent nature of the testing helps to catch defects early in the development cycle, preventing them from becoming endemic and expensive problems. Eliminating defects early in the process usually avoids lengthy and tedious debugging later in the project.

TDD can lead to more modularized, flexible, and extensible code. This effect often comes about because the methodology requires that the developers think of the software in terms of small units that can be written and tested independently and integrated together later. This leads to smaller, more focused classes, looser coupling, and cleaner interfaces. The use of the mock object design pattern also contributes to the overall modularization of the code because this pattern requires that the code be written so that modules can be switched easily between mock versions for unit testing and "real" versions for deployment.

Because no more code is written than necessary to pass a failing test case, automated tests tend to cover every code path. For example, for a TDD developer to add an else branch to an existing if statement, the developer would first have to write a failing test case that motivates the branch. As a result, the automated tests resulting from TDD tend to be very thorough: they detect any unexpected changes in the code's behaviour. This detects problems that can arise where a change later in the development cycle unexpectedly alters other functionality.

Madeyski[28] provided empirical evidence (via a series of laboratory experiments with over 200 developers) regarding the superiority of the TDD practice over the traditional Test-Last approach or testing for correctness approach, with respect to the lower coupling between objects (CBO). The mean effect size represents a medium (but close to large) effect on the basis of meta-analysis of the performed experiments which is a substantial finding. It suggests a better modularization (i.e., a more modular design), easier reuse and testing of the developed software products due to the TDD programming practice.[28] Madeyski also measured the effect of the TDD practice on unit tests using branch coverage (BC) and mutation score indicator (MSI),[29][30][31] which are indicators of the thoroughness and the fault detection effectiveness of unit tests, respectively. The effect size of TDD on branch coverage was medium in size and therefore is considered substantive effect.[28] These findings have been subsequently confirmed by further, smaller experimental evaluations of TDD.[32][33][34][35]

Increased Confidence: TDD allows programmers to make changes or add new features with confidence. Knowing that the code is constantly tested reduces the fear of breaking existing functionality. This safety net can encourage more innovative and creative approaches to problem-solving.
Reduced Fear of Change, Reduced Stress: In traditional development, changing existing code can be daunting due to the risk of introducing bugs. TDD, with its comprehensive test suite, reduces this fear, as tests will immediately reveal any problems caused by changes. Knowing that the codebase has a safety net of tests can reduce stress and anxiety associated with programming. Developers might feel more relaxed and open to experimenting and refactoring.
Improved Focus: Writing tests first helps programmers concentrate on requirements and design before writing the code. This focus can lead to clearer, more purposeful coding, as the developer is always aware of the goal they are trying to achieve.
Sense of Achievement and Job Satisfaction: Passing tests can provide a quick, regular sense of accomplishment, boosting morale. This can be particularly motivating in long-term projects where the end goal might seem distant. The combination of all these factors can lead to increased job satisfaction. When developers feel confident, focused, and part of a collaborative team, their overall job satisfaction can significantly improve.
This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (August 2013) (Learn how and when to remove this message)
Test-driven development does not perform sufficient testing in situations where full functional tests are required to determine success or failure, due to extensive use of unit tests.[36] Examples of these are user interfaces, programs that work with databases, and some that depend on specific network configurations. TDD encourages developers to put the minimum amount of code into such modules and to maximize the logic that is in testable library code, using fakes and mocks to represent the outside world.[37]

Management support is essential. Without the entire organization believing that test-driven development is going to improve the product, management may feel that time spent writing tests is wasted.[38]

Unit tests created in a test-driven development environment are typically created by the developer who is writing the code being tested. Therefore, the tests may share blind spots with the code: if, for example, a developer does not realize that certain input parameters must be checked, most likely neither the test nor the code will verify those parameters. Another example: if the developer misinterprets the requirements for the module they are developing, the code and the unit tests they write will both be wrong in the same way. Therefore, the tests will pass, giving a false sense of correctness.

A high number of passing unit tests may bring a false sense of security, resulting in fewer additional software testing activities, such as integration testing and compliance testing.

Tests become part of the maintenance overhead of a project. Badly written tests, for example ones that include hard-coded error strings, are themselves prone to failure, and they are expensive to maintain. This is especially the case with fragile tests.[39] There is a risk that tests that regularly generate false failures will be ignored, so that when a real failure occurs, it may not be detected. It is possible to write tests for low and easy maintenance, for example by the reuse of error strings, and this should be a goal during the code refactoring phase described above.

Writing and maintaining an excessive number of tests costs time. Also, more-flexible modules (with limited tests) might accept new requirements without the need for changing the tests. For those reasons, testing for only extreme conditions, or a small sample of data, can be easier to adjust than a set of highly detailed tests.

The level of coverage and testing detail achieved during repeated TDD cycles cannot easily be re-created at a later date. Therefore, these original, or early, tests become increasingly precious as time goes by. The tactic is to fix it early. Also, if a poor architecture, a poor design, or a poor testing strategy leads to a late change that makes dozens of existing tests fail, then it is important that they are individually fixed. Merely deleting, disabling or rashly altering them can lead to undetectable holes in the test coverage.

First TDD Conference was held during July 2021.[40] Conferences were recorded on YouTube[41]

Acceptance testing
Behavior-driven development
Design by contract
Inductive programming
Integration testing
List of software development philosophies
List of unit testing frameworks
Mock object
Programming by example
Sanity check
Self-testing code
Software testing
Test case
Transformation Priority Premise
Unit testing
Continuous test-driven development
Extreme programmingSoftware development philosophiesSoftware development processSoftware testing
Articles with short descriptionShort description is different from WikidataWikipedia articles needing clarification from February 2022Articles needing additional references from August 2013All articles needing additional references






# Test_automation.md




(Top)





1
General approaches








2
Other approaches




Toggle Other approaches subsection





2.1
Model-based testing








2.2
Regression testing








2.3
API testing








2.4
Graphical user interface (GUI) testing










3
Methodologies




Toggle Methodologies subsection





3.1
Test-driven development








3.2
Continuous testing










4
Considerations




Toggle Considerations subsection





4.1
Factors to consider for the decision to implement test automation








4.2
Plateau effect








4.3
What to test










5
Roles




Toggle Roles subsection





5.1
Test automation tools








5.2
Test engineer










6
Testing at different levels




Toggle Testing at different levels subsection





6.1
Unit, service, and user interface levels








6.2
Unit, integration, and end-to-end levels










7
Framework approach in automation




Toggle Framework approach in automation subsection





7.1
Unit testing frameworks








7.2
Test automation interface






7.2.1
Interface engine








7.2.2
Object repository












8
Defining boundaries between automation framework and a testing tool




Toggle Defining boundaries between automation framework and a testing tool subsection





8.1
Data-driven testing








8.2
Modularity-driven testing








8.3
Keyword-driven testing








8.4
Hybrid testing








8.5
Model-based testing








8.6
Behavior driven development










9
See also








10
References




Toggle References subsection





10.1
General references














2.1
Model-based testing








2.2
Regression testing








2.3
API testing








2.4
Graphical user interface (GUI) testing


















3.1
Test-driven development








3.2
Continuous testing














4.1
Factors to consider for the decision to implement test automation








4.2
Plateau effect








4.3
What to test
















5.1
Test automation tools








5.2
Test engineer














6.1
Unit, service, and user interface levels








6.2
Unit, integration, and end-to-end levels














7.1
Unit testing frameworks








7.2
Test automation interface






7.2.1
Interface engine








7.2.2
Object repository














7.2.1
Interface engine








7.2.2
Object repository














8.1
Data-driven testing








8.2
Modularity-driven testing








8.3
Keyword-driven testing








8.4
Hybrid testing








8.5
Model-based testing








8.6
Behavior driven development
























10.1
General references








Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
This article includes a list of general references, but it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations. (February 2009) (Learn how and when to remove this message)
In software testing, test automation is the use of software separate from the software being tested to control the execution of tests and the comparison of actual outcomes with predicted outcomes.[1] Test automation can automate some repetitive but necessary tasks in a formalized testing process already in place, or perform additional testing that would be difficult to do manually. Test automation is critical for continuous delivery and continuous testing.[2]

There are many approaches to test automation, however below are the general approaches used widely:

Graphical user interface testing. A testing framework that generates user interface events such as keystrokes and mouse clicks, and observes the changes that result in the user interface, to validate that the observable behavior of the program is correct.
API driven testing. A testing framework that uses a programming interface to the application to validate the behaviour under test. Typically API driven testing bypasses application user interface altogether. It can also be testing public (usually) interfaces to classes, modules or libraries are tested with a variety of input arguments to validate that the results that are returned are correct.
One way to generate test cases automatically is model-based testing through use of a model of the system for test case generation, but research continues into a variety of alternative methodologies for doing so.[citation needed] In some cases, the model-based approach enables non-technical users to create automated business test cases in plain English so that no programming of any kind is needed in order to configure them for multiple operating systems, browsers, and smart devices.[3]

Some software testing tasks (such as extensive low-level interface regression testing) can be laborious and time-consuming to do manually. In addition, a manual approach might not always be effective in finding certain classes of defects. Test automation offers a possibility to perform these types of testing effectively.

Once automated tests have been developed, they can be run quickly and repeatedly many times. This can be a cost-effective method for regression testing of software products that have a long maintenance life. Even minor patches over the lifetime of the application can cause existing features to break which were working at an earlier point in time.

API testing is also being widely used by software testers as it enables them to verify requirements independent of their GUI implementation, commonly to test them earlier in development, and to make sure the test itself adheres to clean code principles, especially the single responsibility principle. It involves directly testing APIs as part of integration testing, to determine if they meet expectations for functionality, reliability, performance, and security.[4] Since APIs lack a GUI, API testing is performed at the message layer.[5] API testing is considered critical when an API serves as the primary interface to application logic.[6]

Many test automation tools provide record and playback features that allow users to interactively record user actions and replay them back any number of times, comparing actual results to those expected. The advantage of this approach is that it requires little or no software development. This approach can be applied to any application that has a graphical user interface. However, reliance on these features poses major reliability and maintainability problems. Relabelling a button or moving it to another part of the window may require the test to be re-recorded. Record and playback also often adds irrelevant activities or incorrectly records some activities.[citation needed]

A variation on this type of tool is for testing of web sites. Here, the "interface" is the web page. However, such a framework utilizes entirely different techniques because it is rendering HTML and listening to DOM Events instead of operating system events. Headless browsers or solutions based on Selenium Web Driver are normally used for this purpose.[7][8][9]

Another variation of this type of test automation tool is for testing mobile applications. This is very useful given the number of different sizes, resolutions, and operating systems used on mobile phones. For this variation, a framework is used in order to instantiate actions on the mobile device and to gather results of the actions.

Another variation is script-less test automation that does not use record and playback, but instead builds a model[clarification needed] of the application and then enables the tester to create test cases by simply inserting test parameters and conditions, which requires no scripting skills.

Test automation, mostly using unit testing, is a key feature of extreme programming and agile software development, where it is known as test-driven development (TDD) or test-first development. Unit tests can be written to define the functionality before the code is written. However, these unit tests evolve and are extended as coding progresses, issues are discovered and the code is subjected to refactoring.[10] Only when all the tests for all the demanded features pass is the code considered complete. Proponents argue that it produces software that is both more reliable and less costly than code that is tested by manual exploration.[citation needed] It is considered more reliable because the code coverage is better, and because it is run constantly during development rather than once at the end of a waterfall development cycle. The developer discovers defects immediately upon making a change, when it is least expensive to fix. Finally, code refactoring is safer when unit testing is used; transforming the code into a simpler form with less code duplication, but equivalent behavior, is much less likely to introduce new defects when the refactored code is covered by unit tests.

Continuous testing is the process of executing automated tests as part of the software delivery pipeline to obtain immediate feedback on the business risks associated with a software release candidate.[11][12] For Continuous Testing, the scope of testing extends from validating bottom-up requirements or user stories to assessing the system requirements associated with overarching business goals.[13]

What to automate, when to automate, or even whether one really needs automation are crucial decisions which the testing (or development) team must make.[14] A multi-vocal literature review of 52 practitioner and 26 academic sources found that five main factors to consider in test automation decision are: 1) System Under Test (SUT), 2) the types and numbers of tests, 3) test-tool, 4) human and organizational topics, and 5) cross-cutting factors. The most frequent individual factors identified in the study were: need for regression testing, economic factors, and maturity of SUT.[15]

While the reusability of automated tests is valued by software development companies, this property can also be viewed as a disadvantage. It leads to the so-called "Pesticide Paradox", where repeatedly executed scripts stop detecting errors that go beyond their frameworks. In such cases, manual testing may be a better investment. This ambiguity once again leads to the conclusion that the decision on test automation should be made individually, keeping in mind project requirements and peculiarities.

Testing tools can help automate tasks such as product installation, test data creation, GUI interaction, problem detection (consider parsing or polling agents equipped with test oracles), defect logging, etc., without necessarily automating tests in an end-to-end fashion.

One must keep satisfying popular requirements when thinking of test automation:

Platform and OS independence
Data driven capability (Input Data, Output Data, Metadata)
Customization Reporting (DB Data Base Access, Crystal Reports)
Easy debugging and logging
Version control friendly – minimal binary files
Extensible & Customization (Open APIs to be able to integrate with other tools)
Common Driver (For example, in the Java development ecosystem, that means Ant or Maven and the popular IDEs). This enables tests to integrate with the developers' workflows.
Support unattended test runs for integration with build processes and batch runs. Continuous integration servers require this.
Email Notifications like bounce messages
Support distributed execution environment (distributed test bed)
Distributed application support (distributed SUT)
Test automation tools can be expensive and are usually employed in combination with manual testing. Test automation can be made cost-effective in the long term, especially when used repeatedly in regression testing. A good candidate for test automation is a test case for common flow of an application, as it is required to be executed (regression testing) every time an enhancement is made in the application. Test automation reduces the effort associated with manual testing. Manual effort is needed to develop and maintain automated checks, as well as reviewing test results.

In automated testing, the test engineer or software quality assurance person must have software coding ability since the test cases are written in the form of source code which when run produce output according to the assertions that are a part of it. Some test automation tools allow for test authoring to be done by keywords instead of coding, which do not require programming.

A strategy to decide the amount of tests to automate is the test automation pyramid. This strategy suggests to write three types of tests with different granularity. The higher the level, less is the amount of tests to write.[16]

As a solid foundation, unit testing provides robustness to the software products. Testing individual parts of the code makes it easy to write and run the tests. Developers write unit tests as a part of each story and integrate them with CI.[17]
The service layer refers to testing the services of an application separately from its user interface, these services are anything that the application does in response to some input or set of inputs.
At the top level we have UI testing which has fewer tests due to the different attributes that make it more complex to run, for example the fragility of the tests, where a small change in the user interface can break a lot of tests and adds maintenance effort.[16][18]
One conception of the testing pyramid contains unit, integration, and end-to-end unit tests. According to Google's testing blog, unit tests should make up the majority of your testing strategy, with fewer integration tests and only a small amount of end-to-end tests.[19]

Unit tests: These are tests that test individual components or units of code in isolation. They are fast, reliable, and isolate failures to small units of code.
Integration tests: These tests check how different units of code work together. Although individual units may function properly on their own, integration tests ensure that they operate together coherently.
End-to-end tests: These test the system as a whole, simulating real-world usage scenarios. They are the slowest and most complex tests.
A test automation framework is an integrated system that sets the rules of automation of a specific product. This system integrates the function libraries, test data sources, object details and various reusable modules. These components act as small building blocks which need to be assembled to represent a business process. The framework provides the basis of test automation and simplifies the automation effort.

The main advantage of a framework of assumptions, concepts and tools that provide support for automated software testing is the low cost for maintenance. If there is change to any test case then only the test case file needs to be updated and the driver Script and startup script will remain the same. Ideally, there is no need to update the scripts in case of changes to the application.

Choosing the right framework/scripting technique helps in maintaining lower costs. The costs associated with test scripting are due to development and maintenance efforts. The approach of scripting used during test automation has effect on costs.

Various framework/scripting techniques are generally used:

Linear (procedural code, possibly generated by tools like those that use record and playback)
Structured (uses control structures - typically ‘if-else’, ‘switch’, ‘for’, ‘while’ conditions/ statements)
Data-driven (data is persisted outside of tests in a database, spreadsheet, or other mechanism)
Keyword-driven
Hybrid (two or more of the patterns above are used)
Agile automation framework
The Testing framework is responsible for:[20]

defining the format in which to express expectations
creating a mechanism to hook into or drive the application under test
executing the tests
reporting results
A growing trend in software development is the use of unit testing frameworks such as the xUnit frameworks (for example, JUnit and NUnit) that allow the execution of unit tests to determine whether various sections of the code are acting as expected under various circumstances. Test cases describe tests that need to be run on the program to verify that the program runs as expected.

Test automation interfaces are platforms that provide a single workspace for incorporating multiple testing tools and frameworks for System/Integration testing of application under test. The goal of Test Automation Interface is to simplify the process of mapping tests to business criteria without coding coming in the way of the process. Test automation interface are expected to improve the efficiency and flexibility of maintaining test scripts.[21]

Test Automation Interface consists of the following core modules:

Interface Engine
Interface Environment
Object Repository
Interface engines are built on top of Interface Environment. Interface engine consists of a parser and a test runner. The parser is present to parse the object files coming from the object repository into the test specific scripting language. The test runner executes the test scripts using a test harness.[21]

Object repositories are a collection of UI/Application object data recorded by the testing tool while exploring the application under test.[21]

Tools are specifically designed to target some particular test environment, such as Windows and web automation tools, etc. Tools serve as a driving agent for an automation process. However, an automation framework is not a tool to perform a specific task, but rather infrastructure that provides the solution where different tools can do their job in a unified manner. This provides a common platform for the automation engineer.

There are various types of frameworks. They are categorized on the basis of the automation component they leverage. These are:

Data-driven testing
Modularity-driven testing
Keyword-driven testing
Hybrid testing
Model-based testing
Code-driven testing
Behavior driven development
Comparison of GUI testing tools
List of web testing tools
Continuous testing
Fuzzing
Headless browser
Software testing
System testing
Unit test
Software testingAutomation software
CS1 Arabic-language sources (ar)Articles with short descriptionShort description is different from WikidataArticles lacking in-text citations from February 2009All articles lacking in-text citationsAll articles with unsourced statementsArticles with unsourced statements from August 2009Articles with unsourced statements from March 2013Wikipedia articles needing clarification from June 2016Articles with unsourced statements from January 2013Articles with excerptsWebarchive template wayback links






# Timeboxing.md




(Top)





1
In project management




Toggle In project management subsection





1.1
As an alternative to fixing scope








1.2
To manage risk








1.3
Adoption in software development










2
In personal time management








3
Relationship with other methods








4
See also








5
References










1.1
As an alternative to fixing scope








1.2
To manage risk








1.3
Adoption in software development




















Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
In agile principles, timeboxing allocates a maximum unit of time to an activity, called a timebox, within which a planned activity takes place. It is used by agile principles-based project management approaches and for personal time management.

Timeboxing is used as a project planning technique. The schedule is divided into a number of separate time periods (timeboxes), with each part having its own deliverables, deadline and budget.[citation needed] Sometimes referred to as schedule as independent variable (SAIV).[1] "Timeboxing works best in multistage projects or tasks that take little time and you can fit them in the same time slot. It is also worth implementing in case of duties that have foreseeable time-frames of completion."[2]

In project management, there are generally considered to be three constraints: time (sometimes schedule), cost (sometimes budget), and scope.[3][4][5][6][7] (Quality is often added as a fourth constraint---represented as the middle of a triangle.[8][9][10]) The assumption is that a change in one constraint will affect the others.[6]

Without timeboxing, projects usually work to a fixed scope,[11] in which case when it becomes clear that some deliverables cannot be completed within the planned timescales, either the deadline has to be extended (to allow more time to complete the fixed scope) or more people are involved (to complete the fixed scope in the same time). Often both happen, resulting in delayed delivery, increased costs, and often reduced quality (as per The Mythical Man-Month principle).

With timeboxing, the deadline is fixed, meaning that the scope would have to be reduced. As this means organizations have to focus on completing the most important deliverables first, timeboxing often goes hand-in-hand with a scheme for prioritizing of deliverables (such as with the MoSCoW method).[12]

Timeboxes are used as a form of risk management, to explicitly identify uncertain task/time relationships, i.e., work that may easily extend past its deadline. Time constraints are often a primary driver in planning and should not be changed without considering project or sub-project critical paths. That is, it's usually important to meet deadlines. Risk factors for missed deadlines can include complications upstream of the project, planning errors within the project, team-related issues, or faulty execution of the plan. Upstream issues might include changes in project mission or backing/support from management. A common planning error is inadequate task breakdown, which can lead to underestimation of the time required to perform the work. Team-related issues can include trouble with inter-team communication; lack of experience or required cross-functionality; lack of commitment/drive/motivation (i.e. poor team building and management).

To stay on deadline, the following actions against the triple constraints are commonly evaluated:

Reduce scope: drop requirements of lower impact (the ones that will not be directly missed by the user)
Time is the fixed constraint here
Increase cost: e.g., add overtime or resources
Many successful software development projects use timeboxing, especially smaller ones.[13] Adopting timeboxing more than tripled developer productivity at DuPont in the '80s.[14] In some cases, applications were completely delivered within the time estimated to complete just a specification.[14] However, Steve McConnell argues that not every product is suitable[14] and that timeboxing should only be used after the customer agrees to cut features, not quality.[14] There is little evidence for strong adoption amongst the largest class of projects.[13]

Timeboxing has been adopted by some notable software development methodologies:

Dynamic systems development method (DSDM).[12]
In lean software development, pull scheduling with Kanban provides short term time management. When developing a large and complex system, where long term planning is required, timeboxing is layered above.[15]
Rapid application development (RAD) software development process features iterative development and software prototyping. According to Steve McConnell, timeboxing is a "Best Practice" for RAD and a typical timebox length should be 60–120 days.[14]
Scrum was influenced by ideas of timeboxing and iterative development.[16] Regular timeboxed units known as sprints form the basic unit of development.[17] A typical length for a sprint is less than 30 days.[18][19] Sprint planning, sprint retrospective and sprint review meetings are timeboxed.[18]
In Extreme programming methodologies, development planning is timeboxed into iterations typically 1, 2 or 3 weeks in length. The business revalues pending user stories before each iteration.[20]
Agile software development advocates moving from plan driven to value driven development. Quality and time are fixed but flexibility allowed in scope. Delivering the most important features first leads to an earlier return on investment than the waterfall model.[7]

A lack of detailed specifications typically is the result of a lack of time, or the lack of knowledge of the desired end result (solution). In many types of projects, and especially in software engineering, analyzing and defining all requirements and specifications before the start of the realization phase is impossible. Timeboxing can be a favorable type of contracting for projects in which the deadline is the most critical aspect and when not all requirements are completely specified up front. This also allows for new feedback or insights discovered during the project to be reflected in the end result.[12]

Timeboxing can be used for personal tasks, in which case it uses a reduced scale of time (e.g., thirty minutes) and of deliverables (e.g., a household chore instead of project deliverable), and is often called timeblocking.

Personal timeboxing is also said to act as a life hack to help curb perfectionist tendencies (by setting a firm time and not overcommitting to a task) which can also enhance creativity and focus (by creating a sense of urgency or increased pressure).[21]

Timeboxing acts as a building block in other personal time management methods:

The Pomodoro Technique is based on 25 minute timeboxes of focused concentration separated by breaks allowing the mind to recover.[22]
Andy Hunt gives timeboxing as his 'T' in SMART.[23]
Design sprint, a time-constrained five-phase process used in design thinking.
Time managementDynamic systems development methodSoftware project managementAgile software developmentLean manufacturing
Webarchive template archiveis linksWebarchive template wayback linksArticles with short descriptionShort description is different from WikidataAll articles with unsourced statementsArticles with unsourced statements from November 2011






# Unified_Modeling_Language.md




(Top)





1
History




Toggle History subsection





1.1
Before UML 1.0








1.2
UML 1.x






1.2.1
Cardinality notation










1.3
UML 2










2
Design




Toggle Design subsection





2.1
Software development methods








2.2
Modeling










3
Diagrams




Toggle Diagrams subsection





3.1
Structure diagrams








3.2
Behavior diagrams






3.2.1
Interaction diagrams












4
Metamodeling








5
Adoption








6
See also








7
References








8
Further reading








9
External links










1.1
Before UML 1.0








1.2
UML 1.x






1.2.1
Cardinality notation










1.3
UML 2












1.2.1
Cardinality notation














2.1
Software development methods








2.2
Modeling














3.1
Structure diagrams








3.2
Behavior diagrams






3.2.1
Interaction diagrams














3.2.1
Interaction diagrams






















The unified modeling language (UML) is a general-purpose visual modeling language that is intended to provide a standard way to visualize the design of a system.[1]

UML provides a standard notation for many types of diagrams which can be roughly divided into three main groups: behavior diagrams, interaction diagrams, and structure diagrams. 

The creation of UML was originally motivated by the desire to standardize the disparate notational systems and approaches to software design. It was developed at Rational Software in 1994–1995, with further development led by them through 1996.[2]

In 1997, UML was adopted as a standard by the Object Management Group (OMG) and has been managed by this organization ever since. In 2005, UML was also published by the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC) as the ISO/IEC 19501 standard.[3] Since then the standard has been periodically revised to cover the latest revision of UML.[4]

In software engineering, most practitioners do not use UML, but instead produce informal hand drawn diagrams; these diagrams, however, often include elements from UML.[5]: 536 

UML has evolved since the second half of the 1990s and has its roots in the object-oriented programming methods developed in the late 1980s and early 1990s. The timeline (see image) shows the highlights of the history of object-oriented modeling methods and notation.

It is originally based on the notations of the Booch method, the object-modeling technique (OMT), and object-oriented software engineering (OOSE), which it has integrated into a single language.[6]

Rational Software Corporation hired James Rumbaugh from General Electric in 1994 and after that, the company became the source for two of the most popular object-oriented modeling approaches of the day:[7] Rumbaugh's object-modeling technique (OMT) and Grady Booch's method. They were soon assisted in their efforts by Ivar Jacobson, the creator of the object-oriented software engineering (OOSE) method, who joined them at Rational in 1995.[2]

Under the technical leadership of those three (Rumbaugh, Jacobson, and Booch), a consortium called the UML Partners was organized in 1996 to complete the Unified Modeling Language (UML) specification and propose it to the Object Management Group (OMG) for standardization. The partnership also contained additional interested parties (for example HP, DEC, IBM, and Microsoft). The UML Partners' UML 1.0 draft was proposed to the OMG in January 1997 by the consortium. During the same month, the UML Partners formed a group, designed to define the exact meaning of language constructs, chaired by Cris Kobryn and administered by Ed Eykholt, to finalize the specification and integrate it with other standardization efforts. The result of this work, UML 1.1, was submitted to the OMG in August 1997 and adopted by the OMG in November 1997.[2][8]

After the first release, a task force was formed[2] to improve the language, which released several minor revisions, 1.3, 1.4, and 1.5.[9]

The standards it produced (as well as the original standard) have been noted as being ambiguous and inconsistent.[10]

As with database Chen, Bachman, and ISO ER diagrams, class models are specified to use "look-across" cardinalities, even though several authors (Merise,[11]
Elmasri & Navathe,[12]
amongst others[13])
prefer same-side or "look-here" for roles and both minimum and maximum cardinalities. Recent researchers (Feinerer[14]
and Dullea et al.
[15])
have shown that the "look-across" technique used by UML and ER diagrams is less effective and less coherent when applied to n-ary relationships of order strictly greater than 2.

Feinerer says: "Problems arise if we operate under the look-across semantics as used for UML associations. Hartmann[16]
investigates this situation and shows how and why different transformations fail.", and: "As we will see on the next few pages, the look-across interpretation introduces several difficulties which prevent the extension of simple mechanisms from binary to n-ary associations."

UML 2.0 major revision replaced version 1.5 in 2005, which was developed with an enlarged consortium to improve the language further to reflect new experiences on the usage of its features.[17]

Although UML 2.1 was never released as a formal specification, versions 2.1.1 and 2.1.2 appeared in 2007, followed by UML 2.2 in February 2009. UML 2.3 was formally released in May 2010.[18] UML 2.4.1 was formally released in August 2011.[18] UML 2.5 was released in October 2012 as an "In progress" version and was officially released in June 2015.[18]
The formal version 2.5.1 was adopted in December 2017.[1]

There are four parts to the UML 2.x specification:

The Superstructure that defines the notation and semantics for diagrams and their model elements
The Infrastructure that defines the core metamodel on which the Superstructure is based
The Object Constraint Language (OCL) for defining rules for model elements
The UML Diagram Interchange that defines how UML 2 diagram layouts are exchanged
Until UML 2.4.1, the latest versions of these standards were:[19]

UML Superstructure version 2.4.1
UML Infrastructure version 2.4.1
OCL version 2.3.1
UML Diagram Interchange version 1.0.
Since version 2.5, the UML Specification has been simplified (without Superstructure and Infrastructure), and the latest versions of these standards are now:[20]

UML Specification 2.5.1
OCL version 2.4
It continues to be updated and improved by the revision task force, who resolve any issues with the language.[21]

UML offers a way to visualize a system's architectural blueprints in a diagram, including elements such as:[6]

any activities (jobs);
individual components of the system;
and how they can interact with other software components;
how the system will run;
how entities interact with others (components and interfaces);
external user interface.
and how they can interact with other software components;
Although originally intended for object-oriented design documentation, UML has been extended to a larger set of design documentation (as listed above),[22] and has been found useful in many contexts.[23]

UML is not a development method by itself;[24] however, it was designed to be compatible with the leading object-oriented software development methods of its time, for example, OMT, Booch method, Objectory, and especially RUP it was originally intended to be used with when work began at Rational Software.

It is important to distinguish between the UML model and the set of diagrams of a system. A diagram is a partial graphic representation of a system's model. The set of diagrams need not completely cover the model and deleting a diagram does not change the model. The model may also contain documentation that drives the model elements and diagrams (such as written use cases).

UML diagrams represent two different views of a system model:[25]

Static (or structural) view: emphasizes the static structure of the system using objects, attributes, operations and relationships. It includes class diagrams and composite structure diagrams.
Dynamic (or behavioral) view: emphasizes the dynamic behavior of the system by showing collaborations among objects and changes to the internal states of objects. This view includes sequence diagrams, activity diagrams and state machine diagrams.
UML models can be exchanged among UML tools by using the XML Metadata Interchange (XMI) format.

In UML, one of the key tools for behavior modeling is the use-case model, caused by OOSE. Use cases are a way of specifying required usages of a system. Typically, they are used to capture the requirements of a system, that is, what a system is supposed to do.[26]

UML diagram types
Structural UML diagrams
Class diagram
Component diagram
Composite structure diagram
Deployment diagram
Object diagram
Package diagram
Profile diagram

Behavioral UML diagrams
Activity diagram
Communication diagram
Interaction overview diagram
Sequence diagram
State diagram
Timing diagram
Use case diagram
vte
Class diagram
Component diagram
Composite structure diagram
Deployment diagram
Object diagram
Package diagram
Profile diagram
Activity diagram
Communication diagram
Interaction overview diagram
Sequence diagram
State diagram
Timing diagram
Use case diagram
vte
UML 2 has many types of diagrams, which are divided into two categories.[6] Some types represent structural information, and the rest represent general types of behavior, including a few that represent different aspects of interactions. These diagrams can be categorized hierarchically as shown in the following class diagram:[6]

These diagrams may all contain comments or notes explaining usage, constraint, or intent.

Structure diagrams represent the static aspects of the system. It emphasizes the things that must be present in the system being modeled. Since structure diagrams represent the structure, they are used extensively in documenting the software architecture of software systems. For example, the component diagram describes how a software system is split up into components and shows the dependencies among these components.




Component diagram



Class diagram


Behavior diagrams represent the dynamic aspect of the system. It emphasizes what must happen in the system being modeled. Since behavior diagrams illustrate the behavior of a system, they are used extensively to describe the functionality of software systems. As an example, the activity diagram describes the business and operational step-by-step activities of the components in a system.




Activity diagram



Use case diagram


Interaction diagrams, a subset of behavior diagrams, emphasize the flow of control and data among the things in the system being modeled. For example, the sequence diagram shows how objects communicate with each other regarding a sequence of messages.




Sequence diagram



Communication diagram


The Object Management Group (OMG) has developed a metamodeling architecture to define the UML, called the Meta-Object Facility.[27] MOF is designed as a four-layered architecture, as shown in the image at right. It provides a meta-meta model at the top, called the M3 layer. This M3-model is the language used by Meta-Object Facility to build metamodels, called M2-models.

The most prominent example of a Layer 2 Meta-Object Facility model is the UML metamodel, which describes the UML itself. These M2-models describe elements of the M1-layer, and thus M1-models. These would be, for example, models written in UML. The last layer is the M0-layer or data layer. It is used to describe runtime instances of the system.[28]

The meta-model can be extended using a mechanism called stereotyping. This has been criticized as being insufficient/untenable by Brian Henderson-Sellers and Cesar Gonzalez-Perez in "Uses and Abuses of the Stereotype Mechanism in UML 1.x and 2.0".[29]

In 2013, UML had been marketed by OMG for many contexts, but aimed primarily at software development with limited success.[23][30]

It has been treated, at times, as a design silver bullet, which leads to problems. UML misuse includes overuse (designing every part of the system with it, which is unnecessary) and assuming that novices can design with it.[31]

It is considered a large language, with many constructs. Some people (including Jacobson) feel that UML's size hinders learning (and therefore using) it.[32]

MS Visual Studio dropped support for UML in 2016 due to lack of usage.[33]

According to Google Trends UML has been on a steady decline since 2004.[34]

Applications of UML
Business Process Model and Notation (BPMN)
C4 model
Department of Defense Architecture Framework
DOT (graph description language)
List of Unified Modeling Language tools
MODAF
Model-based testing
Model-driven engineering
Object-oriented role analysis and modeling
Process Specification Language
Systems Modeling Language (SysML)
Unified Modeling LanguageArchitecture description languageData modeling languagesData modeling diagramsDiagramsKnowledge representationISO standardsSpecification languagesSoftware modeling languageModeling languages
Webarchive template wayback linksArticles with short descriptionShort description matches WikidataUse American English from March 2020All Wikipedia articles written in American EnglishUse dmy dates from September 2020Commons link from WikidataArticles with FAST identifiersArticles with BNF identifiersArticles with BNFdata identifiersArticles with GND identifiersArticles with J9U identifiersArticles with LCCN identifiersArticles with NKC identifiers






# Unit_testing.md




(Top)





1
History








2
Unit








3
Execution








4
Testing criteria








5
Test case








6
Test double








7
Parameterized test








8
Agile








9
Test-driven development








10
Value




Toggle Value subsection





10.1
Early detection of problems in the development cycle








10.2
Reduced cost








10.3
More frequent releases








10.4
Allows for code refactoring








10.5
Detects changes which may break a design contract








10.6
Reduce uncertainty








10.7
Documentation of system behavior










11
Limitations and disadvantages




Toggle Limitations and disadvantages subsection





11.1
Difficulty in setting up realistic and useful tests








11.2
Requires discipline throughout the development process








11.3
Requires version control








11.4
Requires regular reviews








11.5
Limitations for embedded system software








11.6
Limitations for testing integration with external systems










12
Examples




Toggle Examples subsection





12.1
JUnit










13
As executable specifications








14
Applications




Toggle Applications subsection





14.1
Extreme programming








14.2
Automated testing frameworks








14.3
Language-level unit testing support










15
See also








16
References








17
Further reading








18
External links




























10.1
Early detection of problems in the development cycle








10.2
Reduced cost








10.3
More frequent releases








10.4
Allows for code refactoring








10.5
Detects changes which may break a design contract








10.6
Reduce uncertainty








10.7
Documentation of system behavior
























11.1
Difficulty in setting up realistic and useful tests








11.2
Requires discipline throughout the development process








11.3
Requires version control








11.4
Requires regular reviews








11.5
Limitations for embedded system software








11.6
Limitations for testing integration with external systems






















12.1
JUnit














14.1
Extreme programming








14.2
Automated testing frameworks








14.3
Language-level unit testing support






















Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Unit testing, a.k.a. component or module testing, is a form of software testing by which isolated source code is tested to validate expected behavior.[1]

Unit testing describes tests that are run at the unit-level to contrast testing at the integration or system level.

Unit testing, as principle for testing separately smaller parts of large software systems dates back to the early days of software engineering. In June 1956, H.D. Benington presented at US Navy's Symposium on Advanced Programming Methods for Digital Computers the SAGE project and its specification based approach where the coding phase was followed by "parameter testing" to validate component subprograms against their specification, followed then by an "assembly testing" for parts put together.[2][3]

In 1964, a similar approach is described for the software of the Mercury project, where individual units developed by different programmes underwent "unit tests" before being integrated together.[4] In 1969, testing methodologies appear more structured, with unit tests, component tests and integration tests with the purpose of validating individual parts written separately and their progressive assembly into larger blocks.[5] Some public standards adopted end of the 60's, such as MIL-STD-483[6] and MIL-STD-490 contributed further to a wide acceptance of unit testing in large projects. 

Unit testing was in those times interactive[3] or automated,[7] using either coded tests or capture and replay testing tools. In 1989, Kent Beck described a testing framework for Smalltalk (later called SUnit) in "Simple Smalltalk Testing: With Patterns". In 1997, Kent Beck and Erich Gamma developed and released JUnit, a unit test framework that became popular with Java developers.[8] Google embraced automated testing around 2005–2006.[9]

Unit is defined as a single behaviour exhibited by the system under test (SUT), usually corresponding to a requirement. While it may imply it's a function or a module (in procedural programming) or a method or a class (in object-oriented programming) it doesn't mean functions/methods, modules or classes always correspond to units. From the system-requirements perspective only the perimeter of the system is relevant, thus only entry points to externally-visible system behaviours define units.[10]

Unit tests can be performed manually or via automated test execution. Automated tests include benefits such as: running tests often, running tests without staffing cost, and consistent and repeatable testing.

Testing is often performed by the programmer who writes and modifies the code under test.
Unit testing may be viewed as part of the process of writing code.

This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (September 2019) (Learn how and when to remove this message)
During development, a programmer may code criteria, or results that are known to be good, into the test to verify the unit's correctness. 

During test execution, frameworks log tests that fail any criterion and report them in a summary. 

For this, the most commonly used approach is test - function - expected value.

A parameterized test is a test that accepts a set of values that can be used to enable the test to run with multiple, different input values. A testing framework that supports parametrized tests supports a way to encode parameter sets and to run the test with each set.

Use of parametrized tests can reduce test code duplication.

Parameterized tests are supported by TestNG, JUnit,[13] XUnit and NUnit, as well as in various JavaScript test frameworks.[citation needed]

Parameters for the unit tests may be coded manually or in some cases are automatically generated by the test framework. In recent years support was added for writing more powerful (unit) tests, leveraging the concept of theories, test cases that execute the same steps, but using test data generated at runtime, unlike regular parameterized tests that use the same execution steps with input sets that are pre-defined.[citation needed]

Sometimes, in the agile software development, unit testing is done per user story and comes in the later half of the sprint after requirements gathering and development are complete. Typically, the developers or other members from the development team, such as consultants, will write step-by-step 'test scripts' for the developers to execute in the tool. Test scripts are generally written to prove the effective and technical operation of specific developed features in the tool, as opposed to full fledged business processes that would be interfaced by the end user, which is typically done during user acceptance testing. If the test-script can be fully executed from start to finish without incident, the unit test is considered to have "passed", otherwise errors are noted and the user story is moved back to development in an 'in-progress' state. User stories that successfully pass unit tests are moved on to the final steps of the sprint - Code review, peer review, and then lastly a 'show-back' session demonstrating the developed tool to stakeholders.

In test-driven development (TDD), unit tests are written while the production code is written. Starting with working code, the developer adds test code for a required behavior, then adds just enough code to make the test pass, then refactors the code (including test code) as makes sense and then repeats by adding another test.

Unit testing is intended to ensure that the units meet their design and behave as intended.[14]

By writing tests first for the smallest testable units, then the compound behaviors between those, one can build up comprehensive tests for complex applications.[14]

One goal of unit testing is to isolate each part of the program and show that the individual parts are correct.[1] A unit test provides a strict, written contract that the piece of code must satisfy.

Unit testing finds problems early in the development cycle. This includes both bugs in the programmer's implementation and flaws or missing parts of the specification for the unit. The process of writing a thorough set of tests forces the author to think through inputs, outputs, and error conditions, and thus more crisply define the unit's desired behavior.[citation needed]

The cost of finding a bug before coding begins or when the code is first written is considerably lower than the cost of detecting, identifying, and correcting the bug later. Bugs in released code may also cause costly problems for the end-users of the software.[15][16][17] Code can be impossible or difficult to unit test if poorly written, thus unit testing can force developers to structure functions and objects in better ways.

Unit testing enables more frequent releases in software development. By testing individual components in isolation, developers can quickly identify and address issues, leading to faster iteration and release cycles.[18]

Unit testing allows the programmer to refactor code or upgrade system libraries at a later date, and make sure the module still works correctly (e.g., in regression testing). The procedure is to write test cases for all functions and methods so that whenever a change causes a fault, it can be identified quickly. 

Unit tests detect changes which may break a design contract.

Unit testing may reduce uncertainty in the units themselves and can be used in a bottom-up testing style approach. By testing the parts of a program first and then testing the sum of its parts, integration testing becomes much easier.[citation needed]

Some programmers contend that unit tests provide a form of documentation of the code. Developers wanting to learn what functionality is provided by a unit, and how to use it, can review the unit tests to gain an understanding of it.[citation needed]

Test cases can embody characteristics that are critical to the success of the unit. These characteristics can indicate appropriate/inappropriate use of a unit as well as negative behaviors that are to be trapped by the unit. A test case documents these critical characteristics, although many software development environments do not rely solely upon code to document the product in development.[citation needed]

In some processes, the act of writing tests and the code under test, plus associated refactoring, may take the place of formal design. Each unit test can be seen as a design element specifying classes, methods, and observable behavior.[citation needed]

Testing will not catch every error in the program, because it cannot evaluate every execution path in any but the most trivial programs. This problem is a superset of the halting problem, which is undecidable. The same is true for unit testing. Additionally, unit testing by definition only tests the functionality of the units themselves. Therefore, it will not catch integration errors or broader system-level errors (such as functions performed across multiple units, or non-functional test areas such as performance). Unit testing should be done in conjunction with other software testing activities, as they can only show the presence or absence of particular errors; they cannot prove a complete absence of errors. To guarantee correct behavior for every execution path and every possible input, and ensure the absence of errors, other techniques are required, namely the application of formal methods to prove that a software component has no unexpected behavior.[citation needed]

An elaborate hierarchy of unit tests does not equal integration testing. Integration with peripheral units should be included in integration tests, but not in unit tests.[citation needed] Integration testing typically still relies heavily on humans testing manually; high-level or global-scope testing can be difficult to automate, such that manual testing often appears faster and cheaper.[citation needed]

Software testing is a combinatorial problem. For example, every Boolean decision statement requires at least two tests: one with an outcome of "true" and one with an outcome of "false". As a result, for every line of code written, programmers often need 3 to 5 lines of test code.[citation needed] This obviously takes time and its investment may not be worth the effort. There are problems that cannot easily be tested at all – for example those that are nondeterministic or involve multiple threads. In addition, code for a unit test is as likely to be buggy as the code it is testing. Fred Brooks in The Mythical Man-Month quotes: "Never go to sea with two chronometers; take one or three."[19] Meaning, if two chronometers contradict, how do you know which one is correct?

Another challenge related to writing the unit tests is the difficulty of setting up realistic and useful tests. It is necessary to create relevant initial conditions so the part of the application being tested behaves like part of the complete system. If these initial conditions are not set correctly, the test will not be exercising the code in a realistic context, which diminishes the value and accuracy of unit test results.[citation needed]

To obtain the intended benefits from unit testing, rigorous discipline is needed throughout the software development process.

It is essential to keep careful records not only of the tests that have been performed, but also of all changes that have been made to the source code of this or any other unit in the software. Use of a version control system is essential. If a later version of the unit fails a particular test that it had previously passed, the version-control software can provide a list of the source code changes (if any) that have been applied to the unit since that time.[citation needed]

It is also essential to implement a sustainable process for ensuring that test case failures are reviewed regularly and addressed immediately.[20] If such a process is not implemented and ingrained into the team's workflow, the application will evolve out of sync with the unit test suite, increasing false positives and reducing the effectiveness of the test suite.

Unit testing embedded system software presents a unique challenge: Because the software is being developed on a different platform than the one it will eventually run on, you cannot readily run a test program in the actual deployment environment, as is possible with desktop programs.[21]

Unit tests tend to be easiest when a method has input parameters and some output. It is not as easy to create unit tests when a major function of the method is to interact with something external to the application. For example, a method that will work with a database might require a mock up of database interactions to be created, which probably won't be as comprehensive as the real database interactions.[22][better source needed]

Below is an example of a JUnit test suite. It focuses on the Adder class.

The test suite uses assert statements to verify the expected result of various input values to the sum method.

This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (September 2019) (Learn how and when to remove this message)
Using unit-tests as a design specification has one significant advantage over other design methods: The design document (the unit-tests themselves) can itself be used to verify the implementation. The tests will never pass unless the developer implements a solution according to the design.

Unit testing lacks some of the accessibility of a diagrammatic specification such as a UML diagram, but they may be generated from the unit test using automated tools. Most modern languages have free tools (usually available as extensions to IDEs). Free tools, like those based on the xUnit framework, outsource to another system the graphical rendering of a view for human consumption.

Unit testing is the cornerstone of extreme programming, which relies on an automated unit testing framework. This automated unit testing framework can be either third party, e.g., xUnit, or created within the development group.

Extreme programming uses the creation of unit tests for test-driven development. The developer writes a unit test that exposes either a software requirement or a defect. This test will fail because either the requirement isn't implemented yet, or because it intentionally exposes a defect in the existing code. Then, the developer writes the simplest code to make the test, along with other tests, pass.

Most code in a system is unit tested, but not necessarily all paths through the code. Extreme programming mandates a "test everything that can possibly break" strategy, over the traditional "test every execution path" method. This leads developers to develop fewer tests than classical methods, but this isn't really a problem, more a restatement of fact, as classical methods have rarely ever been followed methodically enough for all execution paths to have been thoroughly tested.[citation needed] Extreme programming simply recognizes that testing is rarely exhaustive (because it is often too expensive and time-consuming to be economically viable) and provides guidance on how to effectively focus limited resources.

Crucially, the test code is considered a first class project artifact in that it is maintained at the same quality as the implementation code, with all duplication removed. Developers release unit testing code to the code repository in conjunction with the code it tests. Extreme programming's thorough unit testing allows the benefits mentioned above, such as simpler and more confident code development and refactoring, simplified code integration, accurate documentation, and more modular designs. These unit tests are also constantly run as a form of regression test.

Unit testing is also critical to the concept of Emergent Design. As emergent design is heavily dependent upon refactoring, unit tests are an integral component.[citation needed]

An automated testing framework provides features for automating test execution and can accelerate writing and running tests. Frameworks have been developed for a wide variety of programming languages.

Generally, frameworks are third-party; not distributed with a compiler or integrated development environment (IDE). 

Tests can be written without using a framework to exercise the code under test using assertions, exception handling, and other control flow mechanisms to verify behavior and report failure. Some note that testing without a framework is valuable since there is a barrier to entry for the adoption of a framework; that having some tests is better than none, but once a framework is in place, adding tests can be easier.[23]

In some frameworks advanced test features are missing and must be hand-coded.

Some programming languages directly support unit testing. Their grammar allows the direct declaration of unit tests without importing a library (whether third party or standard). Additionally, the Boolean conditions of the unit tests can be expressed in the same syntax as Boolean expressions used in non-unit test code, such as what is used for if and while statements.

Languages with built-in unit testing support include:

Cobra
D[24]
Rust[25]
Languages with standard unit testing framework support include:

Apex
Crystal[26]
Erlang
Go[27]
Julia[28]
LabVIEW
MATLAB
Python[29]
Racket[30][31]
Ruby[32]
Some languages do not have built-in unit-testing support but have established unit testing libraries or frameworks. These languages include:

ABAP
C++
C#
Clojure[33]
Elixir
Java
JavaScript
Objective-C
Perl
PHP
PowerShell[34]
R with testthat
Scala
tcl
Visual Basic .NET
Xojo with XojoUnit
Acceptance testing
Characterization test
Component-based usability testing
Design predicates
Design by contract
Extreme programming
Functional testing
Integration testing
List of unit testing frameworks
Regression testing
Software archaeology
Software testing
System testing
Test case
Test-driven development
xUnit – a family of unit testing frameworks.
Unit testingExtreme programmingTypes of tools used in software development
CS1 maint: date and yearArticles with short descriptionShort description is different from WikidataUse dmy dates from April 2020Articles needing additional references from September 2019All articles needing additional referencesArticles with excerptsAll articles with unsourced statementsArticles with unsourced statements from November 2023Articles with unsourced statements from January 2013Articles with unsourced statements from September 2019Articles with unsourced statements from October 2010Articles with unsourced statements from January 2010All articles lacking reliable referencesArticles lacking reliable references from February 2019Articles with unsourced statements from November 2008Articles with example Java code






# User_story.md




(Top)





1
History








2
Principle




Toggle Principle subsection





2.1
Common templates










3
Examples








4
Usage




Toggle Usage subsection





4.1
Acceptance criteria










5
Benefits








6
Limitations








7
Relationship to epics, themes and initiatives/programs




Toggle Relationship to epics, themes and initiatives/programs subsection





7.1
Theme








7.2
Initiative








7.3
Epic










8
Story map








9
User journey map








10
Comparing with use cases








11
See also








12
References








13
Further reading












2.1
Common templates














4.1
Acceptance criteria
















7.1
Theme








7.2
Initiative








7.3
Epic
























Some of this article's listed sources may not be reliable. Please help improve this article by looking for better, more reliable sources. Unreliable citations may be challenged and removed. (August 2017) (Learn how and when to remove this message)


Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
In software development and product management, a user story is an informal, natural language description of features of a software system. They are written from the perspective of an end user or user of a system, and may be recorded on index cards, Post-it notes, or digitally in specific management software.[1] Depending on the product, user stories may be written by different stakeholders like client, user, manager, or development team.

User stories are a type of boundary object. They facilitate sensemaking and communication; and may help software teams document their understanding of the system and its context.[2]

1997: Kent Beck introduces user stories at the Chrysler C3 project in Detroit.
1998: Alistair Cockburn visited the C3 project and coined the phrase "A user story is a promise for a conversation."[3]
1999: Kent Beck published the first edition of the book Extreme Programming Explained, introducing Extreme Programming (XP),[4] and the usage of user stories in the planning game.
2001: Ron Jeffries proposed a "Three Cs" formula for user story creation:[5]
The Card (or often a post-it note) is a tangible physical token to hold the concepts;
The Conversation is between the stakeholders (customers, users, developers, testers, etc.). It is verbal and often supplemented by documentation;
The Confirmation ensures that the objectives of the conversation have been reached.
2001: The XP team at Connextra[6] in London devised the user story format and shared examples with others.
2004: Mike Cohn generalized the principles of user stories beyond the usage of cards in his book User Stories Applied: For Agile Software Development[7] that is now considered the standard reference for the topic according to Martin Fowler.[8] Cohn names Rachel Davies as the inventor of user stories.[citation needed] While Davies was a team member at Connextra she credits the team as a whole with the invention.[citation needed]
2014: After a first article in 2005[9] and a blog post in 2008,[10] in 2014 Jeff Patton published the user-story mapping technique, which intends to improve with a systematic approach the identification of user stories and to structure the stories to give better visibility to their interdependence.[11]
The Card (or often a post-it note) is a tangible physical token to hold the concepts;
The Conversation is between the stakeholders (customers, users, developers, testers, etc.). It is verbal and often supplemented by documentation;
The Confirmation ensures that the objectives of the conversation have been reached.
User stories are written by or for users or customers to influence the functionality of the system being developed. In some teams, the product manager (or product owner in Scrum), is primarily responsible for formulating user stories and organizing them into a product backlog. In other teams, anyone can write a user story. User stories can be developed through discussion with stakeholders, based on personas or are simply made up.

User stories may follow one of several formats or templates.

The most common is the Connextra template, stated below.[12][7][13] Mike Cohn suggested the "so that" clause is optional although still often helpful.[14]

Chris Matts suggested that "hunting the value" was the first step in successfully delivering software, and proposed this alternative:[15]

Another template based on the Five Ws specifies:[16]

A template that's commonly used to improve security is called the "Evil User Story" or "Abuse User Story" and is used as a way to think like a hacker in order to consider scenarios that might occur in a cyber-attack. These stories are written from the perspective of an attacker attempting to compromise or damage the application, rather the typical personae found in a user story:[17]

A central part of many agile development methodologies, such as in extreme programming's planning game, user stories describe what may be built in the software product. User stories are prioritized by the customer (or the product owner in Scrum) to indicate which are most important for the system and will be broken down into tasks and estimated by the developers. One way of estimating is via a Fibonacci scale.

When user stories are about to be implemented, the developers should have the possibility to talk to the customer about it. The short stories may be
difficult to interpret, may require some background knowledge or the requirements may have changed since the story was written.

User stories can be expanded to add detail based on these conversations. This can include notes, attachments and acceptance criteria.

Mike Cohn defines acceptance criteria as "notes about what the story must do in order for the product owner to accept it as complete."[20] They define the boundaries of a user story and are used to confirm when a story is completed and working as intended.

The appropriate amount of information to be included in the acceptance criteria varies by team, program and project. Some may include 'predecessor criteria', "The user has already logged in and has already edited his information once".[This quote needs a citation] Some may write the acceptance criteria in typical agile format, Given-When-Then. Others may simply use bullet points taken from original requirements gathered from customers or stakeholders.[20]
In order for a story to be considered done or complete, all acceptance criteria must be met.

There is no good evidence that using user stories increases software success or developer productivity. However, user stories facilitate sensemaking without undue problem structuring, which is linked to success.[21]

Limitations of user stories include:

Scale-up problem: User stories written on small physical cards are hard to maintain, difficult to scale to large projects and troublesome for geographically distributed teams.
Vague, informal and incomplete: User story cards are regarded as conversation starters. Being informal, they are open to many interpretations. Being brief, they do not state all of the details necessary to implement a feature. Stories are therefore inappropriate for reaching formal agreements or writing legal contracts.[22]
Lack of non-functional requirements: User stories rarely include performance or non-functional requirement details, so non-functional tests (e.g. response time) may be overlooked.
Don't necessarily represent how technology has to be built: Since user stories are often written from the business perspective, once a technical team begins to implement, it may find that technical constraints require effort which may be broader than the scope of an individual story. Sometimes splitting stories into smaller ones can help resolve this. Other times, 'technical-only' stories are most appropriate. These 'technical-only' stories may be challenged by the business stakeholders as not delivering value that can be demonstrated to customers/stakeholders.
In many contexts, user stories are used and also summarized in groups for ontological, semantic and organizational reasons. Initiative is also referred to as Program in certain scaled agile frameworks. The different usages depend on the point-of-view, e.g. either looking from a user perspective as product owner in relation to features or a company perspective in relation to task organization.

While some suggest to use 'epic' and 'theme' as labels for any thinkable kind of grouping of user stories, organization management tends to use it for strong structuring and uniting work loads. For instance, Jira seems to use a hierarchically organized to-do-list, in which they named the first level of to-do-tasks 'user-story', the second level 'epics' (grouping of user stories) and the third level 'initiatives' (grouping of epics). However, initiatives are not always present in product management development and just add another level of granularity. In Jira, 'themes' exist (for tracking purposes) that allow to cross-relate and group items of different parts of the fixed hierarchy.[23][24]

In this usage, Jira shifts the meaning of themes in an organization perspective: e.g how much time did we spent on developing theme "xyz". But another definition of themes is: a set of stories, epics, features etc for a user that forms a common semantic unit or goal. There is probably not a common definition because different approaches exist for different styles of product design and development. In this sense, some also suggest to not use any kind of hard groups and hierarchies.[25][26][27][28][29][30]

Multiple epics or many very large stories that are closely related are summarized as themes. A common explanation of epics is also: so much work that requires many sprints, or in scaled frameworks -- a Release Train or Solution Train.

Multiple themes, epics, or stories grouped together hierarchically.[31]

Multiple themes or stories grouped together by ontology and/or semantic relationship.

A story map[32] organises user stories according to a narrative flow that presents the big picture of the product. The technique was developed by Jeff Patton from 2005 to 2014 to address the risk of projects flooded with very detailed user stories that distract from realizing the product's main objectives.[citation needed]

User story mapping[33] uses workshops with users to identify first the main business activities. Each of these main activities may involve several kind of users or personas.

The horizontal cross-cutting narrative line is then drawn by identifying the main tasks of the individual user involved in these business activities. The line is kept throughout the project. More detailed user stories are gathered and collected as usual with the user story practice. But each new user story is either inserted into the narrative flow or related vertically to a main tasks.

The horizontal axis corresponds to the coverage of the product objectives, and the vertical axis to the needs of the individual users.

In this way it becomes possible to describe even large systems without losing the big picture.

Story maps can easily provide a two-dimensional graphical visualization of the product backlog: At the top of the map are the headings under which stories are grouped, usually referred to as 'epics' (big coarse-grained user stories), 'themes' (collections of related user stories[34]) or 'activities'. These are identified by orienting at the user’s workflow or "the order you'd explain the behavior of the system". Vertically, below the epics, the actual story cards are allocated and ordered by priority. The first horizontal row is a "walking skeleton"[35] and below that represents increasing sophistication.[36][clarification needed]

A user journey map[37] intends to show the big picture but for a single user category. Its narrative line focuses on the chronology of phases and actions that a single user has to perform in order to achieve his or her objectives.

This allows to map the user experience beyond a set of user stories. Based on user feedback, the positive and negative emotions can be identified across the journey. Points of friction or unfulfilled needs can be identified on the map. This technique is used to improve the design of a product,[38] allowing to engage users in participatory approaches.[39]

A use case has been described as "a generalized description of a set of interactions between the system and one or more actors, where an actor is either a user or another system."[40] While user stories and use cases have some similarities, there are several differences between them.




User Stories

Use Cases


Similarities


Generally formulated in users' everyday language. They should help the reader understand what the software should accomplish.


Written in users' everyday business language, to facilitate stakeholder communications.


Differences


Provide a small-scale and easy-to-use presentation of information, with little detail, thus remaining open to interpretation, through conversations with on-site customers.


Use cases organize requirements to form a narrative of how users relate to and use a system. Hence they focus on user goals and how interacting with a system satisfies the goals.[41]
Use case flows describe sequences of interactions, and may be worded in terms of a formal model. A use case is intended to provide sufficient detail for it to be understood on its own.


Template

As a , I can  so that .[19]


Title: "goal the use case is trying to satisfy"
Main Success Scenario: numbered list of steps
Step: "a simple statement of the interaction between the actor and a system"
Extensions: separately numbered lists, one per Extension
Extension: "a condition that results in different interactions from .. the main success scenario". An extension from main step 3 is numbered 3a, etc.

Generally formulated in users' everyday language. They should help the reader understand what the software should accomplish.
Written in users' everyday business language, to facilitate stakeholder communications.
Provide a small-scale and easy-to-use presentation of information, with little detail, thus remaining open to interpretation, through conversations with on-site customers.
Use cases organize requirements to form a narrative of how users relate to and use a system. Hence they focus on user goals and how interacting with a system satisfies the goals.[41]
Use case flows describe sequences of interactions, and may be worded in terms of a formal model. A use case is intended to provide sufficient detail for it to be understood on its own.
Title: "goal the use case is trying to satisfy"
Main Success Scenario: numbered list of steps
Step: "a simple statement of the interaction between the actor and a system"
Extensions: separately numbered lists, one per Extension
Extension: "a condition that results in different interactions from .. the main success scenario". An extension from main step 3 is numbered 3a, etc.
Step: "a simple statement of the interaction between the actor and a system"
Extension: "a condition that results in different interactions from .. the main success scenario". An extension from main step 3 is numbered 3a, etc.
Kent Beck, Alistair Cockburn, Martin Fowler and others discussed this topic further on the c2.com wiki (the home of extreme programming).[42]

Kanban board
Persona (user experience)
Scenario (computing)
Use case
Software requirementsExtreme programmingAgile software development
CS1 maint: location missing publisherCS1 errors: generic nameCS1 errors: missing periodicalArticles with short descriptionShort description is different from WikidataArticles lacking reliable references from August 2017All articles lacking reliable referencesUse dmy dates from May 2021All articles with unsourced statementsArticles with unsourced statements from April 2020Articles with unsourced quotesArticles with unsourced statements from August 2020Wikipedia articles needing clarification from April 2014






# V-model_(software_development).md




(Top)





1
Project definition phases




Toggle Project definition phases subsection





1.1
Requirements analysis








1.2
System design








1.3
Architecture design








1.4
Module design










2
Validation phases




Toggle Validation phases subsection





2.1
Unit testing








2.2
Integration testing








2.3
System testing








2.4
User acceptance testing










3
Criticism








4
Current state








5
See also








6
References








7
Further reading










1.1
Requirements analysis








1.2
System design








1.3
Architecture design








1.4
Module design


















2.1
Unit testing








2.2
Integration testing








2.3
System testing








2.4
User acceptance testing
























This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "V-model" software development – news · newspapers · books · scholar · JSTOR (September 2018) (Learn how and when to remove this message)
Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
In software development, the V-model[2] represents a development process that may be considered an extension of the waterfall model and is an example of the more general V-model. Instead of moving down linearly, the process steps are bent upwards after the coding phase, to form the typical V shape. The V-Model demonstrates the relationships between each phase of the development life cycle and its associated phase of testing. The horizontal and vertical axes represent time or project completeness (left-to-right) and level of abstraction (coarsest-grain abstraction uppermost), respectively.

In the requirements analysis phase, the first step in the verification process, the requirements of the system are collected by analyzing the needs of the user(s). This phase is concerned with establishing what the ideal system has to perform. However, it does not determine how the software will be designed or built. Usually, the users are interviewed and a document called the user requirements document is generated.

The user requirements document will typically describe the system's functional, interface, performance, data, security, etc. requirements as expected by the user. It is used by business analysts to communicate their understanding of the system to the users. The users carefully review this document as this document would serve as the guideline for the system designers in the system design phase. The user acceptance tests are designed in this phase. See also Functional requirements.

There are different methods for gathering requirements of both soft and hard methodologies including; interviews, questionnaires, document analysis, observation, throw-away prototypes, use case, and static and dynamic views with users.

Systems design is the phase where system engineers analyze and understand the business of the proposed system by studying the user requirements document. They figure out possibilities and techniques by which the user requirements can be implemented. If any of the requirements are not feasible, the user is informed of the issue. A resolution is found and the user requirement document is edited accordingly.

The software specification document which serves as a blueprint for the development phase is generated. This document contains the general system organization, menu structures, data structures etc. It may also hold example business scenarios, sample windows, and reports to aid understanding. Other technical documentation like entity diagrams, and data dictionaries will also be produced in this phase. The documents for system testing are prepared.

The phase of the design of computer architecture and software architecture can also be referred to as high-level design. The baseline in selecting the architecture is that it should realize all which typically consists of the list of modules, brief functionality of each module, their interface relationships, dependencies, database tables, architecture diagrams, technology details, etc. The integration testing design is carried out in the particular phase.[3]

The module design phase can also be referred to as low-level design. The designed system is broken up into smaller units or modules and each of them is explained so that the programmer can start coding directly.
The low-level design document or program specifications will contain a detailed functional logic of the module, in pseudocode:

database tables, with all elements, including their type and size
all interface details with complete API references
all dependency issues
error message listings
complete input and outputs for a module.
The unit test design is developed in this stage.

In the V-model, each stage of the verification phase has a corresponding stage in the validation phase.[4] The following are the typical phases of validation in the V-Model, though they may be known by other names.

In the V-Model, Unit Test Plans (UTPs) are developed during the module design phase. These UTPs are executed to eliminate bugs at the code level or unit level. A unit is the smallest entity that can independently exist, e.g. a program module. Unit testing verifies that the smallest entity can function correctly when isolated from the rest of the codes/units.

Integration Test Plans are developed during the Architectural Design Phase. These tests verify that units created and tested independently can coexist and communicate among themselves. Test results are shared with the customer's team.

System Tests Plans are developed during the System Design Phase. Unlike Unit and Integration Test Plans, System Test Plans are composed by the client's business team. System Test ensures that expectations from the application developed are met. The whole application is tested for its functionality, interdependency, and communication. System Testing verifies that functional and non-functional requirements have been met. Load and performance testing, stress testing, regression testing, etc., are subsets of system testing.

User Acceptance Test (UAT) Plans are developed during the Requirements Analysis phase. Test Plans are composed by business users. UAT is performed in a user environment that resembles the production environment, using realistic data. UAT verifies that the delivered system meets the user's requirement and the system is ready for use in real-time.

The V-Model has been criticized by Agile advocates and others as an inadequate model of software development for numerous reasons.[5][6][7] Criticisms include:

It is too simple to accurately reflect the software development process, and can lead managers into a false sense of security. The V-Model reflects a project management view of software development and fits the needs of project managers, accountants and lawyers rather than software developers or users.
Although it is easily understood by novices, that early understanding is useful only if the novice goes on to acquire a deeper understanding of the development process and how the V-Model must be adapted and extended in practice. If practitioners persist with their naive view of the V-Model they will have great difficulty applying it successfully.
It is inflexible and encourages a rigid and linear view of software development and has no inherent ability to respond to change.
It provides only a slight variant on the waterfall model and is therefore subject to the same criticisms as that model. It provides greater emphasis on testing, and particularly the importance of early test planning. However, a common practical criticism of the V-Model is that it leads to testing being squeezed into tight windows at the end of development when earlier stages have overrun but the implementation date remains fixed.
It is consistent with, and therefore implicitly encourages, inefficient and ineffective approaches to testing. It implicitly promotes writing test scripts in advance rather than exploratory testing; it encourages testers to look for what they expect to find, rather than discover what is truly there. It also encourages a rigid link between the equivalent levels of either leg (e.g. user acceptance test plans being derived from user requirements documents), rather than encouraging testers to select the most effective and efficient way to plan and execute testing.
It lacks coherence and precision. There is widespread confusion about what exactly the V-Model is. If one boils it down to those elements that most people would agree upon it becomes a trite and unhelpful representation of software development. Disagreement about the merits of the V-Model often reflects a lack of shared understanding of its definition.
Supporters of the V-Model argue that it has evolved and supports flexibility and agility throughout the development process.[8] They argue that in addition to being a highly disciplined approach, it promotes meticulous design, development, and documentation necessary to build stable software products. Lately, it is being adopted by the medical device industry.[9][10]

Product lifecycle management
Systems development life cycle
Software development process
Webarchive template wayback linksArticles with short descriptionShort description matches WikidataArticles needing additional references from September 2018All articles needing additional referencesCommons category link is locally definedModule:Interwiki extra: additional interwiki links






# Velocity_(software_development).md




(Top)





1
Principle








2
Terminology








3
Criticism








4
References














This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Velocity" software development – news · newspapers · books · scholar · JSTOR (May 2018) (Learn how and when to remove this message)
Part of a series onSoftware development
Core activities
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance

Paradigms and models
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall

Methodologies and frameworks
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP

Supporting disciplines
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience

Practices
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD

Tools
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code

Standards and bodies of knowledge
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG

Glossaries
Artificial intelligence
Computer science
Electrical and electronics engineering

Outlines
Outline of software development
vte
Data modeling
Processes
Requirements
Design
Construction
Engineering
Testing
Debugging
Deployment
Maintenance
Agile
Cleanroom
Incremental
Prototyping
Spiral
V model
Waterfall
ASD
DevOps
DAD
DSDM
FDD
IID
Kanban
Lean SD
LeSS
MDD
MSF
PSP
RAD
RUP
SAFe
Scrum
SEMAT
TDD
TSP
UP
XP
Configuration management
 Deployment management
Documentation
Software quality assurance
Project management
User experience
ATDD
BDD
CCO
CI
CD
DDD
PP
SBE
Stand-up
TDD
Compiler
Debugger
Profiler
GUI designer
UML Modeling
IDE
Build automation
Release automation
Infrastructure as code
CMMI
IEEE standards
ISO 9001
ISO/IEC standards
PMBOK
SWEBOK
ITIL
IREB
OMG
Artificial intelligence
Computer science
Electrical and electronics engineering
Outline of software development
vte
Velocity is a metric for work done, which is often used in agile software development.[1]

Measuring velocity is sometimes called velocity tracking.[citation needed] The velocity metric is used for planning sprints and measuring team performance.

The main idea behind velocity is to help teams estimate how much work they can complete in a given time period based on how quickly similar work was previously completed.[2] Velocity is relative measure. In other words, the raw numbers mean little; it is the trend that matters.[3]

The following terminology is used in velocity tracking.

One problem with velocity is that it conflates work done with planning accuracy. In other words, a team can inflate velocity by estimating tasks more conservatively. If a team says that a task will take four hours or is worth 4 points instead of taking two hours or being worth two points, their velocity will look better (sometimes called point inflation).[5][1]

A second problem with velocity is that it does not take quality, alignment with user goals or priority into account. Velocity can be increased by neglecting good design, refactoring, coding standards and technical debt. Simply completing features as quickly as possible increases velocity regardless of quality. Similarly, velocity includes work done regardless of the benefits of that work. For example, building a feature no one wants or needs still counts as "work done” and completing a work unit which moves away from a user goal such as ease of use is movement in the opposite of the direction desired.[citation needed]

A third problem with velocity is that it is often misused as a measure of efficiency or team performance. Velocity is a metric of work done, not efficiency. Velocity can be increased by working overtime or adding team members, neither of which necessarily increase efficiency or performance.[citation needed]

Agile software development
Articles needing additional references from May 2018All articles needing additional referencesAll articles with unsourced statementsArticles with unsourced statements from October 2018Articles with unsourced statements from May 2018






# Waterfall_model.md




(Top)





1
History








2
Model








3
Supporting arguments








4
Criticism








5
Modified waterfall models








6
Royce's final model








7
See also








8
References








9
External links


























This article needs to be updated. Please help update this article to reflect recent events or newly available information. (October 2021)
The waterfall model is a breakdown of development activities into linear sequential phases, meaning they are passed down onto each other, where each phase depends on the deliverables of the previous one and corresponds to a specialization of tasks.[1]
The approach is typical for certain areas of engineering design. In software development,[1]
it tends to be among the less iterative and flexible approaches, as progress flows in largely one direction (downwards like a waterfall) through the phases of conception, initiation, analysis, design, construction, testing, deployment and maintenance.[2]
The waterfall model is the earliest SDLC approach that was used in software development.[3]

The waterfall development model originated in the manufacturing and construction industries,[citation needed] where the highly structured physical environments meant that design changes became prohibitively expensive much sooner in the development process.[citation needed]
When first adopted for software development, there were no recognized alternatives for knowledge-based creative work.[4]

The first known presentation describing use of such phases in software engineering was held by Herbert D. Benington at the Symposium on Advanced Programming Methods for Digital Computers on 29 June 1956.[5]
This presentation was about the development of software for SAGE. In 1983 the paper was republished with a foreword by Benington explaining that the phases were on purpose organized according to the specialization of tasks, and pointing out that the process was not in fact performed in a strict top-down fashion, but depended on a prototype.[6][better source needed]

Although the term "waterfall" is not used in the paper, the first formal detailed diagram of the process later known as the "waterfall model" is often[7] cited as a 1970 article by Winston W. Royce.[8][9][10] However, he also felt it had major flaws stemming from the fact that testing only happened at the end of the process, which he described as being "risky and invites failure".[8] The rest of his paper introduced five steps which he felt were necessary to "eliminate most of the development risks" associated with the unaltered waterfall approach.[8]

Royce's five additional steps (which included writing complete documentation at various stages of development) never took mainstream hold, but his diagram of what he considered a flawed process became the starting point when describing a "waterfall" approach.[11]
[12]

The earliest use of the term "waterfall" may have been in a 1976 paper by Bell and Thayer.[13][better source needed]

In 1985, the United States Department of Defense adopted the waterfall model in the DOD-STD-2167 standard for working with software development contractors. This standard referred for iterations of a software development[14] to "the sequential phases of a software development cycle" and stated that "the contractor shall implement a software development cycle that includes the following six phases: Software Requirement Analysis, Preliminary Design, Detailed Design, Coding and Unit Testing, Integration, and Testing".[14][15]

Although Royce never recommended nor described a waterfall model,[16] rigid adherence to the following phases are criticized by him:

System and software requirements: captured in a product requirements document
Analysis: resulting in models, schema, and business rules
Design: resulting in the software architecture
Coding: the development, proving, and integration of software
Testing: the systematic discovery and debugging of defects
Operations: the installation, migration, support, and maintenance of complete systems
Thus the waterfall model maintains that one should move to a phase only when its preceding phase is reviewed and verified.

Various modified waterfall models (including Royce's final model), however, can include slight or major variations on this process.[8] These variations included returning to the previous cycle after flaws were found downstream, or returning all the way to the design phase if downstream phases deemed insufficient.

Time spent early in the software production cycle can reduce costs at later stages. For example, a problem found in the early stages (such as requirements specification) is cheaper to fix than the same bug found later on in the process (by a factor of 50 to 200).[17]

In common practice, waterfall methodologies result in a project schedule with 20–40% of the time invested for the first two phases, 30–40% of the time to coding, and the rest dedicated to testing and implementation. The actual project organization needs to be highly structured. Most medium and large projects will include a detailed set of procedures and controls, which regulate every process on the project.[18][failed verification]

A further argument for the waterfall model is that it places emphasis on documentation (such as requirements documents and design documents) as well as source code.[citation needed] In less thoroughly designed and documented methodologies, knowledge is lost if team members leave before the project is completed, and it may be difficult for a project to recover from the loss. If a fully working design document is present (as is the intent of big design up front and the waterfall model), new team members or even entirely new teams should be able to familiarise themselves by reading the documents.[19]

The waterfall model provides a structured approach; the model itself progresses linearly through discrete, easily understandable and explainable phases and thus is easy to understand; it also provides easily identifiable milestones in the development process. It is perhaps for this reason that the waterfall model is used as a beginning example of a development model in many software engineering texts and courses.[20]

Simulation can play a valuable role within the waterfall model. By creating computerized or mathematical simulations of the system being developed, teams can gain insights into how the system will perform before proceeding to the next phase. Simulations allow for testing and refining the design, identifying potential issues or bottlenecks, and making informed decisions about the system's functionality and performance.

Clients may not know exactly what their requirements are before they see working software and so change their requirements, leading to redesign, redevelopment, and retesting, and increased costs.[21]

Designers may not be aware of future difficulties when designing a new software product or feature, in which case it is better to revise the design than persist in a design that does not account for any newly discovered constraints, requirements, or problems.[22]

Organisations may attempt to deal with a lack of concrete requirements from clients by employing systems analysts to examine existing manual systems and analyse what they do and how they might be replaced. However, in practice, it is difficult to sustain a strict separation between systems analysis and programming.[23] This is because implementing any non-trivial system will almost inevitably expose issues and edge cases that the systems analyst did not consider.

In response to the perceived problems with the pure waterfall model, modified waterfall models were introduced, such as "Sashimi (Waterfall with Overlapping Phases), Waterfall with Subprojects, and Waterfall with Risk Reduction."[17]

Some organisations, such as the United States Department of Defense, now have a stated preference against waterfall-type methodologies, starting with MIL-STD-498 released in 1994, which encourages evolutionary acquisition and Iterative and Incremental Development.[24]

In response to the perceived problems with the "pure" waterfall model, many 'modified waterfall models' have been introduced. These models may address some or all of the criticisms of the "pure" waterfall model.

These include the Rapid Development models that Steve McConnell calls "modified waterfalls":[17] Peter DeGrace's "sashimi model" (waterfall with overlapping phases), waterfall with subprojects, and waterfall with risk reduction. Other software development model combinations such as "incremental waterfall model" also exist.[25]

Winston W. Royce's final model, his intended improvement upon his initial "waterfall model", illustrated that feedback could (should, and often would) lead from code testing to design (as testing of code uncovered flaws in the design) and from design back to requirements specification (as design problems may necessitate the removal of conflicting or otherwise unsatisfiable/undesignable requirements). In the same paper Royce also advocated large quantities of documentation, doing the job "twice if possible" (a sentiment similar to that of Fred Brooks, famous for writing the Mythical Man Month, an influential book in software project management, who advocated planning to "throw one away"), and involving the customer as much as possible (a sentiment similar to that of extreme programming).

Royce notes on the final model are:

Complete program design before analysis and coding begins
Documentation must be current and complete
Do the job twice if possible
Testing must be planned, controlled, and monitored
Involve the customer
List of software development philosophies
Agile software development
Big design up front
Chaos model
DevOps
Iterative and incremental development
Monitoring Maintenance Lifecycle
Object-oriented analysis and design
Rapid application development
Software development process
Spiral model
Structured Systems Analysis and Design Method (SSADM)
System development methodology
Traditional engineering
V-model
Software development philosophiesProject managementDesign
Webarchive template wayback linksArticles with short descriptionShort description is different from WikidataEngvarB from January 2023Wikipedia articles in need of updating from October 2021All Wikipedia articles in need of updatingAll articles with unsourced statementsArticles with unsourced statements from October 2021Articles with unsourced statements from February 2021All articles lacking reliable referencesArticles lacking reliable references from March 2021All articles with failed verificationArticles with failed verification from March 2021Articles with unsourced statements from March 2021Commons category link is on Wikidata




