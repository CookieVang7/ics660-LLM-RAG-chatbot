



From Wikipedia, the free encyclopedia


Use of special software to control test execution and analysis
"Automated QA" redirects here. For the company, see [AutomatedQA](/wiki/AutomatedQA "AutomatedQA").


| Part of a series on |
| --- |
| [Software development](/wiki/Software_development "Software development") |
| Core activities * [Data modeling](/wiki/Data_modeling "Data modeling") * [Processes](/wiki/Software_development_process "Software development process") * [Requirements](/wiki/Requirements_analysis "Requirements analysis") * [Design](/wiki/Software_design "Software design") * [Construction](/wiki/Software_construction "Software construction") * [Engineering](/wiki/Software_engineering "Software engineering") * [Testing](/wiki/Software_testing "Software testing") * [Debugging](/wiki/Debugging "Debugging") * [Deployment](/wiki/Software_deployment "Software deployment") * [Maintenance](/wiki/Software_maintenance "Software maintenance") |
| Paradigms and models * [Agile](/wiki/Agile_software_development "Agile software development") * [Cleanroom](/wiki/Cleanroom_software_engineering "Cleanroom software engineering") * [Incremental](/wiki/Incremental_build_model "Incremental build model") * [Prototyping](/wiki/Software_prototyping "Software prototyping") * [Spiral](/wiki/Spiral_model "Spiral model") * [V model](/wiki/V-model_(software_development) "V-model (software development)") * [Waterfall](/wiki/Waterfall_model "Waterfall model") |
| [Methodologies](/wiki/Software_development_methodology "Software development methodology") and frameworks * [ASD](/wiki/Adaptive_software_development "Adaptive software development") * [DevOps](/wiki/DevOps "DevOps") * [DAD](/wiki/Disciplined_agile_delivery "Disciplined agile delivery") * [DSDM](/wiki/Dynamic_systems_development_method "Dynamic systems development method") * [FDD](/wiki/Feature-driven_development "Feature-driven development") * [IID](/wiki/Iterative_and_incremental_development "Iterative and incremental development") * [Kanban](/wiki/Kanban_(development) "Kanban (development)") * [Lean SD](/wiki/Lean_software_development "Lean software development") * [LeSS](/wiki/Scrum_(software_development)#Large-scale_Scrum "Scrum (software development)") * [MDD](/wiki/Model-driven_development "Model-driven development") * [MSF](/wiki/Microsoft_Solutions_Framework "Microsoft Solutions Framework") * [PSP](/wiki/Personal_software_process "Personal software process") * [RAD](/wiki/Rapid_application_development "Rapid application development") * [RUP](/wiki/Rational_Unified_Process "Rational Unified Process") * [SAFe](/wiki/Scaled_agile_framework "Scaled agile framework") * [Scrum](/wiki/Scrum_(software_development) "Scrum (software development)") * [SEMAT](/wiki/SEMAT "SEMAT") * [TDD](/wiki/Test-driven_development "Test-driven development") * [TSP](/wiki/Team_software_process "Team software process") * [OpenUP](/wiki/OpenUP "OpenUP") * [UP](/wiki/Unified_Process "Unified Process") * [XP](/wiki/Extreme_programming "Extreme programming") |
| Supporting disciplines * [Configuration management](/wiki/Software_configuration_management "Software configuration management") * [Documentation](/wiki/Software_documentation "Software documentation") * [Software quality assurance](/wiki/Software_quality_assurance "Software quality assurance") * [Project management](/wiki/Software_project_management "Software project management") * [User experience](/wiki/User_experience "User experience") |
| Practices * [ATDD](/wiki/Acceptance_test%E2%80%93driven_development "Acceptance test–driven development") * [BDD](/wiki/Behavior-driven_development "Behavior-driven development") * [CCO](/wiki/Extreme_programming_practices#Collective_code_ownership "Extreme programming practices") * [CI](/wiki/Continuous_integration "Continuous integration") * [CD](/wiki/Continuous_delivery "Continuous delivery") * [DDD](/wiki/Domain-driven_design "Domain-driven design") * [PP](/wiki/Pair_programming "Pair programming") * [SBE](/wiki/Specification_by_example "Specification by example") * [Stand-up](/wiki/Stand-up_meeting "Stand-up meeting") * [TDD](/wiki/Test-driven_development "Test-driven development") |
| [Tools](/wiki/Programming_tool "Programming tool") * [Compiler](/wiki/Compiler "Compiler") * [Debugger](/wiki/Debugger "Debugger") * [Profiler](/wiki/Profiling_(computer_programming) "Profiling (computer programming)") * [GUI designer](/wiki/Graphical_user_interface_builder "Graphical user interface builder") * [UML Modeling](/wiki/UML_tool "UML tool") * [IDE](/wiki/Integrated_development_environment "Integrated development environment") * [Build automation](/wiki/Build_automation "Build automation") * [Release automation](/wiki/Application-release_automation "Application-release automation") * [Infrastructure as code](/wiki/Infrastructure_as_code "Infrastructure as code") |
| Standards and bodies of knowledge * [CMMI](/wiki/Capability_Maturity_Model_Integration "Capability Maturity Model Integration") * [IEEE standards](/wiki/IEEE_Standards_Association "IEEE Standards Association") * [ISO 9001](/wiki/ISO_9001 "ISO 9001") * [ISO/IEC standards](/wiki/ISO/IEC_JTC_1/SC_7 "ISO/IEC JTC 1/SC 7") * [PMBOK](/wiki/Project_Management_Body_of_Knowledge "Project Management Body of Knowledge") * [SWEBOK](/wiki/Software_Engineering_Body_of_Knowledge "Software Engineering Body of Knowledge") * [ITIL](/wiki/ITIL "ITIL") * [IREB](/wiki/International_Requirements_Engineering_Board "International Requirements Engineering Board") * [OMG](/wiki/Object_Management_Group "Object Management Group") |
| Glossaries * [Artificial intelligence](/wiki/Glossary_of_artificial_intelligence "Glossary of artificial intelligence") * [Computer science](/wiki/Glossary_of_computer_science "Glossary of computer science") * [Electrical and electronics engineering](/wiki/Glossary_of_electrical_and_electronics_engineering "Glossary of electrical and electronics engineering") |
| Outlines * [Outline of software development](/wiki/Outline_of_software_development "Outline of software development") |
| * [v](/wiki/Template:Software_development_process "Template:Software development process") * [t](/wiki/Template_talk:Software_development_process "Template talk:Software development process") * [e](/wiki/Special:EditPage/Template:Software_development_process "Special:EditPage/Template:Software development process") |




|  | This article includes a list of general [references](/wiki/Wikipedia:Citing_sources "Wikipedia:Citing sources"), but **it lacks sufficient corresponding [inline citations](/wiki/Wikipedia:Citing_sources#Inline_citations "Wikipedia:Citing sources")**. Please help to [improve](/wiki/Wikipedia:WikiProject_Reliability "Wikipedia:WikiProject Reliability") this article by [introducing](/wiki/Wikipedia:When_to_cite "Wikipedia:When to cite") more precise citations. *(February 2009)* *([Learn how and when to remove this message](/wiki/Help:Maintenance_template_removal "Help:Maintenance template removal"))* |
| --- | --- |


In [software testing](/wiki/Software_testing "Software testing"), **test automation** is the use of [software](/wiki/Software "Software") separate from the software being tested to control the execution of tests and the comparison of actual outcomes with predicted outcomes.[[1]](#cite_note-1) Test automation can automate some repetitive but necessary tasks in a formalized testing process already in place, or perform additional testing that would be difficult to do manually. Test automation is critical for [continuous delivery](/wiki/Continuous_delivery "Continuous delivery") and [continuous testing](/wiki/Continuous_testing "Continuous testing").[[2]](#cite_note-2)




General approaches[[edit](/w/index.php?title=Test_automation&action=edit&section=1 "Edit section: General approaches")]
-----------------------------------------------------------------------------------------------------------------------


There are many approaches to test automation, however below are the general approaches used widely:



* **[Graphical user interface testing](/wiki/Graphical_user_interface_testing "Graphical user interface testing")**. A testing framework that generates [user interface](/wiki/Graphical_user_interface "Graphical user interface") events such as keystrokes and mouse clicks, and observes the changes that result in the user interface, to validate that the observable behavior of the program is correct.
* **[API driven testing](/wiki/API_testing "API testing")**. A testing framework that uses a programming interface to the application to validate the behaviour under test. Typically API driven testing bypasses application user interface altogether. It can also be testing [public (usually) interfaces](/wiki/Public_interface "Public interface") to classes, modules or libraries are tested with a variety of input arguments to validate that the results that are returned are correct.


Other approaches[[edit](/w/index.php?title=Test_automation&action=edit&section=2 "Edit section: Other approaches")]
-------------------------------------------------------------------------------------------------------------------


### Model-based testing[[edit](/w/index.php?title=Test_automation&action=edit&section=3 "Edit section: Model-based testing")]


Main article: [Model-based testing](/wiki/Model-based_testing "Model-based testing")
One way to generate test cases automatically is [model-based testing](/wiki/Model-based_testing "Model-based testing") through use of a model of the system for test case generation, but research continues into a variety of alternative methodologies for doing so.[*[citation needed](/wiki/Wikipedia:Citation_needed "Wikipedia:Citation needed")*] In some cases, the model-based approach enables non-technical users to create automated business test cases in plain English so that no programming of any kind is needed in order to configure them for multiple operating systems, browsers, and smart devices.[[3]](#cite_note-3)



### Regression testing[[edit](/w/index.php?title=Test_automation&action=edit&section=4 "Edit section: Regression testing")]


Some [software testing](/wiki/Software_testing "Software testing") tasks (such as extensive low-level interface [regression testing](/wiki/Regression_testing "Regression testing")) can be laborious and time-consuming to do manually. In addition, a manual approach might not always be effective in finding certain classes of defects. Test automation offers a possibility to perform these types of testing effectively.


Once automated tests have been developed, they can be run quickly and repeatedly many times. This can be a cost-effective method for regression testing of software products that have a long maintenance life. Even minor patches over the lifetime of the application can cause existing features to break which were working at an earlier point in time.



### API testing[[edit](/w/index.php?title=Test_automation&action=edit&section=5 "Edit section: API testing")]


Main article: [API testing](/wiki/API_testing "API testing")
[API testing](/wiki/API_testing "API testing") is also being widely used by software testers as it enables them to verify requirements independent of their GUI implementation, commonly to test them earlier in development, and to make sure the test itself adheres to clean code principles, especially the single responsibility principle. It involves directly testing [APIs](/wiki/API "API") as part of [integration testing](/wiki/Integration_testing "Integration testing"), to determine if they meet expectations for functionality, reliability, performance, and security.[[4]](#cite_note-reichart1-4) Since APIs lack a [GUI](/wiki/Graphical_user_interface "Graphical user interface"), API testing is performed at the [message layer](/wiki/Communications_protocol#Layering "Communications protocol").[[5]](#cite_note-stickyminds-5) API testing is considered critical when an API serves as the primary interface to [application logic](/wiki/Application_logic "Application logic").[[6]](#cite_note-6)



### Graphical user interface (GUI) testing[[edit](/w/index.php?title=Test_automation&action=edit&section=6 "Edit section: Graphical user interface (GUI) testing")]


Main article: [Graphical user interface testing](/wiki/Graphical_user_interface_testing "Graphical user interface testing")
Many test automation tools provide record and playback features that allow users to interactively record user actions and replay them back any number of times, comparing actual results to those expected. The advantage of this approach is that it requires little or no [software development](/wiki/Software_development "Software development"). This approach can be applied to any application that has a [graphical user interface](/wiki/Graphical_user_interface "Graphical user interface"). However, reliance on these features poses major reliability and maintainability problems. Relabelling a button or moving it to another part of the window may require the test to be re-recorded. Record and playback also often adds irrelevant activities or incorrectly records some activities.[*[citation needed](/wiki/Wikipedia:Citation_needed "Wikipedia:Citation needed")*]


A variation on this type of tool is for testing of web sites. Here, the "interface" is the web page. However, such a framework utilizes entirely different techniques because it is rendering [HTML](/wiki/HTML "HTML") and listening to [DOM Events](/wiki/DOM_Events "DOM Events") instead of operating system events. [Headless browsers](/wiki/Headless_browser "Headless browser") or solutions based on [Selenium Web Driver](/wiki/Selenium_(Software)#Selenium_WebDriver "Selenium (Software)") are normally used for this purpose.[[7]](#cite_note-7)[[8]](#cite_note-Headless_Testing_with_Browsers-8)[[9]](#cite_note-9)


Another variation of this type of test automation tool is for testing mobile applications. This is very useful given the number of different sizes, resolutions, and operating systems used on mobile phones. For this variation, a framework is used in order to instantiate actions on the mobile device and to gather results of the actions.


Another variation is script-less test automation that does not use record and playback, but instead builds a model[*[clarification needed](/wiki/Wikipedia:Please_clarify "Wikipedia:Please clarify")*] of the application and then enables the tester to create test cases by simply inserting test parameters and conditions, which requires no scripting skills.



Methodologies[[edit](/w/index.php?title=Test_automation&action=edit&section=7 "Edit section: Methodologies")]
-------------------------------------------------------------------------------------------------------------


### Test-driven development[[edit](/w/index.php?title=Test_automation&action=edit&section=8 "Edit section: Test-driven development")]


Test automation, mostly using unit testing, is a key feature of [extreme programming](/wiki/Extreme_programming "Extreme programming") and [agile software development](/wiki/Agile_software_development "Agile software development"), where it is known as [test-driven development](/wiki/Test-driven_development "Test-driven development") (TDD) or test-first development. Unit tests can be written to define the functionality *before* the code is written. However, these unit tests evolve and are extended as coding progresses, issues are discovered and the code is subjected to refactoring.[[10]](#cite_note-Learning_TDD-10) Only when all the tests for all the demanded features pass is the code considered complete. Proponents argue that it produces software that is both more reliable and less costly than code that is tested by manual exploration.[*[citation needed](/wiki/Wikipedia:Citation_needed "Wikipedia:Citation needed")*] It is considered more reliable because the code coverage is better, and because it is run constantly during development rather than once at the end of a [waterfall](/wiki/Waterfall_model "Waterfall model") development cycle. The developer discovers defects immediately upon making a change, when it is least expensive to fix. Finally, [code refactoring](/wiki/Code_refactoring "Code refactoring") is safer when unit testing is used; transforming the code into a simpler form with less [code duplication](/wiki/Code_duplication "Code duplication"), but equivalent behavior, is much less likely to introduce new defects when the refactored code is covered by unit tests.



### Continuous testing[[edit](/w/index.php?title=Test_automation&action=edit&section=9 "Edit section: Continuous testing")]


Main article: [Continuous testing](/wiki/Continuous_testing "Continuous testing")
[Continuous testing](/wiki/Continuous_testing "Continuous testing") is the process of executing automated tests as part of the software delivery pipeline to obtain immediate feedback on the business risks associated with a software release candidate.[[11]](#cite_note-essential-11)[[12]](#cite_note-stickym-12) For Continuous Testing, the scope of testing extends from validating bottom-up requirements or user stories to assessing the system requirements associated with overarching business goals.[[13]](#cite_note-pnsqc-13)



Considerations[[edit](/w/index.php?title=Test_automation&action=edit&section=10 "Edit section: Considerations")]
----------------------------------------------------------------------------------------------------------------


### Factors to consider for the decision to implement test automation[[edit](/w/index.php?title=Test_automation&action=edit&section=11 "Edit section: Factors to consider for the decision to implement test automation")]


What to automate, when to automate, or even whether one really needs automation are crucial decisions which the testing (or development) team must make.[[14]](#cite_note-14) A multi-vocal literature review of 52 practitioner and 26 academic sources found that five main factors to consider in test automation decision are: 1) System Under Test (SUT), 2) the types and numbers of tests, 3) test-tool, 4) human and organizational topics, and 5) cross-cutting factors. The most frequent individual factors identified in the study were: need for regression testing, economic factors, and maturity of SUT.[[15]](#cite_note-15)



### Plateau effect[[edit](/w/index.php?title=Test_automation&action=edit&section=12 "Edit section: Plateau effect")]


While the reusability of automated tests is valued by software development companies, this property can also be viewed as a disadvantage. It leads to the so-called ["Pesticide Paradox"](/wiki/Plateau_effect "Plateau effect"), where repeatedly executed scripts stop detecting errors that go beyond their frameworks. In such cases, [manual testing](/wiki/Manual_testing "Manual testing") may be a better investment. This ambiguity once again leads to the conclusion that the decision on test automation should be made individually, keeping in mind project requirements and peculiarities.



### What to test[[edit](/w/index.php?title=Test_automation&action=edit&section=13 "Edit section: What to test")]


Testing tools can help automate tasks such as product installation, test data creation, GUI interaction, problem detection (consider parsing or polling agents equipped with [test oracles](/wiki/Test_oracle "Test oracle")), defect logging, etc., without necessarily automating tests in an end-to-end fashion.


One must keep satisfying popular requirements when thinking of test automation:



* [Platform](/wiki/Computing_platform "Computing platform") and [OS](/wiki/Operating_system "Operating system") independence
* Data driven capability (Input Data, Output Data, [Metadata](/wiki/Metadata "Metadata"))
* Customization Reporting (DB [Data Base](/wiki/Data_Base "Data Base") Access, [Crystal Reports](/wiki/Crystal_Reports "Crystal Reports"))
* Easy debugging and logging
* [Version control](/wiki/Version_control "Version control") friendly – minimal binary files
* Extensible & Customization (Open [APIs](/wiki/API "API") to be able to integrate with other tools)
* Common Driver (For example, in the Java development ecosystem, that means [Ant](/wiki/Apache_Ant "Apache Ant") or [Maven](/wiki/Apache_Maven "Apache Maven") and the popular [IDEs](/wiki/Integrated_Development_Environment "Integrated Development Environment")). This enables tests to integrate with the developers' [workflows](/wiki/Workflows "Workflows").
* Support unattended test runs for integration with build processes and batch runs. [Continuous integration](/wiki/Continuous_integration "Continuous integration") servers require this.
* Email Notifications like [bounce messages](/wiki/Bounce_message "Bounce message")
* Support distributed execution environment (distributed [test bed](/wiki/Testbed "Testbed"))
* Distributed application support (distributed [SUT](/wiki/System_Under_Test "System Under Test"))


Roles[[edit](/w/index.php?title=Test_automation&action=edit&section=14 "Edit section: Roles")]
----------------------------------------------------------------------------------------------


### Test automation tools[[edit](/w/index.php?title=Test_automation&action=edit&section=15 "Edit section: Test automation tools")]


Test automation tools can be expensive and are usually employed in combination with manual testing. Test automation can be made cost-effective in the long term, especially when used repeatedly in [regression testing](/wiki/Regression_testing "Regression testing"). A good candidate for test automation is a test case for common flow of an application, as it is required to be executed (regression testing) every time an enhancement is made in the application. Test automation reduces the effort associated with manual testing. Manual effort is needed to develop and maintain automated checks, as well as reviewing test results.



### Test engineer[[edit](/w/index.php?title=Test_automation&action=edit&section=16 "Edit section: Test engineer")]


Main article: [Test engineer](/wiki/Test_engineer "Test engineer")
In automated testing, the [test engineer](/wiki/Test_engineer "Test engineer") or [software quality assurance](/wiki/Software_quality_assurance "Software quality assurance") person must have software coding ability since the test cases are written in the form of source code which when run produce output according to the [assertions](/wiki/Assertion_(computing) "Assertion (computing)") that are a part of it. Some test automation tools allow for test authoring to be done by keywords instead of coding, which do not require programming.



Testing at different levels[[edit](/w/index.php?title=Test_automation&action=edit&section=17 "Edit section: Testing at different levels")]
------------------------------------------------------------------------------------------------------------------------------------------


A strategy to decide the amount of tests to automate is the test automation pyramid. This strategy suggests to write three types of tests with different granularity. The higher the level, less is the amount of tests to write.[[16]](#cite_note-:0-16)



### Unit, service, and user interface levels[[edit](/w/index.php?title=Test_automation&action=edit&section=18 "Edit section: Unit, service, and user interface levels")]


[![](//upload.wikimedia.org/wikipedia/commons/thumb/5/54/The_test_automation_pyramid.png/220px-The_test_automation_pyramid.png)](/wiki/File:The_test_automation_pyramid.png)

The test automation pyramid proposed by Mike Cohn[[16]](#cite_note-:0-16)


* As a solid foundation, [unit testing](/wiki/Unit_testing "Unit testing") provides robustness to the software products. Testing individual parts of the code makes it easy to write and run the tests. Developers write unit tests as a part of each story and integrate them with CI.[[17]](#cite_note-17)
* The service layer refers to testing the services of an application separately from its user interface, these services are anything that the application does in response to some input or set of inputs.
* At the top level we have [UI testing](/wiki/UI_Testing "UI Testing") which has fewer tests due to the different attributes that make it more complex to run, for example the fragility of the tests, where a small change in the user interface can break a lot of tests and adds maintenance effort.[[16]](#cite_note-:0-16)[[18]](#cite_note-18)


### Unit, integration, and end-to-end levels[[edit](/w/index.php?title=Test_automation&action=edit&section=19 "Edit section: Unit, integration, and end-to-end levels")]


[![A triangular diagram depicting Google's "testing pyramid". Progresses from the smallest section "E2E" at the top, to "Integration" in the middle, to the largest section "Unit" at the bottom.](//upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Testing_Pyramid.png/220px-Testing_Pyramid.png)](/wiki/File:Testing_Pyramid.png)

Google's testing pyramid[[19]](#cite_note-:1-19)


One conception of the testing pyramid contains unit, integration, and end-to-end unit tests. According to [Google](/wiki/Google "Google")'s testing blog, unit tests should make up the majority of your testing strategy, with fewer integration tests and only a small amount of end-to-end tests.[[19]](#cite_note-:1-19)



* Unit tests: These are tests that test individual components or units of code in isolation. They are fast, reliable, and isolate failures to small units of code.
* Integration tests: These tests check how different units of code work together. Although individual units may function properly on their own, integration tests ensure that they operate together coherently.
* End-to-end tests: These test the system as a whole, simulating real-world usage scenarios. They are the slowest and most complex tests.


Framework approach in automation[[edit](/w/index.php?title=Test_automation&action=edit&section=20 "Edit section: Framework approach in automation")]
----------------------------------------------------------------------------------------------------------------------------------------------------


A test automation framework is an integrated system that sets the rules of automation of a specific product. This system integrates the function libraries, test data sources, object details and various reusable modules. These components act as small building blocks which need to be assembled to represent a business process. The framework provides the basis of test automation and simplifies the automation effort.


The main advantage of a [framework](/wiki/Software_framework "Software framework") of assumptions, concepts and tools that provide support for automated software testing is the low cost for [maintenance](/wiki/Software_maintenance "Software maintenance"). If there is change to any [test case](/wiki/Test_case "Test case") then only the test case file needs to be updated and the [driver Script](/w/index.php?title=Driver_Script&action=edit&redlink=1 "Driver Script (page does not exist)") and [startup script](/wiki/Startup_script "Startup script") will remain the same. Ideally, there is no need to update the scripts in case of changes to the application.


Choosing the right framework/scripting technique helps in maintaining lower costs. The costs associated with test scripting are due to development and maintenance efforts. The approach of scripting used during test automation has effect on costs.


Various framework/scripting techniques are generally used:



1. Linear (procedural code, possibly generated by tools like those that use record and playback)
2. Structured (uses control structures - typically ‘if-else’, ‘switch’, ‘for’, ‘while’ conditions/ statements)
3. [Data-driven](/wiki/Data-driven_testing "Data-driven testing") (data is persisted outside of tests in a database, spreadsheet, or other mechanism)
4. [Keyword-driven](/wiki/Keyword-driven_testing "Keyword-driven testing")
5. Hybrid (two or more of the patterns above are used)
6. Agile automation framework


The Testing framework is responsible for:[[20]](#cite_note-20)



1. defining the format in which to express expectations
2. creating a mechanism to hook into or drive the application under test
3. executing the tests
4. reporting results


### Unit testing frameworks[[edit](/w/index.php?title=Test_automation&action=edit&section=21 "Edit section: Unit testing frameworks")]


A growing trend in software development is the use of [unit testing](/wiki/Unit_testing "Unit testing") frameworks such as the [xUnit](/wiki/XUnit "XUnit") frameworks (for example, [JUnit](/wiki/JUnit "JUnit") and [NUnit](/wiki/NUnit "NUnit")) that allow the execution of unit tests to determine whether various sections of the [code](/wiki/Code "Code") are acting as expected under various circumstances. [Test cases](/wiki/Test_case "Test case") describe tests that need to be run on the program to verify that the program runs as expected.



### Test automation interface[[edit](/w/index.php?title=Test_automation&action=edit&section=22 "Edit section: Test automation interface")]


Test automation interfaces are platforms that provide a single [workspace](/wiki/Workspace "Workspace") for incorporating multiple testing tools and frameworks for [System/Integration testing](/wiki/System_testing "System testing") of application under test. The goal of Test Automation Interface is to simplify the process of mapping tests to business criteria without coding coming in the way of the process. Test automation interface are expected to improve the efficiency and flexibility of maintaining test scripts.[[21]](#cite_note-Interface-21)



[![](//upload.wikimedia.org/wikipedia/commons/thumb/8/89/Test_Automation_Interface.png/220px-Test_Automation_Interface.png)](/wiki/File:Test_Automation_Interface.png)

Test Automation Interface Model


Test Automation Interface consists of the following core modules:



* Interface Engine
* Interface Environment
* Object Repository


#### Interface engine[[edit](/w/index.php?title=Test_automation&action=edit&section=23 "Edit section: Interface engine")]


Interface engines are built on top of Interface Environment. Interface engine consists of a [parser](/wiki/Parser "Parser") and a test runner. The parser is present to parse the object files coming from the object repository into the test specific scripting language. The test runner executes the test scripts using a [test harness](/wiki/Test_harness "Test harness").[[21]](#cite_note-Interface-21)



#### Object repository[[edit](/w/index.php?title=Test_automation&action=edit&section=24 "Edit section: Object repository")]


Object repositories are a collection of UI/Application object data recorded by the testing tool while exploring the application under test.[[21]](#cite_note-Interface-21)



Defining boundaries between automation framework and a testing tool[[edit](/w/index.php?title=Test_automation&action=edit&section=25 "Edit section: Defining boundaries between automation framework and a testing tool")]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


Tools are specifically designed to target some particular test environment, such as Windows and web automation tools, etc. Tools serve as a driving agent for an automation process. However, an automation framework is not a tool to perform a specific task, but rather infrastructure that provides the solution where different tools can do their job in a unified manner. This provides a common platform for the automation engineer.


There are various types of frameworks. They are categorized on the basis of the automation component they leverage. These are:



1. [Data-driven testing](/wiki/Data-driven_testing "Data-driven testing")
2. [Modularity-driven testing](/wiki/Modularity-driven_testing "Modularity-driven testing")
3. [Keyword-driven testing](/wiki/Keyword-driven_testing "Keyword-driven testing")
4. [Hybrid testing](/wiki/Hybrid_testing "Hybrid testing")
5. [Model-based testing](/wiki/Model-based_testing "Model-based testing")
6. Code-driven testing
7. [Behavior driven development](/wiki/Behavior_driven_development "Behavior driven development")


### Data-driven testing[[edit](/w/index.php?title=Test_automation&action=edit&section=26 "Edit section: Data-driven testing")]


This paragraph is an excerpt from [Data-driven testing](/wiki/Data-driven_testing "Data-driven testing").[[edit](https://en.wikipedia.org/w/index.php?title=Data-driven_testing&action=edit)]
[Data-driven testing](/wiki/Data-driven_testing "Data-driven testing") (DDT), also known as table-driven testing or parameterized testing, is a [software testing](/wiki/Software_testing "Software testing") methodology that is used in the testing of [computer](/wiki/Computer "Computer") [software](/wiki/Software "Software") to describe testing done using a table of conditions directly as test inputs and verifiable outputs as well as the process where test environment settings and control are not hard-coded.[[22]](#cite_note-22)[[23]](#cite_note-23) In the simplest form the tester supplies the inputs from a row in the table and expects the outputs which occur in the same row. The table typically contains values which correspond to boundary or partition input spaces. In the control methodology, test configuration is "read" from a database.
### Modularity-driven testing[[edit](/w/index.php?title=Test_automation&action=edit&section=27 "Edit section: Modularity-driven testing")]


This paragraph is an excerpt from [Modularity-driven testing](/wiki/Modularity-driven_testing "Modularity-driven testing").[[edit](https://en.wikipedia.org/w/index.php?title=Modularity-driven_testing&action=edit)]
[Modularity-driven testing](/wiki/Modularity-driven_testing "Modularity-driven testing") is a term used in the testing of [software](/wiki/Software "Software"). The test [script](/wiki/Script_(computer_programming) "Script (computer programming)") modularity [framework](/wiki/Software_framework "Software framework") requires the creation of small, independent scripts that represent modules, sections, and functions of the application-under-test. These small scripts are then used in a hierarchical fashion to construct larger tests, realizing a particular test case.[[24]](#cite_note-24)
### Keyword-driven testing[[edit](/w/index.php?title=Test_automation&action=edit&section=28 "Edit section: Keyword-driven testing")]


These paragraphs are an excerpt from [Keyword-driven testing](/wiki/Keyword-driven_testing "Keyword-driven testing").[[edit](https://en.wikipedia.org/w/index.php?title=Keyword-driven_testing&action=edit)]
[Keyword-driven testing](/wiki/Keyword-driven_testing "Keyword-driven testing"), also known as action word based testing (not to be confused with action driven testing), is a [software testing](/wiki/Software_testing "Software testing") methodology suitable for both [manual](/wiki/Manual_testing "Manual testing") and [automated testing](/wiki/Automated_testing "Automated testing"). This method separates the documentation of [test cases](/wiki/Test_case "Test case") – including both the data and functionality to use – from the prescription of the way the test cases are executed. As a result, it separates the test creation process into two distinct stages: a design and development stage, and an execution stage. The design substage covers the [requirement analysis](/wiki/Requirement_analysis "Requirement analysis") and assessment and the data analysis, definition, and population.
### Hybrid testing[[edit](/w/index.php?title=Test_automation&action=edit&section=29 "Edit section: Hybrid testing")]


These paragraphs are an excerpt from [Hybrid testing](/wiki/Hybrid_testing "Hybrid testing").[[edit](https://en.wikipedia.org/w/index.php?title=Hybrid_testing&action=edit)]
[Hybrid testing](/wiki/Hybrid_testing "Hybrid testing") is what most frameworks evolve/develop into over time and multiple projects. The most successful automation frameworks generally accommodate both grammar and spelling, as well as information input. This allows information given to be cross-checked against existing and confirmed information. This helps to prevent false or misleading information being posted. It still however allows others to post new and relevant information to existing posts, and so increases the usefulness and relevance of the site. This said, no system is perfect, and it may not perform to this standard on all subjects all the time but will improve with increasing input and increasing use.
### Model-based testing[[edit](/w/index.php?title=Test_automation&action=edit&section=30 "Edit section: Model-based testing")]


This section is an excerpt from [Model-based testing](/wiki/Model-based_testing "Model-based testing").[[edit](https://en.wikipedia.org/w/index.php?title=Model-based_testing&action=edit)]
[![](//upload.wikimedia.org/wikipedia/commons/3/36/Mbt-overview.png)](/wiki/File:Mbt-overview.png)

General model-based testing setting


[Model-based testing](/wiki/Model-based_testing "Model-based testing") is an application of [model-based design](/wiki/Model-based_design "Model-based design") for designing and optionally also executing artifacts to perform [software testing](/wiki/Software_testing "Software testing") or [system testing](/wiki/System_testing "System testing"). Models can be used to represent the desired behavior of a [system under test](/wiki/System_under_test "System under test") (SUT), or to represent testing strategies and a test environment. The picture on the right depicts the former approach.
### Behavior driven development[[edit](/w/index.php?title=Test_automation&action=edit&section=31 "Edit section: Behavior driven development")]


This paragraph is an excerpt from [Behavior-driven development](/wiki/Behavior-driven_development "Behavior-driven development").[[edit](https://en.wikipedia.org/w/index.php?title=Behavior-driven_development&action=edit)]
[Behavior-driven development](/wiki/Behavior-driven_development "Behavior-driven development") (BDD) involves naming [software tests](/wiki/Software_testing "Software testing") using [domain language](/wiki/Domain_model "Domain model") to describe the behavior of the [code](/wiki/Source_code "Source code").
See also[[edit](/w/index.php?title=Test_automation&action=edit&section=32 "Edit section: See also")]
----------------------------------------------------------------------------------------------------


* [Comparison of GUI testing tools](/wiki/Comparison_of_GUI_testing_tools "Comparison of GUI testing tools")
* [List of web testing tools](/wiki/List_of_web_testing_tools "List of web testing tools")
* [Continuous testing](/wiki/Continuous_testing "Continuous testing")
* [Fuzzing](/wiki/Fuzzing "Fuzzing")
* [Headless browser](/wiki/Headless_browser "Headless browser")
* [Software testing](/wiki/Software_testing "Software testing")
* [System testing](/wiki/System_testing "System testing")
* [Unit test](/wiki/Unit_test "Unit test")


References[[edit](/w/index.php?title=Test_automation&action=edit&section=33 "Edit section: References")]
--------------------------------------------------------------------------------------------------------



1. **[^](#cite_ref-1)** Kolawa, Adam; Huizinga, Dorota (2007). *Automated Defect Prevention: Best Practices in Software Management*. Wiley-IEEE Computer Society Press. p. 74. [ISBN](/wiki/ISBN_(identifier) "ISBN (identifier)") [978-0-470-04212-0](/wiki/Special:BookSources/978-0-470-04212-0 "Special:BookSources/978-0-470-04212-0").
2. **[^](#cite_ref-2)** O’Connor, Rory V.; Akkaya, Mariye Umay; Kemaneci, Kerem; Yilmaz, Murat; Poth, Alexander; Messnarz, Richard (2015-10-15). [*Systems, Software and Services Process Improvement: 22nd European Conference, EuroSPI 2015, Ankara, Turkey, September 30 -- October 2, 2015. Proceedings*](https://books.google.com/books?id=2xOcCgAAQBAJ&q=Systems%2C+Software+and+Services+Process+Improvement%3A+27th+European+Conference&pg=PA71). Springer. [ISBN](/wiki/ISBN_(identifier) "ISBN (identifier)") [978-3-319-24647-5](/wiki/Special:BookSources/978-3-319-24647-5 "Special:BookSources/978-3-319-24647-5").
3. **[^](#cite_ref-3)** *Proceedings from the 5th International Conference on Software Testing and Validation (ICST). Software Competence Center Hagenberg. "Test Design: Lessons Learned and Practical Implications*. [doi](/wiki/Doi_(identifier) "Doi (identifier)"):[10.1109/IEEESTD.2008.4578383](https://doi.org/10.1109%2FIEEESTD.2008.4578383). [ISBN](/wiki/ISBN_(identifier) "ISBN (identifier)") [978-0-7381-5746-7](/wiki/Special:BookSources/978-0-7381-5746-7 "Special:BookSources/978-0-7381-5746-7").
4. **[^](#cite_ref-reichart1_4-0)** [Testing APIs protects applications and reputations](http://searchsoftwarequality.techtarget.com/tip/Testing-APIs-protects-applications-and-reputations), by Amy Reichert, SearchSoftwareQuality March 2015
5. **[^](#cite_ref-stickyminds_5-0)** [All About API Testing: An Interview with Jonathan Cooper](http://www.stickyminds.com/interview/all-about-api-testing-interview-jonathan-cooper), by Cameron Philipp-Edmonds, Stickyminds August 19, 2014
6. **[^](#cite_ref-6)** [Produce Better Software by Using a Layered Testing Strategy](https://www.gartner.com/en/documents/2645817), by Sean Kenefick, [Gartner](/wiki/Gartner "Gartner") January 7, 2014
7. **[^](#cite_ref-7)** Headless Testing with Browsers; <https://docs.travis-ci.com/user/gui-and-headless-browsers/>
8. **[^](#cite_ref-Headless_Testing_with_Browsers_8-0)** Headless Testing with PhantomJS;<http://phantomjs.org/headless-testing.html>
9. **[^](#cite_ref-9)** Automated User Interface Testing; <https://www.devbridge.com/articles/automated-user-interface-testing/>
10. **[^](#cite_ref-Learning_TDD_10-0)** Vodde, Bas; Koskela, Lasse (2007). "Learning Test-Driven Development by Counting Lines". *IEEE Software*. **24** (3): 74–79. [doi](/wiki/Doi_(identifier) "Doi (identifier)"):[10.1109/ms.2007.80](https://doi.org/10.1109%2Fms.2007.80). [S2CID](/wiki/S2CID_(identifier) "S2CID (identifier)") [30671391](https://api.semanticscholar.org/CorpusID:30671391).
11. **[^](#cite_ref-essential_11-0)** [Part of the Pipeline: Why Continuous Testing Is Essential](https://www.techwell.com/techwell-insights/2015/08/part-pipeline-why-continuous-testing-essential), by Adam Auerbach, TechWell Insights August 2015
12. **[^](#cite_ref-stickym_12-0)** [The Relationship between Risk and Continuous Testing: An Interview with Wayne Ariola](http://www.stickyminds.com/interview/relationship-between-risk-and-continuous-testing-interview-wayne-ariola), by Cameron Philipp-Edmonds, Stickyminds December 2015
13. **[^](#cite_ref-pnsqc_13-0)** [DevOps: Are You Pushing Bugs to Clients Faster](http://uploads.pnsqc.org/2015/papers/t-007_Ariola_paper.pdf), by Wayne Ariola and Cynthia Dunlop, PNSQC October 2015
14. **[^](#cite_ref-14)** 
Brian Marick. ["When Should a Test Be Automated?"](http://www.stickyminds.com/sitewide.asp?Function=edetail&ObjectType=ART&ObjectId=2010). StickyMinds.com. Retrieved 2009-08-20.
15. **[^](#cite_ref-15)** Garousi, Vahid; Mäntylä, Mika V. (2016-08-01). "When and what to automate in software testing? A multi-vocal literature review". *Information and Software Technology*. **76**: 92–117. [doi](/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/j.infsof.2016.04.015](https://doi.org/10.1016%2Fj.infsof.2016.04.015).
16. ^ [***a***](#cite_ref-:0_16-0) [***b***](#cite_ref-:0_16-1) [***c***](#cite_ref-:0_16-2) Mike Cohn (2010). *Succeeding with Agile*. Raina Chrobak. [ISBN](/wiki/ISBN_(identifier) "ISBN (identifier)") [978-0-321-57936-2](/wiki/Special:BookSources/978-0-321-57936-2 "Special:BookSources/978-0-321-57936-2").
17. **[^](#cite_ref-17)** ["Full Stack Testing by Gayathri Mohan"](https://www.thoughtworks.com/en-us/insights/books/full-stack-testing). *www.thoughtworks.com*. Retrieved 2022-09-13.
18. **[^](#cite_ref-18)** [The Practical Test Pyramid](https://martinfowler.com/articles/practical-test-pyramid.html), by Ham Vocke
19. ^ [***a***](#cite_ref-:1_19-0) [***b***](#cite_ref-:1_19-1) ["Just Say No to More End-to-End Tests"](https://testing.googleblog.com/2015/04/just-say-no-to-more-end-to-end-tests.html). *Google Testing Blog*. Retrieved 2023-02-11.
20. **[^](#cite_ref-20)** ["Selenium Meet-Up 4/20/2010 Elisabeth Hendrickson on Robot Framework 1of2"](https://www.youtube.com/watch?v=qf2i-xQ3LoY). *[YouTube](/wiki/YouTube "YouTube")*. Retrieved 2010-09-26.
21. ^ [***a***](#cite_ref-Interface_21-0) [***b***](#cite_ref-Interface_21-1) [***c***](#cite_ref-Interface_21-2) ["Conquest: Interface for Test Automation Design"](https://web.archive.org/web/20120426044210/http://www.qualitycow.com/Docs/ConquestInterface.pdf) (PDF). Archived from [the original](http://www.qualitycow.com/Docs/ConquestInterface.pdf) (PDF) on 2012-04-26. Retrieved 2011-12-11.
22. **[^](#cite_ref-22)** ["golang/go TableDrivenTests"](https://github.com/golang/go/wiki/TableDrivenTests). *GitHub*.
23. **[^](#cite_ref-23)** ["JUnit 5 User Guide"](https://junit.org/junit5/docs/current/user-guide/#writing-tests-parameterized-tests). *junit.org*.
24. **[^](#cite_ref-24)** DESAI, SANDEEP; SRIVASTAVA, ABHISHEK (2016-01-30). [*SOFTWARE TESTING : A Practical Approach*](https://books.google.com/books?id=B4sQDAAAQBAJ&dq=Modularity-driven+testing+framework&pg=PA157) (in Arabic). PHI Learning Pvt. Ltd. [ISBN](/wiki/ISBN_(identifier) "ISBN (identifier)") [978-81-203-5226-1](/wiki/Special:BookSources/978-81-203-5226-1 "Special:BookSources/978-81-203-5226-1").

### General references[[edit](/w/index.php?title=Test_automation&action=edit&section=34 "Edit section: General references")]



* Elfriede Dustin; et al. (1999). [*Automated Software Testing*](https://archive.org/details/automatedsoftwar00elfr). Addison Wesley. [ISBN](/wiki/ISBN_(identifier) "ISBN (identifier)") [978-0-201-43287-9](/wiki/Special:BookSources/978-0-201-43287-9 "Special:BookSources/978-0-201-43287-9").
* Elfriede Dustin; et al. (2009). *Implementing Automated Software Testing*. Addison Wesley. [ISBN](/wiki/ISBN_(identifier) "ISBN (identifier)") [978-0-321-58051-1](/wiki/Special:BookSources/978-0-321-58051-1 "Special:BookSources/978-0-321-58051-1").
* Mark Fewster & Dorothy Graham (1999). *Software Test Automation*. ACM Press/Addison-Wesley. [ISBN](/wiki/ISBN_(identifier) "ISBN (identifier)") [978-0-201-33140-0](/wiki/Special:BookSources/978-0-201-33140-0 "Special:BookSources/978-0-201-33140-0").
* Roman Savenkov: *How to Become a Software Tester.* Roman Savenkov Consulting, 2008, [ISBN](/wiki/ISBN_(identifier) "ISBN (identifier)") [978-0-615-23372-7](/wiki/Special:BookSources/978-0-615-23372-7 "Special:BookSources/978-0-615-23372-7")
* Hong Zhu; et al. (2008). [*AST '08: Proceedings of the 3rd International Workshop on Automation of Software Test*](http://portal.acm.org/citation.cfm?id=1370042#). ACM Press. [doi](/wiki/Doi_(identifier) "Doi (identifier)"):[10.1145/1370042](https://doi.org/10.1145%2F1370042). [ISBN](/wiki/ISBN_(identifier) "ISBN (identifier)") [978-1-60558-030-2](/wiki/Special:BookSources/978-1-60558-030-2 "Special:BookSources/978-1-60558-030-2").
* Mosley, Daniel J.; Posey, Bruce (2002). *Just Enough Software Test Automation*. Prentice Hall Professional. [ISBN](/wiki/ISBN_(identifier) "ISBN (identifier)") [978-0130084682](/wiki/Special:BookSources/978-0130084682 "Special:BookSources/978-0130084682").
* Hayes, Linda G., "Automated Testing Handbook", Software Testing Institute, 2nd Edition, March 2004
* Kaner, Cem, "[Architectures of Test Automation](http://www.kaner.com/pdfs/testarch.pdf) [Archived](https://web.archive.org/web/20210126100156/http://www.kaner.com/pdfs/testarch.pdf) 2021-01-26 at the [Wayback Machine](/wiki/Wayback_Machine "Wayback Machine")", August 2000



  






| * [v](/wiki/Template:Software_testing "Template:Software testing") * [t](/wiki/Template_talk:Software_testing "Template talk:Software testing") * [e](/wiki/Special:EditPage/Template:Software_testing "Special:EditPage/Template:Software testing") [Software testing](/wiki/Software_testing "Software testing") | |
| --- | --- |
| The "box" approach | * [Black-box testing](/wiki/Black-box_testing "Black-box testing") 	+ [All-pairs testing](/wiki/All-pairs_testing "All-pairs testing") 	+ [Exploratory testing](/wiki/Exploratory_testing "Exploratory testing") 	+ [Fuzz testing](/wiki/Fuzz_testing "Fuzz testing") 	+ [Model-based testing](/wiki/Model-based_testing "Model-based testing") 	+ [Scenario testing](/wiki/Scenario_testing "Scenario testing") * [Grey-box testing](/wiki/Grey-box_testing "Grey-box testing") * [White-box testing](/wiki/White-box_testing "White-box testing") 	+ [API testing](/wiki/API_testing "API testing") 	+ [Mutation testing](/wiki/Mutation_testing "Mutation testing") 	+ [Static testing](/wiki/Static_testing "Static testing") |
| Testing levels | * [Acceptance testing](/wiki/Acceptance_testing "Acceptance testing") * [Integration testing](/wiki/Integration_testing "Integration testing") * [System testing](/wiki/System_testing "System testing") * [Unit testing](/wiki/Unit_testing "Unit testing") |
| Testing types, techniques,and [tactics](/wiki/Software_testing_tactics "Software testing tactics") | * [A/B testing](/wiki/A/B_testing "A/B testing") * [Benchmark](/wiki/Benchmark_(computing) "Benchmark (computing)") * [Compatibility testing](/wiki/Compatibility_testing "Compatibility testing") * [Concolic testing](/wiki/Concolic_testing "Concolic testing") * [Concurrent testing](/wiki/Concurrent_testing "Concurrent testing") * [Conformance testing](/wiki/Conformance_testing "Conformance testing") * [Continuous testing](/wiki/Continuous_testing "Continuous testing") * [Destructive testing](/wiki/Destructive_testing "Destructive testing") * [Development testing](/wiki/Development_testing "Development testing") * [Differential testing](/wiki/Differential_testing "Differential testing") * [Dynamic program analysis](/wiki/Dynamic_program_analysis "Dynamic program analysis") * [Installation testing](/wiki/Installation_testing "Installation testing") * [Negative testing](/wiki/Negative_testing "Negative testing") * [Random testing](/wiki/Random_testing "Random testing") * [Regression testing](/wiki/Regression_testing "Regression testing") * [Security testing](/wiki/Security_testing "Security testing") * [Smoke testing (software)](/wiki/Smoke_testing_(software) "Smoke testing (software)") * [Software performance testing](/wiki/Software_performance_testing "Software performance testing") * [Stress testing](/wiki/Stress_testing_(software) "Stress testing (software)") * [Symbolic execution](/wiki/Symbolic_execution "Symbolic execution") * Test automation * [Usability testing](/wiki/Usability_testing "Usability testing") |
| See also | * [Graphical user interface testing](/wiki/Graphical_user_interface_testing "Graphical user interface testing") * [Manual testing](/wiki/Manual_testing "Manual testing") * [Orthogonal array testing](/wiki/Orthogonal_array_testing "Orthogonal array testing") * [Pair testing](/wiki/Pair_testing "Pair testing") * [Soak testing](/wiki/Soak_testing "Soak testing") * [Software reliability testing](/wiki/Software_reliability_testing "Software reliability testing") * [Stress testing](/wiki/Stress_testing "Stress testing") * [Web testing](/wiki/Web_testing "Web testing") |





![](https://login.wikimedia.org/wiki/Special:CentralAutoLogin/start?type=1x1)
Retrieved from "<https://en.wikipedia.org/w/index.php?title=Test_automation&oldid=1226258740>"
[Categories](/wiki/Help:Category "Help:Category"): * [Software testing](/wiki/Category:Software_testing "Category:Software testing")
* [Automation software](/wiki/Category:Automation_software "Category:Automation software")
Hidden categories: * [CS1 Arabic-language sources (ar)](/wiki/Category:CS1_Arabic-language_sources_(ar) "Category:CS1 Arabic-language sources (ar)")
* [Articles with short description](/wiki/Category:Articles_with_short_description "Category:Articles with short description")
* [Short description is different from Wikidata](/wiki/Category:Short_description_is_different_from_Wikidata "Category:Short description is different from Wikidata")
* [Articles lacking in-text citations from February 2009](/wiki/Category:Articles_lacking_in-text_citations_from_February_2009 "Category:Articles lacking in-text citations from February 2009")
* [All articles lacking in-text citations](/wiki/Category:All_articles_lacking_in-text_citations "Category:All articles lacking in-text citations")
* [All articles with unsourced statements](/wiki/Category:All_articles_with_unsourced_statements "Category:All articles with unsourced statements")
* [Articles with unsourced statements from August 2009](/wiki/Category:Articles_with_unsourced_statements_from_August_2009 "Category:Articles with unsourced statements from August 2009")
* [Articles with unsourced statements from March 2013](/wiki/Category:Articles_with_unsourced_statements_from_March_2013 "Category:Articles with unsourced statements from March 2013")
* [Wikipedia articles needing clarification from June 2016](/wiki/Category:Wikipedia_articles_needing_clarification_from_June_2016 "Category:Wikipedia articles needing clarification from June 2016")
* [Articles with unsourced statements from January 2013](/wiki/Category:Articles_with_unsourced_statements_from_January_2013 "Category:Articles with unsourced statements from January 2013")
* [Articles with excerpts](/wiki/Category:Articles_with_excerpts "Category:Articles with excerpts")
* [Webarchive template wayback links](/wiki/Category:Webarchive_template_wayback_links "Category:Webarchive template wayback links")

